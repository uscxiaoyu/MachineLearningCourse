{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b2eeb7-a21f-406c-94b2-d83190119ede",
   "metadata": {},
   "source": [
    "# 线性代数及Python实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044cef56-8433-4d1d-80c3-165f0f0d30b4",
   "metadata": {},
   "source": [
    "## 1. 标量、向量、矩阵、张量\n",
    "- 标量(scalar): 表⽰⼀个单独的数，通常⽤斜体⼩写字母表示\n",
    "- 向量(vector): 表⽰一列数，这些数有序排列的，可以通过下标获取对应值，通常⽤粗体⼩写字母表⽰\n",
    "- 矩阵(matrix): 表⽰⼀个二维数组，每个元素的下标由两个数字确定，通常⽤⼤写粗体字母表⽰\n",
    "- 张量(Tensor): 超过二维的数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ddc913b-6447-4936-af9e-211320a4c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a83f952-7e89-449d-82a2-485222202dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标量:\n",
      "5\n",
      "向量:\n",
      "[1 2]\n",
      "矩阵:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "张量:\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]]\n",
      "\n",
      " [[11 12 13]\n",
      "  [14 15 16]\n",
      "  [17 18 19]]\n",
      "\n",
      " [[21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]]\n"
     ]
    }
   ],
   "source": [
    "# 标量\n",
    "s = 5\n",
    "# 向量\n",
    "v = np.array([1,2])\n",
    "# 矩阵\n",
    "m = np.array([[1,2], [3,4]])\n",
    "# 张量\n",
    "t = np.array([\n",
    "    [[1,2,3],[4,5,6],[7,8,9]],\n",
    "    [[11,12,13],[14,15,16],[17,18,19]],\n",
    "    [[21,22,23],[24,25,26],[27,28,29]],\n",
    "    ])\n",
    "print(\"标量:\\n\" + str(s))\n",
    "print(\"向量:\\n\" + str(v))\n",
    "print(\"矩阵:\\n\" + str(m))\n",
    "print(\"张量:\\n\" + str(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b17fe-9672-46e7-8065-9ada4e4d4d09",
   "metadata": {},
   "source": [
    "## 2. 矩阵转置\n",
    "\n",
    "矩阵转置 (Transpose) 相当于沿着对角线翻转，定义如下：\n",
    "$$\n",
    "A_{i,j}^T=A_{j,i}\n",
    "$$\n",
    "矩阵转置的转置等于矩阵本⾝：\n",
    "$$\n",
    "(A^T)^T=A\n",
    "$$\n",
    "\n",
    "向量可以看成是只有一列的矩阵，为了⽅便，我们可以使⽤⾏向量加转置的操作，如：$x=[x_1,x_2,x_3]^T$\n",
    "\n",
    "标量也可以看成是一行一列的矩阵，其转置等于它⾃⾝：$a^T=a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e9faf4-4ad3-4226-852e-f4aecc4cc7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      " [[1. 2.]\n",
      " [1. 0.]\n",
      " [2. 3.]]\n",
      "A 的转置:\n",
      " [[1. 1. 2.]\n",
      " [2. 0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1.0,2.0],[1.0,0.0],[2.0,3.0]])\n",
    "A_t = A.transpose()\n",
    "print(\"A:\\n\", A)\n",
    "print(\"A 的转置:\\n\", A_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cadbd73-394d-4680-85b2-a4fe98a1f160",
   "metadata": {},
   "source": [
    "# 3. 矩阵加法\n",
    "加法即对应元素相加，要求两个矩阵的形状⼀样:\n",
    "$$\n",
    "C=A+B, C_{i,j}=A_{i,j}+B_{i,j}\n",
    "$$\n",
    "\n",
    "数乘即一个标量与矩阵每个元素相乘:\n",
    "$$\n",
    "D=a\\cdot B+c,D_{i,j}=a\\cdot B_{i,j}+c\n",
    "$$\n",
    "\n",
    "有时我们允许矩阵和向量相加的，得到⼀个矩阵，把 b 加到了 A 的每⼀⾏上，本质上是构造了⼀个将 b 按⾏复制的⼀个新矩阵，这种机制叫做⼴播 (Broadcasting):\n",
    "$$\n",
    "C=A+b, C_{i,j}=A_{i,j}+b_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d135b412-6dbd-4642-900d-2b71ae69cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵相加： [[ 7.  9.]\n",
      " [11. 13.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1.0,2.0],[3.0,4.0]])\n",
    "b = np.array([[6.0,7.0],[8.0,9.0]])\n",
    "print(\"矩阵相加：\", a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75db1830-19ca-4d21-ab04-ef3fda685245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3.],\n",
       "       [5., 6.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + np.array([[1], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38104de7-d16a-431b-8f10-8a118fb464ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3.],\n",
       "       [4., 5.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24f693-cad9-4a2a-822b-ce6ac5ea4ce5",
   "metadata": {},
   "source": [
    "## 4. 矩阵乘法\n",
    "两个矩阵相乘得到第三个矩阵，我们需要$A$的形状为$m\\times n$，$B$的形状为$n\\times p$，得到的矩阵$C$的形状为$m\\times p$:\n",
    "$$\n",
    "C=AB\n",
    "$$\n",
    "具体定义为\n",
    "$$\n",
    "C_{i,j}=\\sum_k A_{i,k}B_{k,j}\n",
    "$$\n",
    "\n",
    "如果有两个相同形状的矩阵$A,B$，它们可以执行Hadmard乘积，即为$A\\odot B$，具体定义为\n",
    "$$\n",
    "C_{i,j} = A_{i,j}\\times B_{ij}\n",
    "$$\n",
    "\n",
    "向量可以看作是列为 1 的矩阵，两个相同维数的向量 x 和 y 的点乘（Dot Product）或者内积，可以表⽰为 $x^Ty$。\n",
    "\n",
    "可以将矩阵乘法理解为： $C_{i,j}$表示$A$的第i行与$B$的第j行的內积:\n",
    "$$\n",
    "C_{i,j}=A_{i,:}B_{:,j}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100d1e37-b3d8-47c3-932b-a413424988f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "按矩阵乘法规则： [[16.  2.]\n",
      " [ 1.  2.]]\n",
      "按逐元素相乘： [[1. 6.]\n",
      " [5. 0.]]\n",
      "按逐元素相乘： [[1. 6.]\n",
      " [5. 0.]]\n",
      "向量内积： 14.0\n"
     ]
    }
   ],
   "source": [
    "m1 = np.array([[1.0, 3.0], [1.0, 0.0]])\n",
    "m2 = np.array([[1.0, 2.0], [5.0, 0.0]])\n",
    "\n",
    "print(\"按矩阵乘法规则：\", np.dot(m1, m2))\n",
    "print(\"按逐元素相乘：\", np.multiply(m1, m2))\n",
    "print(\"按逐元素相乘：\", m1*m2)\n",
    "\n",
    "v1 = np.array([1.0, 2.0])\n",
    "v2 = np.array([4.0, 5.0])\n",
    "print(\"向量内积：\", np.dot(v1, v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cc3e8-05fe-451f-ade3-4b89f3be34b8",
   "metadata": {},
   "source": [
    "## 5. 单位矩阵\n",
    "\n",
    "为了引⼊矩阵的逆，我们需要先定义单位矩阵 (Identity Matrix)：单位矩阵乘以任意⼀个向量等于这个向量本⾝。记 $I_n$ 为保持 $n$ 维向量不变的单位矩阵，即\n",
    "$$\n",
    "I_n\\in R^{n\\times n}, \\forall x\\in R^n, I_nx=x\n",
    "$$\n",
    "单位矩阵的结构⼗分简单，所有的对⾓元素都为 1 ，其他元素都为 0, 例如\n",
    "$$\n",
    "I_3=\\left[\n",
    "\\begin{array}{l}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{array}\n",
    "\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9fe2fdd-2a06-4950-8dcf-be2458ef7d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.identity(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8667b86-d8fc-45ab-958e-90362eba0961",
   "metadata": {},
   "source": [
    "## 6. 矩阵的逆\n",
    "\n",
    "矩阵 A 的逆 (Inversion) 记作 $A^{−1}$, 满足\n",
    "$$\n",
    "A^{-1}A=I_n\n",
    "$$\n",
    "如果 $A^{−1}$ 存在，那么线性⽅程组 $Ax = b$ 的解为：\n",
    "$$\n",
    "A^{-1}AX=I_nx=x=A^{-1}b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131e3a87-ee18-4583-865e-b1df0d1dadf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 的逆矩阵 [[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1.0, 2.0],\n",
    "              [3.0, 4.0]])\n",
    "\n",
    "A_inv = np.linalg.inv(A)\n",
    "print(\"A 的逆矩阵\", A_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59384db7-f38e-4492-a023-41a21516274f",
   "metadata": {},
   "source": [
    "## 7. 范数\n",
    "\n",
    "矩阵的F范数\n",
    "$$\n",
    "||A||_F=\\sqrt{\\sum_{i,j}A_{i,j}^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2adc9f07-559f-4fb5-a1dd-4ec47565d498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量 2 范数 3.1622776601683795\n",
      "向量 1 范数 4.0\n",
      "向量无穷范数 3.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1.0,3.0])\n",
    "print(\"向量 2 范数\", np.linalg.norm(a, ord=2))\n",
    "print(\"向量 1 范数\", np.linalg.norm(a, ord=1))\n",
    "print(\"向量无穷范数\", np.linalg.norm(a, ord=np.inf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e7a3dfa-739c-4ebe-9ea1-27525adb6776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矩阵 F 范数 3.872983346207417\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1.0, 3.0],\n",
    "              [2.0, 1.0]])\n",
    "print(\"矩阵 F 范数\", np.linalg.norm(a, ord=\"fro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6a99dc-1817-4d03-bd51-b26da87d01b4",
   "metadata": {},
   "source": [
    "## 8. 特征值分解\n",
    "如果⼀个 $n\\times n$ 矩阵 $A$ 有 $n$ 组线性⽆关的单位特征向量 ${v(1),...,v(n)}$，以及对应的特征值 $λ_1,...,λ_n$。将这些特征向量按列拼接成⼀个矩阵：\n",
    "$V = [v(1),...,v(n)]$，并将对应的特征值拼接成⼀个向量：$λ = [λ_1,...,λ_n]$。\n",
    "\n",
    "A的特征值分解(Eiendecomposition)为:\n",
    "$$\n",
    "A=V diag(\\lambda) V^{-1}\n",
    "$$\n",
    "\n",
    "注意：\n",
    "- 不是所有的矩阵都有特征值分解\n",
    "- 在某些情况下，实矩阵的特征值分解可能会得到复矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c272c8c-9c6c-4c71-b5f2-6d882b6043f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1.0,2.0,3.0],\n",
    "            [4.0,5.0,6.0],\n",
    "            [7.0,8.0,9.0]])\n",
    "# 计算特征值\n",
    "print(\"特征值:\", np.linalg.eigvals(A))\n",
    "# 计算特征值和特征向量\n",
    "eigvals, eigvectors = np.linalg.eig(A)\n",
    "print(\"特征值:\", eigvals)\n",
    "print(\"特征向量:\", eigvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cc189-8eee-486c-837f-01e37b5ae1d0",
   "metadata": {},
   "source": [
    "## 9. 奇异值分解\n",
    "奇异值分解 (Singular Value Decomposition, SVD) 提供了另⼀种分解矩阵的⽅式，将其分解为奇异向量和奇异值。\n",
    "与特征值分解相⽐，奇异值分解更加通⽤，所有的实矩阵都可以进⾏奇异值分解，⽽特征值分解只对某些⽅阵可以。\n",
    "奇异值分解的形式为：\n",
    "$$\n",
    "A=U\\Sigma V^T\n",
    "$$\n",
    "\n",
    "若 $A$ 是 $m × n$ 的，那么 $U$ 是 $m × m$ 的，其列向量称为左奇异向量，⽽ $V$ 是 $n × n$ 的，其列向量称为右奇异向量，⽽ $Σ$ 是$m × n$的⼀个对⾓矩\n",
    "阵，其对⾓元素称为矩阵 $A$ 的奇异值。\n",
    "\n",
    "事实上，左奇异向量是 $AA^T$ 的特征向量，⽽右奇异向量是 $A^TA$ 的特征向量，⾮ 0 奇异值的平⽅是 $A^TA$ 的⾮ 0 特征值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97f55673-41dc-404c-96e6-6fecd3fe6e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U: [[-0.3863177  -0.92236578]\n",
      " [-0.92236578  0.3863177 ]]\n",
      "D: [9.508032   0.77286964]\n",
      "V: [[-0.42866713 -0.56630692 -0.7039467 ]\n",
      " [ 0.80596391  0.11238241 -0.58119908]\n",
      " [ 0.40824829 -0.81649658  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1.0,2.0,3.0],\n",
    "                [4.0,5.0,6.0]])\n",
    "U,D,V = np.linalg.svd(A)\n",
    "print(\"U:\", U)\n",
    "print(\"D:\", D)\n",
    "print(\"V:\", V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb9eb07-76a8-4145-8738-91035568c79d",
   "metadata": {},
   "source": [
    "## 10. 迹运算\n",
    "\n",
    "一个方阵A的迹等于其对角线上元素之和\n",
    "$$\n",
    "trace(A)=\\sum_i A_{i,i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42cdfd3-9688-4d94-8550-8aedafaa9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d388c2-65fd-41b3-964e-e998647211ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.arange(25).reshape(5, 5)\n",
    "B = torch.arange(25, 50).reshape(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a026656-5f38-481f-8fc3-e594953639de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19],\n",
       "         [20, 21, 22, 23, 24]]),\n",
       " tensor([[25, 26, 27, 28, 29],\n",
       "         [30, 31, 32, 33, 34],\n",
       "         [35, 36, 37, 38, 39],\n",
       "         [40, 41, 42, 43, 44],\n",
       "         [45, 46, 47, 48, 49]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93798d9a-c8ea-4d01-abf5-be22746ab3fb",
   "metadata": {},
   "source": [
    "$tr(A)=tr(A^T)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a5bd2e-1b03-4f1c-a02f-e7e687f4d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(60), tensor(60))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(A), torch.trace(A.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab24e3a-752c-4de3-9187-5c9e61bed276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(185), tensor(185))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(B), torch.trace(B.t())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a1e43-3431-42be-b6bc-4c11615a2fff",
   "metadata": {},
   "source": [
    "$tr(AB)=tr(BA)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c3f6921-f749-4687-88cd-c5a062677b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 400,  410,  420,  430,  440],\n",
       "         [1275, 1310, 1345, 1380, 1415],\n",
       "         [2150, 2210, 2270, 2330, 2390],\n",
       "         [3025, 3110, 3195, 3280, 3365],\n",
       "         [3900, 4010, 4120, 4230, 4340]]),\n",
       " tensor([[1400, 1535, 1670, 1805, 1940],\n",
       "         [1650, 1810, 1970, 2130, 2290],\n",
       "         [1900, 2085, 2270, 2455, 2640],\n",
       "         [2150, 2360, 2570, 2780, 2990],\n",
       "         [2400, 2635, 2870, 3105, 3340]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(A, B), torch.mm(B, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e2030e5-7f20-4a5c-b77a-e6d945bee585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(11600), tensor(11600))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(torch.mm(A, B)), torch.trace(torch.mm(B, A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cdf478-8b57-498e-9ecb-7a200cde09f8",
   "metadata": {},
   "source": [
    "$tr(A^TB)=\\sum_i\\sum_jA_{i,j}B_{i,j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35cf6665-1d62-4799-8c99-10f1cd926506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2000, 2050, 2100, 2150, 2200],\n",
       "        [2175, 2230, 2285, 2340, 2395],\n",
       "        [2350, 2410, 2470, 2530, 2590],\n",
       "        [2525, 2590, 2655, 2720, 2785],\n",
       "        [2700, 2770, 2840, 2910, 2980]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_t_B = torch.mm(A.t(), B)\n",
    "A_t_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eb8fbee-4ed4-4517-b076-d9c765b4febc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12400)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(A_t_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a532ec9-aa6a-4d67-9996-6216137173a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12400)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.IntTensor([A_t_B[i, i] for i in range(5)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7551e-c111-4379-b93c-4c21d685e8cb",
   "metadata": {},
   "source": [
    "一个矩阵$A_{m\\times n}$的$F_2$范数等于\n",
    "$$\n",
    "trace(AA^T)=\\sqrt{\\sum_{i=1}^{i=m} A_{i,:}A_{:,i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39c83a1b-dfe5-45a8-a223-6f18f407b2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fce3d8b2-9d4d-48bd-b6d9-dee44595fca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  30,   80,  130,  180,  230],\n",
       "        [  80,  255,  430,  605,  780],\n",
       "        [ 130,  430,  730, 1030, 1330],\n",
       "        [ 180,  605, 1030, 1455, 1880],\n",
       "        [ 230,  780, 1330, 1880, 2430]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(A, A.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8959d79-d19b-4298-afce-ebbc6bbb4bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4900)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(torch.mm(A, A.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5db65db9-a2c8-48e3-983b-f4501a1ad6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4900)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(A**2)  # F范数的平方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf8a278-f694-4bb6-910c-5e16c3c4c7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
