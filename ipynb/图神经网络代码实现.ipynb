{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7a4b5e",
   "metadata": {},
   "source": [
    "使用PyG的内置数据进行3个任务的代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa623db",
   "metadata": {},
   "source": [
    "## 1.节点分类任务代码实现\n",
    "Cora数据集是PyG内置的节点分类数据集，代表着学术论文的相关性分类问题（即把每一篇学术论文都看成是节点），Cora数据集有2708个节点，1433维特征，边数为5429。标签是文献的主题，共计 7 个类别。所以这是一个7分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0114400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#载入数据\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "#定义网络架构\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)  #输入=节点特征维度，16是中间隐藏神经元个数\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率为：80.8%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "#模型训练\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)    #模型的输入有节点特征还有边特征,使用的是全部数据\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])   #损失仅仅计算的是训练集的损失\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#测试：\n",
    "model.eval()\n",
    "test_predict = model(data.x, data.edge_index)[data.test_mask]\n",
    "max_index = torch.argmax(test_predict, dim=1)\n",
    "test_true = data.y[data.test_mask]\n",
    "correct = 0\n",
    "for i in range(len(max_index)):\n",
    "    if max_index[i] == test_true[i]:\n",
    "        correct += 1\n",
    "print('测试集准确率为：{}%'.format(correct*100/len(test_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a60bff",
   "metadata": {},
   "source": [
    "## 2.边分类任务代码实现\n",
    "同样是利用Cora数据集，只是这个时候我们关注的不再是节点特征，而是边特征，因此，在这里我们需要手动创建边标签的正例与负例。这是一个二分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51906f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "# 边分类模型\n",
    "class EdgeClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeClassifier, self).__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "        self.classifier = torch.nn.Linear(2 * out_channels, 2)  \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv(x, edge_index))\n",
    "        pos_edge_index = edge_index    \n",
    "        total_edge_index = torch.cat([pos_edge_index, \n",
    "                                    negative_sampling(edge_index, num_neg_samples=pos_edge_index.size(1))], dim=1)\n",
    "        edge_features = torch.cat([x[total_edge_index[0]], x[total_edge_index[1]]], dim=1)  \n",
    "        return self.classifier(edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "dataset = Planetoid(root='./data/Cora/raw', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# 创建train_mask和test_mask\n",
    "edges = data.edge_index.t().cpu().numpy()   \n",
    "num_edges = edges.shape[0]\n",
    "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "train_size = int(0.8 * num_edges)\n",
    "train_indices = torch.randperm(num_edges)[:train_size]\n",
    "train_mask[train_indices] = True\n",
    "test_mask[~train_mask] = True\n",
    "\n",
    "# 定义模型和优化器/训练/测试\n",
    "model = EdgeClassifier(dataset.num_features, 64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pos_edge_index = data.edge_index\n",
    "    pos_labels = torch.ones(pos_edge_index.size(1), dtype=torch.long)  \n",
    "    neg_labels = torch.zeros(pos_edge_index.size(1), dtype=torch.long)  \n",
    "    labels = torch.cat([pos_labels, neg_labels], dim=0).to(logits.device)\n",
    "    new_train_mask = torch.cat([train_mask, train_mask], dim=0)\n",
    "    loss = F.cross_entropy(logits[new_train_mask], labels[new_train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pos_edge_index = data.edge_index\n",
    "        pos_labels = torch.ones(pos_edge_index.size(1), dtype=torch.long)\n",
    "        neg_labels = torch.zeros(pos_edge_index.size(1), dtype=torch.long)\n",
    "        labels = torch.cat([pos_labels, neg_labels], dim=0).to(logits.device)\n",
    "        new_test_mask = torch.cat([test_mask, test_mask], dim=0)\n",
    "        \n",
    "        predictions = logits[new_test_mask].max(1)[1]\n",
    "        correct = predictions.eq(labels[new_test_mask]).sum().item()\n",
    "        return correct / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6923, Acc: 0.5000\n",
      "Epoch: 002, Loss: 0.6819, Acc: 0.5836\n",
      "Epoch: 003, Loss: 0.6761, Acc: 0.5433\n",
      "Epoch: 004, Loss: 0.6622, Acc: 0.5289\n",
      "Epoch: 005, Loss: 0.6536, Acc: 0.6113\n",
      "Epoch: 006, Loss: 0.6444, Acc: 0.5987\n",
      "Epoch: 007, Loss: 0.6341, Acc: 0.6027\n",
      "Epoch: 008, Loss: 0.6270, Acc: 0.6487\n",
      "Epoch: 009, Loss: 0.6202, Acc: 0.6314\n",
      "Epoch: 010, Loss: 0.6111, Acc: 0.6581\n",
      "Epoch: 011, Loss: 0.6005, Acc: 0.6723\n",
      "Epoch: 012, Loss: 0.5959, Acc: 0.6650\n",
      "Epoch: 013, Loss: 0.5891, Acc: 0.6686\n",
      "Epoch: 014, Loss: 0.5871, Acc: 0.6667\n",
      "Epoch: 015, Loss: 0.5875, Acc: 0.6771\n",
      "Epoch: 016, Loss: 0.5766, Acc: 0.6854\n",
      "Epoch: 017, Loss: 0.5743, Acc: 0.6761\n",
      "Epoch: 018, Loss: 0.5734, Acc: 0.6920\n",
      "Epoch: 019, Loss: 0.5660, Acc: 0.6929\n",
      "Epoch: 020, Loss: 0.5629, Acc: 0.6887\n",
      "Epoch: 021, Loss: 0.5649, Acc: 0.6903\n",
      "Epoch: 022, Loss: 0.5640, Acc: 0.6899\n",
      "Epoch: 023, Loss: 0.5624, Acc: 0.6965\n",
      "Epoch: 024, Loss: 0.5584, Acc: 0.6996\n",
      "Epoch: 025, Loss: 0.5593, Acc: 0.6934\n",
      "Epoch: 026, Loss: 0.5535, Acc: 0.6929\n",
      "Epoch: 027, Loss: 0.5571, Acc: 0.6984\n",
      "Epoch: 028, Loss: 0.5553, Acc: 0.7027\n",
      "Epoch: 029, Loss: 0.5491, Acc: 0.6939\n",
      "Epoch: 030, Loss: 0.5533, Acc: 0.6884\n",
      "Epoch: 031, Loss: 0.5542, Acc: 0.7076\n",
      "Epoch: 032, Loss: 0.5520, Acc: 0.6974\n",
      "Epoch: 033, Loss: 0.5518, Acc: 0.6967\n",
      "Epoch: 034, Loss: 0.5480, Acc: 0.6946\n",
      "Epoch: 035, Loss: 0.5495, Acc: 0.6811\n",
      "Epoch: 036, Loss: 0.5488, Acc: 0.6903\n",
      "Epoch: 037, Loss: 0.5531, Acc: 0.6963\n",
      "Epoch: 038, Loss: 0.5462, Acc: 0.6967\n",
      "Epoch: 039, Loss: 0.5459, Acc: 0.7019\n",
      "Epoch: 040, Loss: 0.5474, Acc: 0.6965\n",
      "Epoch: 041, Loss: 0.5515, Acc: 0.6929\n",
      "Epoch: 042, Loss: 0.5453, Acc: 0.6979\n",
      "Epoch: 043, Loss: 0.5438, Acc: 0.6937\n",
      "Epoch: 044, Loss: 0.5477, Acc: 0.6894\n",
      "Epoch: 045, Loss: 0.5451, Acc: 0.6986\n",
      "Epoch: 046, Loss: 0.5488, Acc: 0.6944\n",
      "Epoch: 047, Loss: 0.5461, Acc: 0.6925\n",
      "Epoch: 048, Loss: 0.5483, Acc: 0.6899\n",
      "Epoch: 049, Loss: 0.5461, Acc: 0.6989\n",
      "Epoch: 050, Loss: 0.5458, Acc: 0.6932\n",
      "Epoch: 051, Loss: 0.5441, Acc: 0.6977\n",
      "Epoch: 052, Loss: 0.5449, Acc: 0.6934\n",
      "Epoch: 053, Loss: 0.5450, Acc: 0.6948\n",
      "Epoch: 054, Loss: 0.5452, Acc: 0.6932\n",
      "Epoch: 055, Loss: 0.5407, Acc: 0.6948\n",
      "Epoch: 056, Loss: 0.5425, Acc: 0.6889\n",
      "Epoch: 057, Loss: 0.5485, Acc: 0.6944\n",
      "Epoch: 058, Loss: 0.5454, Acc: 0.6998\n",
      "Epoch: 059, Loss: 0.5360, Acc: 0.6958\n",
      "Epoch: 060, Loss: 0.5442, Acc: 0.7022\n",
      "Epoch: 061, Loss: 0.5436, Acc: 0.6939\n",
      "Epoch: 062, Loss: 0.5433, Acc: 0.6991\n",
      "Epoch: 063, Loss: 0.5439, Acc: 0.6866\n",
      "Epoch: 064, Loss: 0.5434, Acc: 0.6901\n",
      "Epoch: 065, Loss: 0.5462, Acc: 0.6882\n",
      "Epoch: 066, Loss: 0.5389, Acc: 0.6913\n",
      "Epoch: 067, Loss: 0.5442, Acc: 0.6842\n",
      "Epoch: 068, Loss: 0.5455, Acc: 0.6944\n",
      "Epoch: 069, Loss: 0.5455, Acc: 0.6882\n",
      "Epoch: 070, Loss: 0.5451, Acc: 0.6939\n",
      "Epoch: 071, Loss: 0.5404, Acc: 0.7060\n",
      "Epoch: 072, Loss: 0.5438, Acc: 0.6948\n",
      "Epoch: 073, Loss: 0.5393, Acc: 0.6965\n",
      "Epoch: 074, Loss: 0.5399, Acc: 0.6929\n",
      "Epoch: 075, Loss: 0.5473, Acc: 0.6911\n",
      "Epoch: 076, Loss: 0.5409, Acc: 0.6901\n",
      "Epoch: 077, Loss: 0.5428, Acc: 0.6955\n",
      "Epoch: 078, Loss: 0.5432, Acc: 0.6970\n",
      "Epoch: 079, Loss: 0.5407, Acc: 0.6911\n",
      "Epoch: 080, Loss: 0.5418, Acc: 0.6858\n",
      "Epoch: 081, Loss: 0.5440, Acc: 0.6967\n",
      "Epoch: 082, Loss: 0.5434, Acc: 0.6920\n",
      "Epoch: 083, Loss: 0.5382, Acc: 0.6972\n",
      "Epoch: 084, Loss: 0.5356, Acc: 0.6965\n",
      "Epoch: 085, Loss: 0.5372, Acc: 0.6927\n",
      "Epoch: 086, Loss: 0.5440, Acc: 0.6799\n",
      "Epoch: 087, Loss: 0.5424, Acc: 0.6889\n",
      "Epoch: 088, Loss: 0.5477, Acc: 0.6709\n",
      "Epoch: 089, Loss: 0.5545, Acc: 0.6849\n",
      "Epoch: 090, Loss: 0.5462, Acc: 0.6934\n",
      "Epoch: 091, Loss: 0.5417, Acc: 0.6804\n",
      "Epoch: 092, Loss: 0.5500, Acc: 0.6839\n",
      "Epoch: 093, Loss: 0.5388, Acc: 0.6844\n",
      "Epoch: 094, Loss: 0.5442, Acc: 0.6731\n",
      "Epoch: 095, Loss: 0.5540, Acc: 0.6877\n",
      "Epoch: 096, Loss: 0.5418, Acc: 0.6828\n",
      "Epoch: 097, Loss: 0.5404, Acc: 0.6712\n",
      "Epoch: 098, Loss: 0.5471, Acc: 0.6958\n",
      "Epoch: 099, Loss: 0.5421, Acc: 0.6922\n",
      "Epoch: 100, Loss: 0.5411, Acc: 0.6866\n",
      "Epoch: 101, Loss: 0.5431, Acc: 0.6911\n",
      "Epoch: 102, Loss: 0.5412, Acc: 0.6922\n",
      "Epoch: 103, Loss: 0.5361, Acc: 0.6856\n",
      "Epoch: 104, Loss: 0.5439, Acc: 0.6944\n",
      "Epoch: 105, Loss: 0.5390, Acc: 0.6906\n",
      "Epoch: 106, Loss: 0.5423, Acc: 0.6837\n",
      "Epoch: 107, Loss: 0.5421, Acc: 0.6906\n",
      "Epoch: 108, Loss: 0.5347, Acc: 0.6880\n",
      "Epoch: 109, Loss: 0.5377, Acc: 0.6970\n",
      "Epoch: 110, Loss: 0.5376, Acc: 0.6896\n",
      "Epoch: 111, Loss: 0.5390, Acc: 0.6880\n",
      "Epoch: 112, Loss: 0.5393, Acc: 0.6934\n",
      "Epoch: 113, Loss: 0.5374, Acc: 0.6963\n",
      "Epoch: 114, Loss: 0.5404, Acc: 0.6908\n",
      "Epoch: 115, Loss: 0.5305, Acc: 0.6929\n",
      "Epoch: 116, Loss: 0.5405, Acc: 0.6880\n",
      "Epoch: 117, Loss: 0.5339, Acc: 0.6896\n",
      "Epoch: 118, Loss: 0.5379, Acc: 0.6873\n",
      "Epoch: 119, Loss: 0.5328, Acc: 0.6934\n",
      "Epoch: 120, Loss: 0.5393, Acc: 0.6941\n",
      "Epoch: 121, Loss: 0.5355, Acc: 0.6955\n",
      "Epoch: 122, Loss: 0.5356, Acc: 0.6970\n",
      "Epoch: 123, Loss: 0.5376, Acc: 0.6993\n",
      "Epoch: 124, Loss: 0.5337, Acc: 0.6854\n",
      "Epoch: 125, Loss: 0.5414, Acc: 0.6920\n",
      "Epoch: 126, Loss: 0.5373, Acc: 0.6887\n",
      "Epoch: 127, Loss: 0.5358, Acc: 0.6842\n",
      "Epoch: 128, Loss: 0.5354, Acc: 0.6925\n",
      "Epoch: 129, Loss: 0.5403, Acc: 0.6880\n",
      "Epoch: 130, Loss: 0.5408, Acc: 0.6903\n",
      "Epoch: 131, Loss: 0.5380, Acc: 0.6861\n",
      "Epoch: 132, Loss: 0.5369, Acc: 0.6868\n",
      "Epoch: 133, Loss: 0.5372, Acc: 0.7015\n",
      "Epoch: 134, Loss: 0.5343, Acc: 0.6839\n",
      "Epoch: 135, Loss: 0.5356, Acc: 0.6873\n",
      "Epoch: 136, Loss: 0.5364, Acc: 0.6882\n",
      "Epoch: 137, Loss: 0.5347, Acc: 0.6946\n",
      "Epoch: 138, Loss: 0.5388, Acc: 0.6984\n",
      "Epoch: 139, Loss: 0.5411, Acc: 0.6946\n",
      "Epoch: 140, Loss: 0.5346, Acc: 0.6899\n",
      "Epoch: 141, Loss: 0.5373, Acc: 0.6884\n",
      "Epoch: 142, Loss: 0.5309, Acc: 0.6913\n",
      "Epoch: 143, Loss: 0.5363, Acc: 0.6963\n",
      "Epoch: 144, Loss: 0.5354, Acc: 0.6818\n",
      "Epoch: 145, Loss: 0.5378, Acc: 0.6884\n",
      "Epoch: 146, Loss: 0.5313, Acc: 0.6802\n",
      "Epoch: 147, Loss: 0.5395, Acc: 0.6726\n",
      "Epoch: 148, Loss: 0.5428, Acc: 0.6863\n",
      "Epoch: 149, Loss: 0.5516, Acc: 0.6752\n",
      "Epoch: 150, Loss: 0.5492, Acc: 0.6906\n",
      "Epoch: 151, Loss: 0.5356, Acc: 0.6972\n",
      "Epoch: 152, Loss: 0.5386, Acc: 0.6868\n",
      "Epoch: 153, Loss: 0.5411, Acc: 0.6903\n",
      "Epoch: 154, Loss: 0.5375, Acc: 0.6903\n",
      "Epoch: 155, Loss: 0.5384, Acc: 0.6835\n",
      "Epoch: 156, Loss: 0.5448, Acc: 0.6785\n",
      "Epoch: 157, Loss: 0.5455, Acc: 0.6795\n",
      "Epoch: 158, Loss: 0.5318, Acc: 0.6847\n",
      "Epoch: 159, Loss: 0.5392, Acc: 0.6908\n",
      "Epoch: 160, Loss: 0.5330, Acc: 0.6830\n",
      "Epoch: 161, Loss: 0.5329, Acc: 0.6939\n",
      "Epoch: 162, Loss: 0.5328, Acc: 0.6854\n",
      "Epoch: 163, Loss: 0.5344, Acc: 0.6880\n",
      "Epoch: 164, Loss: 0.5354, Acc: 0.6823\n",
      "Epoch: 165, Loss: 0.5297, Acc: 0.6899\n",
      "Epoch: 166, Loss: 0.5342, Acc: 0.6811\n",
      "Epoch: 167, Loss: 0.5417, Acc: 0.6877\n",
      "Epoch: 168, Loss: 0.5325, Acc: 0.6861\n",
      "Epoch: 169, Loss: 0.5400, Acc: 0.6901\n",
      "Epoch: 170, Loss: 0.5367, Acc: 0.6906\n",
      "Epoch: 171, Loss: 0.5419, Acc: 0.6882\n",
      "Epoch: 172, Loss: 0.5388, Acc: 0.6832\n",
      "Epoch: 173, Loss: 0.5371, Acc: 0.6832\n",
      "Epoch: 174, Loss: 0.5394, Acc: 0.6806\n",
      "Epoch: 175, Loss: 0.5417, Acc: 0.6858\n",
      "Epoch: 176, Loss: 0.5375, Acc: 0.6887\n",
      "Epoch: 177, Loss: 0.5336, Acc: 0.6953\n",
      "Epoch: 178, Loss: 0.5338, Acc: 0.6939\n",
      "Epoch: 179, Loss: 0.5342, Acc: 0.6844\n",
      "Epoch: 180, Loss: 0.5336, Acc: 0.6830\n",
      "Epoch: 181, Loss: 0.5410, Acc: 0.6821\n",
      "Epoch: 182, Loss: 0.5390, Acc: 0.6929\n",
      "Epoch: 183, Loss: 0.5392, Acc: 0.6861\n",
      "Epoch: 184, Loss: 0.5427, Acc: 0.6873\n",
      "Epoch: 185, Loss: 0.5385, Acc: 0.6915\n",
      "Epoch: 186, Loss: 0.5355, Acc: 0.6960\n",
      "Epoch: 187, Loss: 0.5398, Acc: 0.6908\n",
      "Epoch: 188, Loss: 0.5393, Acc: 0.6854\n",
      "Epoch: 189, Loss: 0.5356, Acc: 0.6816\n",
      "Epoch: 190, Loss: 0.5392, Acc: 0.6823\n",
      "Epoch: 191, Loss: 0.5368, Acc: 0.6771\n",
      "Epoch: 192, Loss: 0.5365, Acc: 0.6776\n",
      "Epoch: 193, Loss: 0.5356, Acc: 0.6780\n",
      "Epoch: 194, Loss: 0.5368, Acc: 0.6818\n",
      "Epoch: 195, Loss: 0.5360, Acc: 0.6837\n",
      "Epoch: 196, Loss: 0.5410, Acc: 0.6832\n",
      "Epoch: 197, Loss: 0.5371, Acc: 0.6764\n",
      "Epoch: 198, Loss: 0.5410, Acc: 0.6802\n",
      "Epoch: 199, Loss: 0.5369, Acc: 0.6839\n",
      "Epoch: 200, Loss: 0.5309, Acc: 0.6915\n",
      "Epoch: 201, Loss: 0.5365, Acc: 0.6723\n",
      "Epoch: 202, Loss: 0.5357, Acc: 0.6892\n",
      "Epoch: 203, Loss: 0.5366, Acc: 0.6934\n",
      "Epoch: 204, Loss: 0.5341, Acc: 0.6776\n",
      "Epoch: 205, Loss: 0.5360, Acc: 0.6877\n",
      "Epoch: 206, Loss: 0.5410, Acc: 0.6837\n",
      "Epoch: 207, Loss: 0.5406, Acc: 0.6799\n",
      "Epoch: 208, Loss: 0.5337, Acc: 0.6816\n",
      "Epoch: 209, Loss: 0.5352, Acc: 0.6844\n",
      "Epoch: 210, Loss: 0.5403, Acc: 0.6939\n",
      "Epoch: 211, Loss: 0.5392, Acc: 0.6873\n",
      "Epoch: 212, Loss: 0.5347, Acc: 0.6854\n",
      "Epoch: 213, Loss: 0.5329, Acc: 0.6823\n",
      "Epoch: 214, Loss: 0.5401, Acc: 0.6875\n",
      "Epoch: 215, Loss: 0.5291, Acc: 0.6899\n",
      "Epoch: 216, Loss: 0.5309, Acc: 0.6863\n",
      "Epoch: 217, Loss: 0.5329, Acc: 0.6818\n",
      "Epoch: 218, Loss: 0.5381, Acc: 0.6816\n",
      "Epoch: 219, Loss: 0.5322, Acc: 0.6849\n",
      "Epoch: 220, Loss: 0.5329, Acc: 0.6778\n",
      "Epoch: 221, Loss: 0.5347, Acc: 0.6795\n",
      "Epoch: 222, Loss: 0.5364, Acc: 0.6896\n",
      "Epoch: 223, Loss: 0.5323, Acc: 0.6835\n",
      "Epoch: 224, Loss: 0.5376, Acc: 0.6851\n",
      "Epoch: 225, Loss: 0.5328, Acc: 0.6752\n",
      "Epoch: 226, Loss: 0.5376, Acc: 0.6894\n",
      "Epoch: 227, Loss: 0.5342, Acc: 0.6731\n",
      "Epoch: 228, Loss: 0.5311, Acc: 0.6809\n",
      "Epoch: 229, Loss: 0.5346, Acc: 0.6830\n",
      "Epoch: 230, Loss: 0.5279, Acc: 0.6799\n",
      "Epoch: 231, Loss: 0.5325, Acc: 0.6906\n",
      "Epoch: 232, Loss: 0.5325, Acc: 0.6911\n",
      "Epoch: 233, Loss: 0.5353, Acc: 0.6856\n",
      "Epoch: 234, Loss: 0.5311, Acc: 0.7043\n",
      "Epoch: 235, Loss: 0.5392, Acc: 0.6821\n",
      "Epoch: 236, Loss: 0.5403, Acc: 0.6856\n",
      "Epoch: 237, Loss: 0.5329, Acc: 0.6837\n",
      "Epoch: 238, Loss: 0.5363, Acc: 0.6832\n",
      "Epoch: 239, Loss: 0.5317, Acc: 0.6790\n",
      "Epoch: 240, Loss: 0.5346, Acc: 0.6752\n",
      "Epoch: 241, Loss: 0.5355, Acc: 0.6875\n",
      "Epoch: 242, Loss: 0.5321, Acc: 0.6813\n",
      "Epoch: 243, Loss: 0.5313, Acc: 0.6818\n",
      "Epoch: 244, Loss: 0.5342, Acc: 0.6795\n",
      "Epoch: 245, Loss: 0.5427, Acc: 0.6697\n",
      "Epoch: 246, Loss: 0.5403, Acc: 0.6858\n",
      "Epoch: 247, Loss: 0.5363, Acc: 0.6802\n",
      "Epoch: 248, Loss: 0.5362, Acc: 0.6813\n",
      "Epoch: 249, Loss: 0.5304, Acc: 0.6884\n",
      "Epoch: 250, Loss: 0.5377, Acc: 0.6671\n",
      "Epoch: 251, Loss: 0.5424, Acc: 0.6880\n",
      "Epoch: 252, Loss: 0.5371, Acc: 0.6750\n",
      "Epoch: 253, Loss: 0.5349, Acc: 0.6818\n",
      "Epoch: 254, Loss: 0.5374, Acc: 0.6828\n",
      "Epoch: 255, Loss: 0.5380, Acc: 0.6726\n",
      "Epoch: 256, Loss: 0.5377, Acc: 0.6844\n",
      "Epoch: 257, Loss: 0.5317, Acc: 0.6901\n",
      "Epoch: 258, Loss: 0.5335, Acc: 0.6915\n",
      "Epoch: 259, Loss: 0.5328, Acc: 0.6823\n",
      "Epoch: 260, Loss: 0.5315, Acc: 0.6851\n",
      "Epoch: 261, Loss: 0.5326, Acc: 0.6721\n",
      "Epoch: 262, Loss: 0.5327, Acc: 0.6825\n",
      "Epoch: 263, Loss: 0.5342, Acc: 0.6806\n",
      "Epoch: 264, Loss: 0.5348, Acc: 0.6776\n",
      "Epoch: 265, Loss: 0.5348, Acc: 0.6750\n",
      "Epoch: 266, Loss: 0.5338, Acc: 0.6825\n",
      "Epoch: 267, Loss: 0.5338, Acc: 0.6714\n",
      "Epoch: 268, Loss: 0.5301, Acc: 0.6766\n",
      "Epoch: 269, Loss: 0.5306, Acc: 0.6797\n",
      "Epoch: 270, Loss: 0.5368, Acc: 0.6783\n",
      "Epoch: 271, Loss: 0.5376, Acc: 0.6825\n",
      "Epoch: 272, Loss: 0.5373, Acc: 0.6773\n",
      "Epoch: 273, Loss: 0.5329, Acc: 0.6861\n",
      "Epoch: 274, Loss: 0.5348, Acc: 0.6733\n",
      "Epoch: 275, Loss: 0.5324, Acc: 0.6816\n",
      "Epoch: 276, Loss: 0.5331, Acc: 0.6821\n",
      "Epoch: 277, Loss: 0.5324, Acc: 0.6832\n",
      "Epoch: 278, Loss: 0.5386, Acc: 0.6731\n",
      "Epoch: 279, Loss: 0.5324, Acc: 0.6887\n",
      "Epoch: 280, Loss: 0.5367, Acc: 0.6861\n",
      "Epoch: 281, Loss: 0.5299, Acc: 0.6821\n",
      "Epoch: 282, Loss: 0.5271, Acc: 0.6757\n",
      "Epoch: 283, Loss: 0.5357, Acc: 0.6716\n",
      "Epoch: 284, Loss: 0.5377, Acc: 0.6837\n",
      "Epoch: 285, Loss: 0.5313, Acc: 0.6790\n",
      "Epoch: 286, Loss: 0.5332, Acc: 0.6783\n",
      "Epoch: 287, Loss: 0.5316, Acc: 0.6809\n",
      "Epoch: 288, Loss: 0.5292, Acc: 0.6839\n",
      "Epoch: 289, Loss: 0.5350, Acc: 0.6686\n",
      "Epoch: 290, Loss: 0.5293, Acc: 0.6787\n",
      "Epoch: 291, Loss: 0.5373, Acc: 0.6721\n",
      "Epoch: 292, Loss: 0.5336, Acc: 0.6892\n",
      "Epoch: 293, Loss: 0.5322, Acc: 0.6693\n",
      "Epoch: 294, Loss: 0.5346, Acc: 0.6854\n",
      "Epoch: 295, Loss: 0.5310, Acc: 0.6842\n",
      "Epoch: 296, Loss: 0.5329, Acc: 0.6745\n",
      "Epoch: 297, Loss: 0.5365, Acc: 0.6735\n",
      "Epoch: 298, Loss: 0.5391, Acc: 0.6712\n",
      "Epoch: 299, Loss: 0.5334, Acc: 0.6811\n",
      "Epoch: 300, Loss: 0.5323, Acc: 0.6797\n",
      "Epoch: 301, Loss: 0.5339, Acc: 0.6882\n",
      "Epoch: 302, Loss: 0.5305, Acc: 0.6839\n",
      "Epoch: 303, Loss: 0.5398, Acc: 0.6797\n",
      "Epoch: 304, Loss: 0.5379, Acc: 0.6761\n",
      "Epoch: 305, Loss: 0.5382, Acc: 0.6802\n",
      "Epoch: 306, Loss: 0.5304, Acc: 0.6823\n",
      "Epoch: 307, Loss: 0.5331, Acc: 0.6804\n",
      "Epoch: 308, Loss: 0.5371, Acc: 0.6740\n",
      "Epoch: 309, Loss: 0.5357, Acc: 0.6847\n",
      "Epoch: 310, Loss: 0.5368, Acc: 0.6792\n",
      "Epoch: 311, Loss: 0.5366, Acc: 0.6844\n",
      "Epoch: 312, Loss: 0.5346, Acc: 0.6875\n",
      "Epoch: 313, Loss: 0.5338, Acc: 0.6778\n",
      "Epoch: 314, Loss: 0.5365, Acc: 0.6771\n",
      "Epoch: 315, Loss: 0.5347, Acc: 0.6792\n",
      "Epoch: 316, Loss: 0.5339, Acc: 0.6702\n",
      "Epoch: 317, Loss: 0.5326, Acc: 0.6816\n",
      "Epoch: 318, Loss: 0.5370, Acc: 0.6686\n",
      "Epoch: 319, Loss: 0.5380, Acc: 0.6792\n",
      "Epoch: 320, Loss: 0.5392, Acc: 0.6695\n",
      "Epoch: 321, Loss: 0.5346, Acc: 0.6828\n",
      "Epoch: 322, Loss: 0.5336, Acc: 0.6797\n",
      "Epoch: 323, Loss: 0.5373, Acc: 0.6742\n",
      "Epoch: 324, Loss: 0.5368, Acc: 0.6908\n",
      "Epoch: 325, Loss: 0.5316, Acc: 0.6818\n",
      "Epoch: 326, Loss: 0.5348, Acc: 0.6761\n",
      "Epoch: 327, Loss: 0.5330, Acc: 0.6740\n",
      "Epoch: 328, Loss: 0.5336, Acc: 0.6731\n",
      "Epoch: 329, Loss: 0.5347, Acc: 0.6783\n",
      "Epoch: 330, Loss: 0.5312, Acc: 0.6792\n",
      "Epoch: 331, Loss: 0.5386, Acc: 0.6842\n",
      "Epoch: 332, Loss: 0.5366, Acc: 0.6747\n",
      "Epoch: 333, Loss: 0.5344, Acc: 0.6797\n",
      "Epoch: 334, Loss: 0.5347, Acc: 0.6716\n",
      "Epoch: 335, Loss: 0.5305, Acc: 0.6721\n",
      "Epoch: 336, Loss: 0.5342, Acc: 0.6752\n",
      "Epoch: 337, Loss: 0.5332, Acc: 0.6752\n",
      "Epoch: 338, Loss: 0.5325, Acc: 0.6766\n",
      "Epoch: 339, Loss: 0.5336, Acc: 0.6792\n",
      "Epoch: 340, Loss: 0.5369, Acc: 0.6697\n",
      "Epoch: 341, Loss: 0.5348, Acc: 0.6776\n",
      "Epoch: 342, Loss: 0.5408, Acc: 0.6686\n",
      "Epoch: 343, Loss: 0.5336, Acc: 0.6795\n",
      "Epoch: 344, Loss: 0.5363, Acc: 0.6830\n",
      "Epoch: 345, Loss: 0.5337, Acc: 0.6804\n",
      "Epoch: 346, Loss: 0.5342, Acc: 0.6773\n",
      "Epoch: 347, Loss: 0.5358, Acc: 0.6723\n",
      "Epoch: 348, Loss: 0.5346, Acc: 0.6761\n",
      "Epoch: 349, Loss: 0.5297, Acc: 0.6773\n",
      "Epoch: 350, Loss: 0.5310, Acc: 0.6716\n",
      "Epoch: 351, Loss: 0.5339, Acc: 0.6768\n",
      "Epoch: 352, Loss: 0.5380, Acc: 0.6707\n",
      "Epoch: 353, Loss: 0.5378, Acc: 0.6771\n",
      "Epoch: 354, Loss: 0.5392, Acc: 0.6880\n",
      "Epoch: 355, Loss: 0.5305, Acc: 0.6785\n",
      "Epoch: 356, Loss: 0.5365, Acc: 0.6754\n",
      "Epoch: 357, Loss: 0.5346, Acc: 0.6778\n",
      "Epoch: 358, Loss: 0.5327, Acc: 0.6783\n",
      "Epoch: 359, Loss: 0.5345, Acc: 0.6778\n",
      "Epoch: 360, Loss: 0.5338, Acc: 0.6778\n",
      "Epoch: 361, Loss: 0.5391, Acc: 0.6766\n",
      "Epoch: 362, Loss: 0.5355, Acc: 0.6768\n",
      "Epoch: 363, Loss: 0.5322, Acc: 0.6778\n",
      "Epoch: 364, Loss: 0.5348, Acc: 0.6776\n",
      "Epoch: 365, Loss: 0.5272, Acc: 0.6768\n",
      "Epoch: 366, Loss: 0.5351, Acc: 0.6806\n",
      "Epoch: 367, Loss: 0.5348, Acc: 0.6842\n",
      "Epoch: 368, Loss: 0.5291, Acc: 0.6863\n",
      "Epoch: 369, Loss: 0.5329, Acc: 0.6728\n",
      "Epoch: 370, Loss: 0.5299, Acc: 0.6714\n",
      "Epoch: 371, Loss: 0.5320, Acc: 0.6830\n",
      "Epoch: 372, Loss: 0.5304, Acc: 0.6702\n",
      "Epoch: 373, Loss: 0.5321, Acc: 0.6780\n",
      "Epoch: 374, Loss: 0.5330, Acc: 0.6752\n",
      "Epoch: 375, Loss: 0.5293, Acc: 0.6731\n",
      "Epoch: 376, Loss: 0.5326, Acc: 0.6806\n",
      "Epoch: 377, Loss: 0.5336, Acc: 0.6733\n",
      "Epoch: 378, Loss: 0.5342, Acc: 0.6716\n",
      "Epoch: 379, Loss: 0.5337, Acc: 0.6631\n",
      "Epoch: 380, Loss: 0.5333, Acc: 0.6735\n",
      "Epoch: 381, Loss: 0.5334, Acc: 0.6662\n",
      "Epoch: 382, Loss: 0.5301, Acc: 0.6721\n",
      "Epoch: 383, Loss: 0.5321, Acc: 0.6719\n",
      "Epoch: 384, Loss: 0.5366, Acc: 0.6747\n",
      "Epoch: 385, Loss: 0.5299, Acc: 0.6740\n",
      "Epoch: 386, Loss: 0.5296, Acc: 0.6686\n",
      "Epoch: 387, Loss: 0.5324, Acc: 0.6797\n",
      "Epoch: 388, Loss: 0.5363, Acc: 0.6825\n",
      "Epoch: 389, Loss: 0.5318, Acc: 0.6861\n",
      "Epoch: 390, Loss: 0.5285, Acc: 0.6733\n",
      "Epoch: 391, Loss: 0.5311, Acc: 0.6754\n",
      "Epoch: 392, Loss: 0.5309, Acc: 0.6705\n",
      "Epoch: 393, Loss: 0.5346, Acc: 0.6768\n",
      "Epoch: 394, Loss: 0.5341, Acc: 0.6761\n",
      "Epoch: 395, Loss: 0.5288, Acc: 0.6783\n",
      "Epoch: 396, Loss: 0.5297, Acc: 0.6776\n",
      "Epoch: 397, Loss: 0.5327, Acc: 0.6780\n",
      "Epoch: 398, Loss: 0.5349, Acc: 0.6750\n",
      "Epoch: 399, Loss: 0.5269, Acc: 0.6768\n",
      "Epoch: 400, Loss: 0.5325, Acc: 0.6828\n",
      "Epoch: 401, Loss: 0.5385, Acc: 0.6884\n",
      "Epoch: 402, Loss: 0.5339, Acc: 0.6742\n",
      "Epoch: 403, Loss: 0.5333, Acc: 0.6679\n",
      "Epoch: 404, Loss: 0.5300, Acc: 0.6773\n",
      "Epoch: 405, Loss: 0.5328, Acc: 0.6674\n",
      "Epoch: 406, Loss: 0.5372, Acc: 0.6806\n",
      "Epoch: 407, Loss: 0.5291, Acc: 0.6702\n",
      "Epoch: 408, Loss: 0.5342, Acc: 0.6669\n",
      "Epoch: 409, Loss: 0.5304, Acc: 0.6778\n",
      "Epoch: 410, Loss: 0.5367, Acc: 0.6626\n",
      "Epoch: 411, Loss: 0.5422, Acc: 0.6771\n",
      "Epoch: 412, Loss: 0.5470, Acc: 0.6586\n",
      "Epoch: 413, Loss: 0.5394, Acc: 0.6752\n",
      "Epoch: 414, Loss: 0.5382, Acc: 0.6799\n",
      "Epoch: 415, Loss: 0.5366, Acc: 0.6615\n",
      "Epoch: 416, Loss: 0.5425, Acc: 0.6754\n",
      "Epoch: 417, Loss: 0.5390, Acc: 0.6750\n",
      "Epoch: 418, Loss: 0.5339, Acc: 0.6629\n",
      "Epoch: 419, Loss: 0.5369, Acc: 0.6731\n",
      "Epoch: 420, Loss: 0.5478, Acc: 0.6662\n",
      "Epoch: 421, Loss: 0.5282, Acc: 0.6681\n",
      "Epoch: 422, Loss: 0.5353, Acc: 0.6742\n",
      "Epoch: 423, Loss: 0.5381, Acc: 0.6735\n",
      "Epoch: 424, Loss: 0.5327, Acc: 0.6674\n",
      "Epoch: 425, Loss: 0.5346, Acc: 0.6716\n",
      "Epoch: 426, Loss: 0.5321, Acc: 0.6787\n",
      "Epoch: 427, Loss: 0.5352, Acc: 0.6648\n",
      "Epoch: 428, Loss: 0.5310, Acc: 0.6768\n",
      "Epoch: 429, Loss: 0.5362, Acc: 0.6752\n",
      "Epoch: 430, Loss: 0.5369, Acc: 0.6735\n",
      "Epoch: 431, Loss: 0.5374, Acc: 0.6700\n",
      "Epoch: 432, Loss: 0.5375, Acc: 0.6785\n",
      "Epoch: 433, Loss: 0.5347, Acc: 0.6766\n",
      "Epoch: 434, Loss: 0.5382, Acc: 0.6676\n",
      "Epoch: 435, Loss: 0.5352, Acc: 0.6771\n",
      "Epoch: 436, Loss: 0.5314, Acc: 0.6688\n",
      "Epoch: 437, Loss: 0.5305, Acc: 0.6854\n",
      "Epoch: 438, Loss: 0.5346, Acc: 0.6780\n",
      "Epoch: 439, Loss: 0.5339, Acc: 0.6679\n",
      "Epoch: 440, Loss: 0.5319, Acc: 0.6707\n",
      "Epoch: 441, Loss: 0.5384, Acc: 0.6728\n",
      "Epoch: 442, Loss: 0.5314, Acc: 0.6707\n",
      "Epoch: 443, Loss: 0.5356, Acc: 0.6747\n",
      "Epoch: 444, Loss: 0.5258, Acc: 0.6728\n",
      "Epoch: 445, Loss: 0.5355, Acc: 0.6806\n",
      "Epoch: 446, Loss: 0.5365, Acc: 0.6847\n",
      "Epoch: 447, Loss: 0.5293, Acc: 0.6688\n",
      "Epoch: 448, Loss: 0.5303, Acc: 0.6731\n",
      "Epoch: 449, Loss: 0.5316, Acc: 0.6757\n",
      "Epoch: 450, Loss: 0.5310, Acc: 0.6738\n",
      "Epoch: 451, Loss: 0.5298, Acc: 0.6776\n",
      "Epoch: 452, Loss: 0.5321, Acc: 0.6764\n",
      "Epoch: 453, Loss: 0.5287, Acc: 0.6671\n",
      "Epoch: 454, Loss: 0.5320, Acc: 0.6669\n",
      "Epoch: 455, Loss: 0.5295, Acc: 0.6655\n",
      "Epoch: 456, Loss: 0.5298, Acc: 0.6669\n",
      "Epoch: 457, Loss: 0.5309, Acc: 0.6787\n",
      "Epoch: 458, Loss: 0.5299, Acc: 0.6752\n",
      "Epoch: 459, Loss: 0.5311, Acc: 0.6785\n",
      "Epoch: 460, Loss: 0.5339, Acc: 0.6830\n",
      "Epoch: 461, Loss: 0.5333, Acc: 0.6790\n",
      "Epoch: 462, Loss: 0.5354, Acc: 0.6839\n",
      "Epoch: 463, Loss: 0.5366, Acc: 0.6695\n",
      "Epoch: 464, Loss: 0.5328, Acc: 0.6681\n",
      "Epoch: 465, Loss: 0.5297, Acc: 0.6712\n",
      "Epoch: 466, Loss: 0.5349, Acc: 0.6705\n",
      "Epoch: 467, Loss: 0.5325, Acc: 0.6797\n",
      "Epoch: 468, Loss: 0.5347, Acc: 0.6735\n",
      "Epoch: 469, Loss: 0.5298, Acc: 0.6700\n",
      "Epoch: 470, Loss: 0.5333, Acc: 0.6842\n",
      "Epoch: 471, Loss: 0.5350, Acc: 0.6761\n",
      "Epoch: 472, Loss: 0.5325, Acc: 0.6757\n",
      "Epoch: 473, Loss: 0.5322, Acc: 0.6768\n",
      "Epoch: 474, Loss: 0.5333, Acc: 0.6676\n",
      "Epoch: 475, Loss: 0.5288, Acc: 0.6712\n",
      "Epoch: 476, Loss: 0.5309, Acc: 0.6792\n",
      "Epoch: 477, Loss: 0.5312, Acc: 0.6728\n",
      "Epoch: 478, Loss: 0.5362, Acc: 0.6738\n",
      "Epoch: 479, Loss: 0.5357, Acc: 0.6757\n",
      "Epoch: 480, Loss: 0.5342, Acc: 0.6693\n",
      "Epoch: 481, Loss: 0.5313, Acc: 0.6790\n",
      "Epoch: 482, Loss: 0.5306, Acc: 0.6856\n",
      "Epoch: 483, Loss: 0.5288, Acc: 0.6776\n",
      "Epoch: 484, Loss: 0.5339, Acc: 0.6761\n",
      "Epoch: 485, Loss: 0.5316, Acc: 0.6750\n",
      "Epoch: 486, Loss: 0.5292, Acc: 0.6752\n",
      "Epoch: 487, Loss: 0.5349, Acc: 0.6669\n",
      "Epoch: 488, Loss: 0.5392, Acc: 0.6695\n",
      "Epoch: 489, Loss: 0.5337, Acc: 0.6764\n",
      "Epoch: 490, Loss: 0.5308, Acc: 0.6752\n",
      "Epoch: 491, Loss: 0.5350, Acc: 0.6787\n",
      "Epoch: 492, Loss: 0.5309, Acc: 0.6742\n",
      "Epoch: 493, Loss: 0.5320, Acc: 0.6664\n",
      "Epoch: 494, Loss: 0.5289, Acc: 0.6740\n",
      "Epoch: 495, Loss: 0.5305, Acc: 0.6650\n",
      "Epoch: 496, Loss: 0.5336, Acc: 0.6652\n",
      "Epoch: 497, Loss: 0.5352, Acc: 0.6783\n",
      "Epoch: 498, Loss: 0.5266, Acc: 0.6776\n",
      "Epoch: 499, Loss: 0.5406, Acc: 0.6600\n",
      "Epoch: 500, Loss: 0.5385, Acc: 0.6709\n",
      "Epoch: 501, Loss: 0.5410, Acc: 0.6771\n",
      "Epoch: 502, Loss: 0.5317, Acc: 0.6603\n",
      "Epoch: 503, Loss: 0.5395, Acc: 0.6771\n",
      "Epoch: 504, Loss: 0.5364, Acc: 0.6693\n",
      "Epoch: 505, Loss: 0.5329, Acc: 0.6671\n",
      "Epoch: 506, Loss: 0.5372, Acc: 0.6771\n",
      "Epoch: 507, Loss: 0.5384, Acc: 0.6716\n",
      "Epoch: 508, Loss: 0.5312, Acc: 0.6600\n",
      "Epoch: 509, Loss: 0.5396, Acc: 0.6676\n",
      "Epoch: 510, Loss: 0.5433, Acc: 0.6714\n",
      "Epoch: 511, Loss: 0.5341, Acc: 0.6702\n",
      "Epoch: 512, Loss: 0.5358, Acc: 0.6709\n",
      "Epoch: 513, Loss: 0.5430, Acc: 0.6676\n",
      "Epoch: 514, Loss: 0.5292, Acc: 0.6624\n",
      "Epoch: 515, Loss: 0.5397, Acc: 0.6723\n",
      "Epoch: 516, Loss: 0.5383, Acc: 0.6932\n",
      "Epoch: 517, Loss: 0.5374, Acc: 0.6610\n",
      "Epoch: 518, Loss: 0.5453, Acc: 0.6723\n",
      "Epoch: 519, Loss: 0.5377, Acc: 0.6643\n",
      "Epoch: 520, Loss: 0.5359, Acc: 0.6577\n",
      "Epoch: 521, Loss: 0.5386, Acc: 0.6795\n",
      "Epoch: 522, Loss: 0.5329, Acc: 0.6735\n",
      "Epoch: 523, Loss: 0.5347, Acc: 0.6671\n",
      "Epoch: 524, Loss: 0.5318, Acc: 0.6693\n",
      "Epoch: 525, Loss: 0.5322, Acc: 0.6787\n",
      "Epoch: 526, Loss: 0.5362, Acc: 0.6780\n",
      "Epoch: 527, Loss: 0.5363, Acc: 0.6700\n",
      "Epoch: 528, Loss: 0.5288, Acc: 0.6873\n",
      "Epoch: 529, Loss: 0.5323, Acc: 0.6726\n",
      "Epoch: 530, Loss: 0.5334, Acc: 0.6655\n",
      "Epoch: 531, Loss: 0.5386, Acc: 0.6766\n",
      "Epoch: 532, Loss: 0.5350, Acc: 0.6792\n",
      "Epoch: 533, Loss: 0.5248, Acc: 0.6702\n",
      "Epoch: 534, Loss: 0.5330, Acc: 0.6832\n",
      "Epoch: 535, Loss: 0.5305, Acc: 0.6813\n",
      "Epoch: 536, Loss: 0.5297, Acc: 0.6716\n",
      "Epoch: 537, Loss: 0.5282, Acc: 0.6759\n",
      "Epoch: 538, Loss: 0.5327, Acc: 0.6750\n",
      "Epoch: 539, Loss: 0.5384, Acc: 0.6619\n",
      "Epoch: 540, Loss: 0.5356, Acc: 0.6740\n",
      "Epoch: 541, Loss: 0.5347, Acc: 0.6735\n",
      "Epoch: 542, Loss: 0.5321, Acc: 0.6596\n",
      "Epoch: 543, Loss: 0.5376, Acc: 0.6858\n",
      "Epoch: 544, Loss: 0.5361, Acc: 0.6674\n",
      "Epoch: 545, Loss: 0.5324, Acc: 0.6676\n",
      "Epoch: 546, Loss: 0.5359, Acc: 0.6615\n",
      "Epoch: 547, Loss: 0.5306, Acc: 0.6716\n",
      "Epoch: 548, Loss: 0.5374, Acc: 0.6667\n",
      "Epoch: 549, Loss: 0.5389, Acc: 0.6709\n",
      "Epoch: 550, Loss: 0.5319, Acc: 0.6771\n",
      "Epoch: 551, Loss: 0.5300, Acc: 0.6716\n",
      "Epoch: 552, Loss: 0.5356, Acc: 0.6830\n",
      "Epoch: 553, Loss: 0.5343, Acc: 0.6809\n",
      "Epoch: 554, Loss: 0.5328, Acc: 0.6750\n",
      "Epoch: 555, Loss: 0.5371, Acc: 0.6714\n",
      "Epoch: 556, Loss: 0.5286, Acc: 0.6823\n",
      "Epoch: 557, Loss: 0.5350, Acc: 0.6738\n",
      "Epoch: 558, Loss: 0.5333, Acc: 0.6776\n",
      "Epoch: 559, Loss: 0.5273, Acc: 0.6806\n",
      "Epoch: 560, Loss: 0.5320, Acc: 0.6740\n",
      "Epoch: 561, Loss: 0.5327, Acc: 0.6690\n",
      "Epoch: 562, Loss: 0.5375, Acc: 0.6733\n",
      "Epoch: 563, Loss: 0.5317, Acc: 0.6688\n",
      "Epoch: 564, Loss: 0.5290, Acc: 0.6745\n",
      "Epoch: 565, Loss: 0.5370, Acc: 0.6747\n",
      "Epoch: 566, Loss: 0.5309, Acc: 0.6697\n",
      "Epoch: 567, Loss: 0.5291, Acc: 0.6683\n",
      "Epoch: 568, Loss: 0.5300, Acc: 0.6726\n",
      "Epoch: 569, Loss: 0.5277, Acc: 0.6719\n",
      "Epoch: 570, Loss: 0.5293, Acc: 0.6721\n",
      "Epoch: 571, Loss: 0.5322, Acc: 0.6813\n",
      "Epoch: 572, Loss: 0.5344, Acc: 0.6726\n",
      "Epoch: 573, Loss: 0.5302, Acc: 0.6858\n",
      "Epoch: 574, Loss: 0.5278, Acc: 0.6768\n",
      "Epoch: 575, Loss: 0.5321, Acc: 0.6816\n",
      "Epoch: 576, Loss: 0.5292, Acc: 0.6660\n",
      "Epoch: 577, Loss: 0.5308, Acc: 0.6728\n",
      "Epoch: 578, Loss: 0.5315, Acc: 0.6735\n",
      "Epoch: 579, Loss: 0.5305, Acc: 0.6842\n",
      "Epoch: 580, Loss: 0.5284, Acc: 0.6733\n",
      "Epoch: 581, Loss: 0.5239, Acc: 0.6726\n",
      "Epoch: 582, Loss: 0.5317, Acc: 0.6790\n",
      "Epoch: 583, Loss: 0.5323, Acc: 0.6809\n",
      "Epoch: 584, Loss: 0.5285, Acc: 0.6731\n",
      "Epoch: 585, Loss: 0.5317, Acc: 0.6674\n",
      "Epoch: 586, Loss: 0.5360, Acc: 0.6716\n",
      "Epoch: 587, Loss: 0.5303, Acc: 0.6610\n",
      "Epoch: 588, Loss: 0.5300, Acc: 0.6662\n",
      "Epoch: 589, Loss: 0.5319, Acc: 0.6783\n",
      "Epoch: 590, Loss: 0.5350, Acc: 0.6858\n",
      "Epoch: 591, Loss: 0.5310, Acc: 0.6828\n",
      "Epoch: 592, Loss: 0.5289, Acc: 0.6716\n",
      "Epoch: 593, Loss: 0.5294, Acc: 0.6839\n",
      "Epoch: 594, Loss: 0.5329, Acc: 0.6681\n",
      "Epoch: 595, Loss: 0.5371, Acc: 0.6733\n",
      "Epoch: 596, Loss: 0.5336, Acc: 0.6747\n",
      "Epoch: 597, Loss: 0.5301, Acc: 0.6785\n",
      "Epoch: 598, Loss: 0.5345, Acc: 0.6681\n",
      "Epoch: 599, Loss: 0.5338, Acc: 0.6721\n",
      "Epoch: 600, Loss: 0.5333, Acc: 0.6778\n",
      "Epoch: 601, Loss: 0.5300, Acc: 0.6690\n",
      "Epoch: 602, Loss: 0.5311, Acc: 0.6806\n",
      "Epoch: 603, Loss: 0.5337, Acc: 0.6776\n",
      "Epoch: 604, Loss: 0.5264, Acc: 0.6655\n",
      "Epoch: 605, Loss: 0.5291, Acc: 0.6605\n",
      "Epoch: 606, Loss: 0.5383, Acc: 0.6709\n",
      "Epoch: 607, Loss: 0.5308, Acc: 0.6688\n",
      "Epoch: 608, Loss: 0.5301, Acc: 0.6636\n",
      "Epoch: 609, Loss: 0.5296, Acc: 0.6686\n",
      "Epoch: 610, Loss: 0.5284, Acc: 0.6607\n",
      "Epoch: 611, Loss: 0.5320, Acc: 0.6636\n",
      "Epoch: 612, Loss: 0.5320, Acc: 0.6719\n",
      "Epoch: 613, Loss: 0.5295, Acc: 0.6757\n",
      "Epoch: 614, Loss: 0.5354, Acc: 0.6809\n",
      "Epoch: 615, Loss: 0.5327, Acc: 0.6792\n",
      "Epoch: 616, Loss: 0.5338, Acc: 0.6686\n",
      "Epoch: 617, Loss: 0.5357, Acc: 0.6792\n",
      "Epoch: 618, Loss: 0.5333, Acc: 0.6821\n",
      "Epoch: 619, Loss: 0.5375, Acc: 0.6645\n",
      "Epoch: 620, Loss: 0.5333, Acc: 0.6776\n",
      "Epoch: 621, Loss: 0.5300, Acc: 0.6754\n",
      "Epoch: 622, Loss: 0.5272, Acc: 0.6726\n",
      "Epoch: 623, Loss: 0.5313, Acc: 0.6773\n",
      "Epoch: 624, Loss: 0.5303, Acc: 0.6716\n",
      "Epoch: 625, Loss: 0.5290, Acc: 0.6709\n",
      "Epoch: 626, Loss: 0.5343, Acc: 0.6787\n",
      "Epoch: 627, Loss: 0.5269, Acc: 0.6726\n",
      "Epoch: 628, Loss: 0.5310, Acc: 0.6664\n",
      "Epoch: 629, Loss: 0.5326, Acc: 0.6591\n",
      "Epoch: 630, Loss: 0.5295, Acc: 0.6733\n",
      "Epoch: 631, Loss: 0.5358, Acc: 0.6693\n",
      "Epoch: 632, Loss: 0.5297, Acc: 0.6757\n",
      "Epoch: 633, Loss: 0.5355, Acc: 0.6683\n",
      "Epoch: 634, Loss: 0.5276, Acc: 0.6716\n",
      "Epoch: 635, Loss: 0.5295, Acc: 0.6731\n",
      "Epoch: 636, Loss: 0.5258, Acc: 0.6723\n",
      "Epoch: 637, Loss: 0.5348, Acc: 0.6764\n",
      "Epoch: 638, Loss: 0.5360, Acc: 0.6795\n",
      "Epoch: 639, Loss: 0.5322, Acc: 0.6771\n",
      "Epoch: 640, Loss: 0.5338, Acc: 0.6785\n",
      "Epoch: 641, Loss: 0.5341, Acc: 0.6752\n",
      "Epoch: 642, Loss: 0.5265, Acc: 0.6728\n",
      "Epoch: 643, Loss: 0.5331, Acc: 0.6671\n",
      "Epoch: 644, Loss: 0.5324, Acc: 0.6792\n",
      "Epoch: 645, Loss: 0.5356, Acc: 0.6705\n",
      "Epoch: 646, Loss: 0.5294, Acc: 0.6728\n",
      "Epoch: 647, Loss: 0.5319, Acc: 0.6726\n",
      "Epoch: 648, Loss: 0.5309, Acc: 0.6719\n",
      "Epoch: 649, Loss: 0.5336, Acc: 0.6804\n",
      "Epoch: 650, Loss: 0.5307, Acc: 0.6742\n",
      "Epoch: 651, Loss: 0.5276, Acc: 0.6683\n",
      "Epoch: 652, Loss: 0.5293, Acc: 0.6735\n",
      "Epoch: 653, Loss: 0.5334, Acc: 0.6747\n",
      "Epoch: 654, Loss: 0.5318, Acc: 0.6674\n",
      "Epoch: 655, Loss: 0.5345, Acc: 0.6615\n",
      "Epoch: 656, Loss: 0.5306, Acc: 0.6787\n",
      "Epoch: 657, Loss: 0.5298, Acc: 0.6738\n",
      "Epoch: 658, Loss: 0.5307, Acc: 0.6693\n",
      "Epoch: 659, Loss: 0.5312, Acc: 0.6636\n",
      "Epoch: 660, Loss: 0.5346, Acc: 0.6719\n",
      "Epoch: 661, Loss: 0.5303, Acc: 0.6776\n",
      "Epoch: 662, Loss: 0.5313, Acc: 0.6636\n",
      "Epoch: 663, Loss: 0.5272, Acc: 0.6607\n",
      "Epoch: 664, Loss: 0.5351, Acc: 0.6577\n",
      "Epoch: 665, Loss: 0.5262, Acc: 0.6702\n",
      "Epoch: 666, Loss: 0.5282, Acc: 0.6712\n",
      "Epoch: 667, Loss: 0.5305, Acc: 0.6655\n",
      "Epoch: 668, Loss: 0.5310, Acc: 0.6764\n",
      "Epoch: 669, Loss: 0.5303, Acc: 0.6707\n",
      "Epoch: 670, Loss: 0.5335, Acc: 0.6745\n",
      "Epoch: 671, Loss: 0.5276, Acc: 0.6731\n",
      "Epoch: 672, Loss: 0.5281, Acc: 0.6783\n",
      "Epoch: 673, Loss: 0.5294, Acc: 0.6766\n",
      "Epoch: 674, Loss: 0.5256, Acc: 0.6747\n",
      "Epoch: 675, Loss: 0.5271, Acc: 0.6778\n",
      "Epoch: 676, Loss: 0.5269, Acc: 0.6716\n",
      "Epoch: 677, Loss: 0.5316, Acc: 0.6629\n",
      "Epoch: 678, Loss: 0.5276, Acc: 0.6757\n",
      "Epoch: 679, Loss: 0.5352, Acc: 0.6577\n",
      "Epoch: 680, Loss: 0.5379, Acc: 0.6667\n",
      "Epoch: 681, Loss: 0.5367, Acc: 0.6650\n",
      "Epoch: 682, Loss: 0.5300, Acc: 0.6752\n",
      "Epoch: 683, Loss: 0.5288, Acc: 0.6702\n",
      "Epoch: 684, Loss: 0.5281, Acc: 0.6742\n",
      "Epoch: 685, Loss: 0.5343, Acc: 0.6723\n",
      "Epoch: 686, Loss: 0.5315, Acc: 0.6671\n",
      "Epoch: 687, Loss: 0.5276, Acc: 0.6695\n",
      "Epoch: 688, Loss: 0.5330, Acc: 0.6664\n",
      "Epoch: 689, Loss: 0.5355, Acc: 0.6735\n",
      "Epoch: 690, Loss: 0.5345, Acc: 0.6676\n",
      "Epoch: 691, Loss: 0.5322, Acc: 0.6693\n",
      "Epoch: 692, Loss: 0.5272, Acc: 0.6752\n",
      "Epoch: 693, Loss: 0.5288, Acc: 0.6709\n",
      "Epoch: 694, Loss: 0.5311, Acc: 0.6652\n",
      "Epoch: 695, Loss: 0.5316, Acc: 0.6700\n",
      "Epoch: 696, Loss: 0.5320, Acc: 0.6712\n",
      "Epoch: 697, Loss: 0.5300, Acc: 0.6773\n",
      "Epoch: 698, Loss: 0.5324, Acc: 0.6804\n",
      "Epoch: 699, Loss: 0.5395, Acc: 0.6714\n",
      "Epoch: 700, Loss: 0.5315, Acc: 0.6714\n",
      "Epoch: 701, Loss: 0.5315, Acc: 0.6676\n",
      "Epoch: 702, Loss: 0.5349, Acc: 0.6610\n",
      "Epoch: 703, Loss: 0.5301, Acc: 0.6752\n",
      "Epoch: 704, Loss: 0.5318, Acc: 0.6657\n",
      "Epoch: 705, Loss: 0.5330, Acc: 0.6655\n",
      "Epoch: 706, Loss: 0.5377, Acc: 0.6726\n",
      "Epoch: 707, Loss: 0.5343, Acc: 0.6768\n",
      "Epoch: 708, Loss: 0.5329, Acc: 0.6723\n",
      "Epoch: 709, Loss: 0.5296, Acc: 0.6738\n",
      "Epoch: 710, Loss: 0.5312, Acc: 0.6768\n",
      "Epoch: 711, Loss: 0.5311, Acc: 0.6761\n",
      "Epoch: 712, Loss: 0.5327, Acc: 0.6766\n",
      "Epoch: 713, Loss: 0.5281, Acc: 0.6757\n",
      "Epoch: 714, Loss: 0.5333, Acc: 0.6643\n",
      "Epoch: 715, Loss: 0.5328, Acc: 0.6707\n",
      "Epoch: 716, Loss: 0.5310, Acc: 0.6603\n",
      "Epoch: 717, Loss: 0.5333, Acc: 0.6636\n",
      "Epoch: 718, Loss: 0.5328, Acc: 0.6662\n",
      "Epoch: 719, Loss: 0.5325, Acc: 0.6839\n",
      "Epoch: 720, Loss: 0.5311, Acc: 0.6797\n",
      "Epoch: 721, Loss: 0.5349, Acc: 0.6681\n",
      "Epoch: 722, Loss: 0.5333, Acc: 0.6683\n",
      "Epoch: 723, Loss: 0.5300, Acc: 0.6723\n",
      "Epoch: 724, Loss: 0.5322, Acc: 0.6707\n",
      "Epoch: 725, Loss: 0.5306, Acc: 0.6745\n",
      "Epoch: 726, Loss: 0.5278, Acc: 0.6586\n",
      "Epoch: 727, Loss: 0.5321, Acc: 0.6785\n",
      "Epoch: 728, Loss: 0.5291, Acc: 0.6757\n",
      "Epoch: 729, Loss: 0.5300, Acc: 0.6754\n",
      "Epoch: 730, Loss: 0.5305, Acc: 0.6709\n",
      "Epoch: 731, Loss: 0.5284, Acc: 0.6638\n",
      "Epoch: 732, Loss: 0.5356, Acc: 0.6766\n",
      "Epoch: 733, Loss: 0.5330, Acc: 0.6634\n",
      "Epoch: 734, Loss: 0.5352, Acc: 0.6629\n",
      "Epoch: 735, Loss: 0.5283, Acc: 0.6648\n",
      "Epoch: 736, Loss: 0.5324, Acc: 0.6581\n",
      "Epoch: 737, Loss: 0.5337, Acc: 0.6716\n",
      "Epoch: 738, Loss: 0.5313, Acc: 0.6726\n",
      "Epoch: 739, Loss: 0.5277, Acc: 0.6688\n",
      "Epoch: 740, Loss: 0.5316, Acc: 0.6764\n",
      "Epoch: 741, Loss: 0.5269, Acc: 0.6771\n",
      "Epoch: 742, Loss: 0.5314, Acc: 0.6738\n",
      "Epoch: 743, Loss: 0.5316, Acc: 0.6802\n",
      "Epoch: 744, Loss: 0.5338, Acc: 0.6690\n",
      "Epoch: 745, Loss: 0.5283, Acc: 0.6802\n",
      "Epoch: 746, Loss: 0.5291, Acc: 0.6719\n",
      "Epoch: 747, Loss: 0.5261, Acc: 0.6719\n",
      "Epoch: 748, Loss: 0.5278, Acc: 0.6702\n",
      "Epoch: 749, Loss: 0.5317, Acc: 0.6806\n",
      "Epoch: 750, Loss: 0.5273, Acc: 0.6795\n",
      "Epoch: 751, Loss: 0.5318, Acc: 0.6719\n",
      "Epoch: 752, Loss: 0.5349, Acc: 0.6679\n",
      "Epoch: 753, Loss: 0.5302, Acc: 0.6629\n",
      "Epoch: 754, Loss: 0.5325, Acc: 0.6787\n",
      "Epoch: 755, Loss: 0.5262, Acc: 0.6787\n",
      "Epoch: 756, Loss: 0.5315, Acc: 0.6700\n",
      "Epoch: 757, Loss: 0.5273, Acc: 0.6719\n",
      "Epoch: 758, Loss: 0.5298, Acc: 0.6700\n",
      "Epoch: 759, Loss: 0.5347, Acc: 0.6669\n",
      "Epoch: 760, Loss: 0.5316, Acc: 0.6643\n",
      "Epoch: 761, Loss: 0.5329, Acc: 0.6728\n",
      "Epoch: 762, Loss: 0.5315, Acc: 0.6738\n",
      "Epoch: 763, Loss: 0.5319, Acc: 0.6674\n",
      "Epoch: 764, Loss: 0.5345, Acc: 0.6731\n",
      "Epoch: 765, Loss: 0.5286, Acc: 0.6723\n",
      "Epoch: 766, Loss: 0.5341, Acc: 0.6700\n",
      "Epoch: 767, Loss: 0.5329, Acc: 0.6778\n",
      "Epoch: 768, Loss: 0.5311, Acc: 0.6664\n",
      "Epoch: 769, Loss: 0.5327, Acc: 0.6785\n",
      "Epoch: 770, Loss: 0.5250, Acc: 0.6776\n",
      "Epoch: 771, Loss: 0.5312, Acc: 0.6690\n",
      "Epoch: 772, Loss: 0.5313, Acc: 0.6757\n",
      "Epoch: 773, Loss: 0.5322, Acc: 0.6728\n",
      "Epoch: 774, Loss: 0.5346, Acc: 0.6714\n",
      "Epoch: 775, Loss: 0.5333, Acc: 0.6652\n",
      "Epoch: 776, Loss: 0.5294, Acc: 0.6593\n",
      "Epoch: 777, Loss: 0.5306, Acc: 0.6771\n",
      "Epoch: 778, Loss: 0.5305, Acc: 0.6714\n",
      "Epoch: 779, Loss: 0.5286, Acc: 0.6695\n",
      "Epoch: 780, Loss: 0.5266, Acc: 0.6721\n",
      "Epoch: 781, Loss: 0.5270, Acc: 0.6778\n",
      "Epoch: 782, Loss: 0.5321, Acc: 0.6778\n",
      "Epoch: 783, Loss: 0.5334, Acc: 0.6695\n",
      "Epoch: 784, Loss: 0.5303, Acc: 0.6690\n",
      "Epoch: 785, Loss: 0.5310, Acc: 0.6643\n",
      "Epoch: 786, Loss: 0.5308, Acc: 0.6719\n",
      "Epoch: 787, Loss: 0.5288, Acc: 0.6759\n",
      "Epoch: 788, Loss: 0.5294, Acc: 0.6712\n",
      "Epoch: 789, Loss: 0.5292, Acc: 0.6686\n",
      "Epoch: 790, Loss: 0.5314, Acc: 0.6766\n",
      "Epoch: 791, Loss: 0.5307, Acc: 0.6731\n",
      "Epoch: 792, Loss: 0.5303, Acc: 0.6676\n",
      "Epoch: 793, Loss: 0.5323, Acc: 0.6667\n",
      "Epoch: 794, Loss: 0.5285, Acc: 0.6712\n",
      "Epoch: 795, Loss: 0.5323, Acc: 0.6681\n",
      "Epoch: 796, Loss: 0.5312, Acc: 0.6780\n",
      "Epoch: 797, Loss: 0.5301, Acc: 0.6719\n",
      "Epoch: 798, Loss: 0.5328, Acc: 0.6679\n",
      "Epoch: 799, Loss: 0.5287, Acc: 0.6773\n",
      "Epoch: 800, Loss: 0.5240, Acc: 0.6742\n",
      "Epoch: 801, Loss: 0.5319, Acc: 0.6660\n",
      "Epoch: 802, Loss: 0.5336, Acc: 0.6683\n",
      "Epoch: 803, Loss: 0.5298, Acc: 0.6773\n",
      "Epoch: 804, Loss: 0.5291, Acc: 0.6638\n",
      "Epoch: 805, Loss: 0.5325, Acc: 0.6764\n",
      "Epoch: 806, Loss: 0.5337, Acc: 0.6645\n",
      "Epoch: 807, Loss: 0.5338, Acc: 0.6671\n",
      "Epoch: 808, Loss: 0.5363, Acc: 0.6683\n",
      "Epoch: 809, Loss: 0.5281, Acc: 0.6733\n",
      "Epoch: 810, Loss: 0.5252, Acc: 0.6657\n",
      "Epoch: 811, Loss: 0.5361, Acc: 0.6747\n",
      "Epoch: 812, Loss: 0.5295, Acc: 0.6629\n",
      "Epoch: 813, Loss: 0.5290, Acc: 0.6669\n",
      "Epoch: 814, Loss: 0.5303, Acc: 0.6719\n",
      "Epoch: 815, Loss: 0.5352, Acc: 0.6761\n",
      "Epoch: 816, Loss: 0.5363, Acc: 0.6655\n",
      "Epoch: 817, Loss: 0.5317, Acc: 0.6705\n",
      "Epoch: 818, Loss: 0.5250, Acc: 0.6702\n",
      "Epoch: 819, Loss: 0.5293, Acc: 0.6681\n",
      "Epoch: 820, Loss: 0.5293, Acc: 0.6624\n",
      "Epoch: 821, Loss: 0.5325, Acc: 0.6662\n",
      "Epoch: 822, Loss: 0.5351, Acc: 0.6650\n",
      "Epoch: 823, Loss: 0.5340, Acc: 0.6731\n",
      "Epoch: 824, Loss: 0.5327, Acc: 0.6648\n",
      "Epoch: 825, Loss: 0.5300, Acc: 0.6662\n",
      "Epoch: 826, Loss: 0.5320, Acc: 0.6738\n",
      "Epoch: 827, Loss: 0.5315, Acc: 0.6707\n",
      "Epoch: 828, Loss: 0.5324, Acc: 0.6676\n",
      "Epoch: 829, Loss: 0.5288, Acc: 0.6669\n",
      "Epoch: 830, Loss: 0.5334, Acc: 0.6702\n",
      "Epoch: 831, Loss: 0.5251, Acc: 0.6702\n",
      "Epoch: 832, Loss: 0.5332, Acc: 0.6641\n",
      "Epoch: 833, Loss: 0.5385, Acc: 0.6693\n",
      "Epoch: 834, Loss: 0.5410, Acc: 0.6655\n",
      "Epoch: 835, Loss: 0.5376, Acc: 0.6742\n",
      "Epoch: 836, Loss: 0.5306, Acc: 0.6641\n",
      "Epoch: 837, Loss: 0.5366, Acc: 0.6688\n",
      "Epoch: 838, Loss: 0.5344, Acc: 0.6660\n",
      "Epoch: 839, Loss: 0.5349, Acc: 0.6626\n",
      "Epoch: 840, Loss: 0.5315, Acc: 0.6622\n",
      "Epoch: 841, Loss: 0.5331, Acc: 0.6712\n",
      "Epoch: 842, Loss: 0.5390, Acc: 0.6577\n",
      "Epoch: 843, Loss: 0.5314, Acc: 0.6676\n",
      "Epoch: 844, Loss: 0.5304, Acc: 0.6693\n",
      "Epoch: 845, Loss: 0.5302, Acc: 0.6667\n",
      "Epoch: 846, Loss: 0.5287, Acc: 0.6731\n",
      "Epoch: 847, Loss: 0.5313, Acc: 0.6612\n",
      "Epoch: 848, Loss: 0.5303, Acc: 0.6662\n",
      "Epoch: 849, Loss: 0.5303, Acc: 0.6828\n",
      "Epoch: 850, Loss: 0.5364, Acc: 0.6752\n",
      "Epoch: 851, Loss: 0.5326, Acc: 0.6747\n",
      "Epoch: 852, Loss: 0.5342, Acc: 0.6745\n",
      "Epoch: 853, Loss: 0.5329, Acc: 0.6742\n",
      "Epoch: 854, Loss: 0.5291, Acc: 0.6695\n",
      "Epoch: 855, Loss: 0.5349, Acc: 0.6652\n",
      "Epoch: 856, Loss: 0.5327, Acc: 0.6612\n",
      "Epoch: 857, Loss: 0.5353, Acc: 0.6615\n",
      "Epoch: 858, Loss: 0.5289, Acc: 0.6740\n",
      "Epoch: 859, Loss: 0.5242, Acc: 0.6655\n",
      "Epoch: 860, Loss: 0.5330, Acc: 0.6671\n",
      "Epoch: 861, Loss: 0.5276, Acc: 0.6655\n",
      "Epoch: 862, Loss: 0.5331, Acc: 0.6728\n",
      "Epoch: 863, Loss: 0.5334, Acc: 0.6619\n",
      "Epoch: 864, Loss: 0.5316, Acc: 0.6742\n",
      "Epoch: 865, Loss: 0.5286, Acc: 0.6752\n",
      "Epoch: 866, Loss: 0.5259, Acc: 0.6716\n",
      "Epoch: 867, Loss: 0.5304, Acc: 0.6695\n",
      "Epoch: 868, Loss: 0.5250, Acc: 0.6695\n",
      "Epoch: 869, Loss: 0.5323, Acc: 0.6700\n",
      "Epoch: 870, Loss: 0.5316, Acc: 0.6712\n",
      "Epoch: 871, Loss: 0.5299, Acc: 0.6731\n",
      "Epoch: 872, Loss: 0.5290, Acc: 0.6705\n",
      "Epoch: 873, Loss: 0.5342, Acc: 0.6662\n",
      "Epoch: 874, Loss: 0.5364, Acc: 0.6723\n",
      "Epoch: 875, Loss: 0.5298, Acc: 0.6716\n",
      "Epoch: 876, Loss: 0.5311, Acc: 0.6823\n",
      "Epoch: 877, Loss: 0.5335, Acc: 0.6695\n",
      "Epoch: 878, Loss: 0.5315, Acc: 0.6721\n",
      "Epoch: 879, Loss: 0.5328, Acc: 0.6671\n",
      "Epoch: 880, Loss: 0.5282, Acc: 0.6667\n",
      "Epoch: 881, Loss: 0.5325, Acc: 0.6747\n",
      "Epoch: 882, Loss: 0.5305, Acc: 0.6664\n",
      "Epoch: 883, Loss: 0.5284, Acc: 0.6705\n",
      "Epoch: 884, Loss: 0.5310, Acc: 0.6641\n",
      "Epoch: 885, Loss: 0.5313, Acc: 0.6728\n",
      "Epoch: 886, Loss: 0.5279, Acc: 0.6738\n",
      "Epoch: 887, Loss: 0.5365, Acc: 0.6731\n",
      "Epoch: 888, Loss: 0.5347, Acc: 0.6671\n",
      "Epoch: 889, Loss: 0.5333, Acc: 0.6650\n",
      "Epoch: 890, Loss: 0.5317, Acc: 0.6714\n",
      "Epoch: 891, Loss: 0.5324, Acc: 0.6686\n",
      "Epoch: 892, Loss: 0.5315, Acc: 0.6787\n",
      "Epoch: 893, Loss: 0.5338, Acc: 0.6780\n",
      "Epoch: 894, Loss: 0.5279, Acc: 0.6674\n",
      "Epoch: 895, Loss: 0.5314, Acc: 0.6854\n",
      "Epoch: 896, Loss: 0.5327, Acc: 0.6648\n",
      "Epoch: 897, Loss: 0.5256, Acc: 0.6702\n",
      "Epoch: 898, Loss: 0.5323, Acc: 0.6634\n",
      "Epoch: 899, Loss: 0.5285, Acc: 0.6643\n",
      "Epoch: 900, Loss: 0.5326, Acc: 0.6667\n",
      "Epoch: 901, Loss: 0.5317, Acc: 0.6759\n",
      "Epoch: 902, Loss: 0.5364, Acc: 0.6655\n",
      "Epoch: 903, Loss: 0.5277, Acc: 0.6702\n",
      "Epoch: 904, Loss: 0.5286, Acc: 0.6596\n",
      "Epoch: 905, Loss: 0.5272, Acc: 0.6693\n",
      "Epoch: 906, Loss: 0.5319, Acc: 0.6726\n",
      "Epoch: 907, Loss: 0.5279, Acc: 0.6780\n",
      "Epoch: 908, Loss: 0.5337, Acc: 0.6626\n",
      "Epoch: 909, Loss: 0.5256, Acc: 0.6690\n",
      "Epoch: 910, Loss: 0.5369, Acc: 0.6567\n",
      "Epoch: 911, Loss: 0.5336, Acc: 0.6785\n",
      "Epoch: 912, Loss: 0.5400, Acc: 0.6624\n",
      "Epoch: 913, Loss: 0.5319, Acc: 0.6676\n",
      "Epoch: 914, Loss: 0.5317, Acc: 0.6641\n",
      "Epoch: 915, Loss: 0.5350, Acc: 0.6652\n",
      "Epoch: 916, Loss: 0.5326, Acc: 0.6671\n",
      "Epoch: 917, Loss: 0.5359, Acc: 0.6754\n",
      "Epoch: 918, Loss: 0.5294, Acc: 0.6607\n",
      "Epoch: 919, Loss: 0.5302, Acc: 0.6752\n",
      "Epoch: 920, Loss: 0.5310, Acc: 0.6551\n",
      "Epoch: 921, Loss: 0.5316, Acc: 0.6669\n",
      "Epoch: 922, Loss: 0.5263, Acc: 0.6605\n",
      "Epoch: 923, Loss: 0.5341, Acc: 0.6610\n",
      "Epoch: 924, Loss: 0.5354, Acc: 0.6771\n",
      "Epoch: 925, Loss: 0.5359, Acc: 0.6650\n",
      "Epoch: 926, Loss: 0.5301, Acc: 0.6596\n",
      "Epoch: 927, Loss: 0.5320, Acc: 0.6702\n",
      "Epoch: 928, Loss: 0.5334, Acc: 0.6740\n",
      "Epoch: 929, Loss: 0.5297, Acc: 0.6773\n",
      "Epoch: 930, Loss: 0.5329, Acc: 0.6603\n",
      "Epoch: 931, Loss: 0.5254, Acc: 0.6662\n",
      "Epoch: 932, Loss: 0.5302, Acc: 0.6650\n",
      "Epoch: 933, Loss: 0.5303, Acc: 0.6723\n",
      "Epoch: 934, Loss: 0.5314, Acc: 0.6671\n",
      "Epoch: 935, Loss: 0.5283, Acc: 0.6719\n",
      "Epoch: 936, Loss: 0.5315, Acc: 0.6728\n",
      "Epoch: 937, Loss: 0.5308, Acc: 0.6619\n",
      "Epoch: 938, Loss: 0.5269, Acc: 0.6723\n",
      "Epoch: 939, Loss: 0.5329, Acc: 0.6655\n",
      "Epoch: 940, Loss: 0.5322, Acc: 0.6757\n",
      "Epoch: 941, Loss: 0.5316, Acc: 0.6776\n",
      "Epoch: 942, Loss: 0.5288, Acc: 0.6676\n",
      "Epoch: 943, Loss: 0.5302, Acc: 0.6733\n",
      "Epoch: 944, Loss: 0.5285, Acc: 0.6750\n",
      "Epoch: 945, Loss: 0.5258, Acc: 0.6631\n",
      "Epoch: 946, Loss: 0.5284, Acc: 0.6667\n",
      "Epoch: 947, Loss: 0.5320, Acc: 0.6783\n",
      "Epoch: 948, Loss: 0.5293, Acc: 0.6688\n",
      "Epoch: 949, Loss: 0.5326, Acc: 0.6572\n",
      "Epoch: 950, Loss: 0.5327, Acc: 0.6712\n",
      "Epoch: 951, Loss: 0.5319, Acc: 0.6705\n",
      "Epoch: 952, Loss: 0.5324, Acc: 0.6728\n",
      "Epoch: 953, Loss: 0.5318, Acc: 0.6747\n",
      "Epoch: 954, Loss: 0.5287, Acc: 0.6787\n",
      "Epoch: 955, Loss: 0.5295, Acc: 0.6662\n",
      "Epoch: 956, Loss: 0.5285, Acc: 0.6738\n",
      "Epoch: 957, Loss: 0.5322, Acc: 0.6679\n",
      "Epoch: 958, Loss: 0.5278, Acc: 0.6795\n",
      "Epoch: 959, Loss: 0.5265, Acc: 0.6695\n",
      "Epoch: 960, Loss: 0.5290, Acc: 0.6629\n",
      "Epoch: 961, Loss: 0.5344, Acc: 0.6693\n",
      "Epoch: 962, Loss: 0.5297, Acc: 0.6712\n",
      "Epoch: 963, Loss: 0.5332, Acc: 0.6695\n",
      "Epoch: 964, Loss: 0.5295, Acc: 0.6655\n",
      "Epoch: 965, Loss: 0.5277, Acc: 0.6705\n",
      "Epoch: 966, Loss: 0.5307, Acc: 0.6676\n",
      "Epoch: 967, Loss: 0.5247, Acc: 0.6688\n",
      "Epoch: 968, Loss: 0.5357, Acc: 0.6629\n",
      "Epoch: 969, Loss: 0.5403, Acc: 0.6652\n",
      "Epoch: 970, Loss: 0.5360, Acc: 0.6700\n",
      "Epoch: 971, Loss: 0.5291, Acc: 0.6778\n",
      "Epoch: 972, Loss: 0.5311, Acc: 0.6716\n",
      "Epoch: 973, Loss: 0.5242, Acc: 0.6764\n",
      "Epoch: 974, Loss: 0.5309, Acc: 0.6783\n",
      "Epoch: 975, Loss: 0.5304, Acc: 0.6693\n",
      "Epoch: 976, Loss: 0.5261, Acc: 0.6752\n",
      "Epoch: 977, Loss: 0.5327, Acc: 0.6740\n",
      "Epoch: 978, Loss: 0.5302, Acc: 0.6705\n",
      "Epoch: 979, Loss: 0.5282, Acc: 0.6740\n",
      "Epoch: 980, Loss: 0.5349, Acc: 0.6645\n",
      "Epoch: 981, Loss: 0.5264, Acc: 0.6610\n",
      "Epoch: 982, Loss: 0.5328, Acc: 0.6686\n",
      "Epoch: 983, Loss: 0.5344, Acc: 0.6686\n",
      "Epoch: 984, Loss: 0.5399, Acc: 0.6697\n",
      "Epoch: 985, Loss: 0.5315, Acc: 0.6714\n",
      "Epoch: 986, Loss: 0.5279, Acc: 0.6638\n",
      "Epoch: 987, Loss: 0.5270, Acc: 0.6645\n",
      "Epoch: 988, Loss: 0.5308, Acc: 0.6669\n",
      "Epoch: 989, Loss: 0.5333, Acc: 0.6700\n",
      "Epoch: 990, Loss: 0.5282, Acc: 0.6719\n",
      "Epoch: 991, Loss: 0.5316, Acc: 0.6634\n",
      "Epoch: 992, Loss: 0.5296, Acc: 0.6731\n",
      "Epoch: 993, Loss: 0.5277, Acc: 0.6681\n",
      "Epoch: 994, Loss: 0.5280, Acc: 0.6697\n",
      "Epoch: 995, Loss: 0.5306, Acc: 0.6650\n",
      "Epoch: 996, Loss: 0.5339, Acc: 0.6733\n",
      "Epoch: 997, Loss: 0.5291, Acc: 0.6752\n",
      "Epoch: 998, Loss: 0.5298, Acc: 0.6780\n",
      "Epoch: 999, Loss: 0.5320, Acc: 0.6714\n",
      "Epoch: 1000, Loss: 0.5323, Acc: 0.6679\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1001):\n",
    "    loss = train()\n",
    "    acc = test()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Acc: {acc:.4f}\")                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c62125",
   "metadata": {},
   "source": [
    "## 3.图分类任务代码实现\n",
    "采用ENZYMES数据集。ENZYMES是一个常用的图分类基准数据集。它是由600个图组成的，这些图实际上表示了不同的蛋白酶的结构，这些蛋白酶分为6个类别（每个类别有100个蛋白酶）。因此，每个图代表一个蛋白酶，我们的任务是预测蛋白酶属于哪一个类别。这是6分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce87f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/ENZYMES.zip\n",
      "Extracting data/ENZYMES/ENZYMES/ENZYMES.zip\n",
      "Processing...\n",
      "Done!\n",
      "/Users/xiaoyu/miniforge3/lib/python3.9/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# 加载数据集\n",
    "dataset = TUDataset(root='./data/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图卷积网络模型\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = torch.nn.Linear(hidden_channels, dataset.num_classes)\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)    # 使用全局平均池化获得图的嵌入\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.2111, Test Acc: 0.1000\n",
      "Epoch: 002, Train Acc: 0.2315, Test Acc: 0.2667\n",
      "Epoch: 003, Train Acc: 0.2241, Test Acc: 0.2667\n",
      "Epoch: 004, Train Acc: 0.2130, Test Acc: 0.1000\n",
      "Epoch: 005, Train Acc: 0.2370, Test Acc: 0.2000\n",
      "Epoch: 006, Train Acc: 0.2537, Test Acc: 0.2500\n",
      "Epoch: 007, Train Acc: 0.2537, Test Acc: 0.2833\n",
      "Epoch: 008, Train Acc: 0.2648, Test Acc: 0.1667\n",
      "Epoch: 009, Train Acc: 0.2352, Test Acc: 0.1333\n",
      "Epoch: 010, Train Acc: 0.2481, Test Acc: 0.1667\n",
      "Epoch: 011, Train Acc: 0.2574, Test Acc: 0.1833\n",
      "Epoch: 012, Train Acc: 0.2685, Test Acc: 0.2667\n",
      "Epoch: 013, Train Acc: 0.2759, Test Acc: 0.3167\n",
      "Epoch: 014, Train Acc: 0.2741, Test Acc: 0.2667\n",
      "Epoch: 015, Train Acc: 0.2611, Test Acc: 0.3000\n",
      "Epoch: 016, Train Acc: 0.2556, Test Acc: 0.2500\n",
      "Epoch: 017, Train Acc: 0.2889, Test Acc: 0.3000\n",
      "Epoch: 018, Train Acc: 0.2907, Test Acc: 0.2333\n",
      "Epoch: 019, Train Acc: 0.2574, Test Acc: 0.1833\n",
      "Epoch: 020, Train Acc: 0.2796, Test Acc: 0.2833\n",
      "Epoch: 021, Train Acc: 0.2685, Test Acc: 0.3333\n",
      "Epoch: 022, Train Acc: 0.3000, Test Acc: 0.2333\n",
      "Epoch: 023, Train Acc: 0.2889, Test Acc: 0.2500\n",
      "Epoch: 024, Train Acc: 0.2778, Test Acc: 0.2500\n",
      "Epoch: 025, Train Acc: 0.3148, Test Acc: 0.3167\n",
      "Epoch: 026, Train Acc: 0.3000, Test Acc: 0.2833\n",
      "Epoch: 027, Train Acc: 0.2870, Test Acc: 0.2333\n",
      "Epoch: 028, Train Acc: 0.2519, Test Acc: 0.1333\n",
      "Epoch: 029, Train Acc: 0.2611, Test Acc: 0.2833\n",
      "Epoch: 030, Train Acc: 0.2981, Test Acc: 0.2667\n",
      "Epoch: 031, Train Acc: 0.2926, Test Acc: 0.2667\n",
      "Epoch: 032, Train Acc: 0.2963, Test Acc: 0.2167\n",
      "Epoch: 033, Train Acc: 0.2963, Test Acc: 0.2333\n",
      "Epoch: 034, Train Acc: 0.2796, Test Acc: 0.3000\n",
      "Epoch: 035, Train Acc: 0.2870, Test Acc: 0.2333\n",
      "Epoch: 036, Train Acc: 0.2889, Test Acc: 0.2000\n",
      "Epoch: 037, Train Acc: 0.2926, Test Acc: 0.2333\n",
      "Epoch: 038, Train Acc: 0.2704, Test Acc: 0.3167\n",
      "Epoch: 039, Train Acc: 0.2870, Test Acc: 0.2500\n",
      "Epoch: 040, Train Acc: 0.3074, Test Acc: 0.2833\n",
      "Epoch: 041, Train Acc: 0.2889, Test Acc: 0.2833\n",
      "Epoch: 042, Train Acc: 0.3019, Test Acc: 0.2500\n",
      "Epoch: 043, Train Acc: 0.2963, Test Acc: 0.2667\n",
      "Epoch: 044, Train Acc: 0.3000, Test Acc: 0.2500\n",
      "Epoch: 045, Train Acc: 0.2907, Test Acc: 0.2833\n",
      "Epoch: 046, Train Acc: 0.3019, Test Acc: 0.2333\n",
      "Epoch: 047, Train Acc: 0.3019, Test Acc: 0.2333\n",
      "Epoch: 048, Train Acc: 0.2870, Test Acc: 0.2500\n",
      "Epoch: 049, Train Acc: 0.2907, Test Acc: 0.2833\n",
      "Epoch: 050, Train Acc: 0.3019, Test Acc: 0.3167\n",
      "Epoch: 051, Train Acc: 0.2870, Test Acc: 0.2333\n",
      "Epoch: 052, Train Acc: 0.2981, Test Acc: 0.2500\n",
      "Epoch: 053, Train Acc: 0.2981, Test Acc: 0.2500\n",
      "Epoch: 054, Train Acc: 0.2870, Test Acc: 0.2500\n",
      "Epoch: 055, Train Acc: 0.3000, Test Acc: 0.2167\n",
      "Epoch: 056, Train Acc: 0.3056, Test Acc: 0.2500\n",
      "Epoch: 057, Train Acc: 0.2778, Test Acc: 0.3000\n",
      "Epoch: 058, Train Acc: 0.3019, Test Acc: 0.2833\n",
      "Epoch: 059, Train Acc: 0.2944, Test Acc: 0.2333\n",
      "Epoch: 060, Train Acc: 0.3000, Test Acc: 0.3000\n",
      "Epoch: 061, Train Acc: 0.3000, Test Acc: 0.2667\n",
      "Epoch: 062, Train Acc: 0.2926, Test Acc: 0.2333\n",
      "Epoch: 063, Train Acc: 0.2944, Test Acc: 0.2833\n",
      "Epoch: 064, Train Acc: 0.2889, Test Acc: 0.2167\n",
      "Epoch: 065, Train Acc: 0.3019, Test Acc: 0.2833\n",
      "Epoch: 066, Train Acc: 0.2981, Test Acc: 0.3333\n",
      "Epoch: 067, Train Acc: 0.2944, Test Acc: 0.2667\n",
      "Epoch: 068, Train Acc: 0.2852, Test Acc: 0.2333\n",
      "Epoch: 069, Train Acc: 0.2944, Test Acc: 0.3333\n",
      "Epoch: 070, Train Acc: 0.2852, Test Acc: 0.3167\n",
      "Epoch: 071, Train Acc: 0.2981, Test Acc: 0.2500\n",
      "Epoch: 072, Train Acc: 0.2815, Test Acc: 0.3000\n",
      "Epoch: 073, Train Acc: 0.3000, Test Acc: 0.3000\n",
      "Epoch: 074, Train Acc: 0.3000, Test Acc: 0.2667\n",
      "Epoch: 075, Train Acc: 0.2963, Test Acc: 0.2667\n",
      "Epoch: 076, Train Acc: 0.3093, Test Acc: 0.1833\n",
      "Epoch: 077, Train Acc: 0.2907, Test Acc: 0.2500\n",
      "Epoch: 078, Train Acc: 0.2926, Test Acc: 0.2833\n",
      "Epoch: 079, Train Acc: 0.2870, Test Acc: 0.3167\n",
      "Epoch: 080, Train Acc: 0.2926, Test Acc: 0.2833\n",
      "Epoch: 081, Train Acc: 0.2870, Test Acc: 0.3167\n",
      "Epoch: 082, Train Acc: 0.2926, Test Acc: 0.2333\n",
      "Epoch: 083, Train Acc: 0.2981, Test Acc: 0.2167\n",
      "Epoch: 084, Train Acc: 0.2907, Test Acc: 0.2167\n",
      "Epoch: 085, Train Acc: 0.2704, Test Acc: 0.2333\n",
      "Epoch: 086, Train Acc: 0.2981, Test Acc: 0.2833\n",
      "Epoch: 087, Train Acc: 0.2944, Test Acc: 0.2833\n",
      "Epoch: 088, Train Acc: 0.2741, Test Acc: 0.2667\n",
      "Epoch: 089, Train Acc: 0.2648, Test Acc: 0.2667\n",
      "Epoch: 090, Train Acc: 0.2759, Test Acc: 0.3000\n",
      "Epoch: 091, Train Acc: 0.3000, Test Acc: 0.2167\n",
      "Epoch: 092, Train Acc: 0.2852, Test Acc: 0.1833\n",
      "Epoch: 093, Train Acc: 0.2926, Test Acc: 0.2333\n",
      "Epoch: 094, Train Acc: 0.2889, Test Acc: 0.2500\n",
      "Epoch: 095, Train Acc: 0.2963, Test Acc: 0.2500\n",
      "Epoch: 096, Train Acc: 0.3074, Test Acc: 0.2333\n",
      "Epoch: 097, Train Acc: 0.2778, Test Acc: 0.2667\n",
      "Epoch: 098, Train Acc: 0.2778, Test Acc: 0.2333\n",
      "Epoch: 099, Train Acc: 0.2981, Test Acc: 0.3167\n",
      "Epoch: 100, Train Acc: 0.2907, Test Acc: 0.2167\n",
      "Epoch: 101, Train Acc: 0.3074, Test Acc: 0.3167\n",
      "Epoch: 102, Train Acc: 0.2907, Test Acc: 0.2667\n",
      "Epoch: 103, Train Acc: 0.2944, Test Acc: 0.3000\n",
      "Epoch: 104, Train Acc: 0.2981, Test Acc: 0.2667\n",
      "Epoch: 105, Train Acc: 0.3074, Test Acc: 0.2833\n",
      "Epoch: 106, Train Acc: 0.3056, Test Acc: 0.3000\n",
      "Epoch: 107, Train Acc: 0.2926, Test Acc: 0.2667\n",
      "Epoch: 108, Train Acc: 0.3074, Test Acc: 0.3167\n",
      "Epoch: 109, Train Acc: 0.2889, Test Acc: 0.3167\n",
      "Epoch: 110, Train Acc: 0.3130, Test Acc: 0.2667\n",
      "Epoch: 111, Train Acc: 0.3019, Test Acc: 0.3167\n",
      "Epoch: 112, Train Acc: 0.2815, Test Acc: 0.3000\n",
      "Epoch: 113, Train Acc: 0.3204, Test Acc: 0.2833\n",
      "Epoch: 114, Train Acc: 0.3019, Test Acc: 0.2500\n",
      "Epoch: 115, Train Acc: 0.2981, Test Acc: 0.3167\n",
      "Epoch: 116, Train Acc: 0.2926, Test Acc: 0.3333\n",
      "Epoch: 117, Train Acc: 0.2981, Test Acc: 0.2833\n",
      "Epoch: 118, Train Acc: 0.2963, Test Acc: 0.3333\n",
      "Epoch: 119, Train Acc: 0.2963, Test Acc: 0.3333\n",
      "Epoch: 120, Train Acc: 0.2870, Test Acc: 0.3167\n",
      "Epoch: 121, Train Acc: 0.3111, Test Acc: 0.2667\n",
      "Epoch: 122, Train Acc: 0.2981, Test Acc: 0.3167\n",
      "Epoch: 123, Train Acc: 0.2907, Test Acc: 0.3667\n",
      "Epoch: 124, Train Acc: 0.2963, Test Acc: 0.3000\n",
      "Epoch: 125, Train Acc: 0.3000, Test Acc: 0.3167\n",
      "Epoch: 126, Train Acc: 0.3037, Test Acc: 0.3000\n",
      "Epoch: 127, Train Acc: 0.2833, Test Acc: 0.2667\n",
      "Epoch: 128, Train Acc: 0.3056, Test Acc: 0.3000\n",
      "Epoch: 129, Train Acc: 0.3056, Test Acc: 0.3167\n",
      "Epoch: 130, Train Acc: 0.2889, Test Acc: 0.3333\n",
      "Epoch: 131, Train Acc: 0.3037, Test Acc: 0.2833\n",
      "Epoch: 132, Train Acc: 0.2926, Test Acc: 0.3000\n",
      "Epoch: 133, Train Acc: 0.3037, Test Acc: 0.3333\n",
      "Epoch: 134, Train Acc: 0.3074, Test Acc: 0.3167\n",
      "Epoch: 135, Train Acc: 0.3000, Test Acc: 0.2333\n",
      "Epoch: 136, Train Acc: 0.3111, Test Acc: 0.3667\n",
      "Epoch: 137, Train Acc: 0.2926, Test Acc: 0.3500\n",
      "Epoch: 138, Train Acc: 0.3037, Test Acc: 0.2500\n",
      "Epoch: 139, Train Acc: 0.3074, Test Acc: 0.3333\n",
      "Epoch: 140, Train Acc: 0.3000, Test Acc: 0.3167\n",
      "Epoch: 141, Train Acc: 0.3185, Test Acc: 0.3500\n",
      "Epoch: 142, Train Acc: 0.3074, Test Acc: 0.3333\n",
      "Epoch: 143, Train Acc: 0.2889, Test Acc: 0.3167\n",
      "Epoch: 144, Train Acc: 0.2870, Test Acc: 0.3500\n",
      "Epoch: 145, Train Acc: 0.3074, Test Acc: 0.3000\n",
      "Epoch: 146, Train Acc: 0.3093, Test Acc: 0.2667\n",
      "Epoch: 147, Train Acc: 0.3019, Test Acc: 0.3333\n",
      "Epoch: 148, Train Acc: 0.2907, Test Acc: 0.3167\n",
      "Epoch: 149, Train Acc: 0.3074, Test Acc: 0.3167\n",
      "Epoch: 150, Train Acc: 0.2963, Test Acc: 0.3167\n",
      "Epoch: 151, Train Acc: 0.3056, Test Acc: 0.3167\n",
      "Epoch: 152, Train Acc: 0.2889, Test Acc: 0.3333\n",
      "Epoch: 153, Train Acc: 0.2889, Test Acc: 0.3000\n",
      "Epoch: 154, Train Acc: 0.3074, Test Acc: 0.3500\n",
      "Epoch: 155, Train Acc: 0.2963, Test Acc: 0.3500\n",
      "Epoch: 156, Train Acc: 0.3093, Test Acc: 0.3333\n",
      "Epoch: 157, Train Acc: 0.3093, Test Acc: 0.3167\n",
      "Epoch: 158, Train Acc: 0.3000, Test Acc: 0.3000\n",
      "Epoch: 159, Train Acc: 0.2870, Test Acc: 0.3500\n",
      "Epoch: 160, Train Acc: 0.2889, Test Acc: 0.3333\n",
      "Epoch: 161, Train Acc: 0.3093, Test Acc: 0.3167\n",
      "Epoch: 162, Train Acc: 0.2944, Test Acc: 0.3833\n",
      "Epoch: 163, Train Acc: 0.3000, Test Acc: 0.3333\n",
      "Epoch: 164, Train Acc: 0.2907, Test Acc: 0.3500\n",
      "Epoch: 165, Train Acc: 0.3111, Test Acc: 0.3667\n",
      "Epoch: 166, Train Acc: 0.3111, Test Acc: 0.3000\n",
      "Epoch: 167, Train Acc: 0.3111, Test Acc: 0.3333\n",
      "Epoch: 168, Train Acc: 0.2981, Test Acc: 0.3500\n",
      "Epoch: 169, Train Acc: 0.2963, Test Acc: 0.2833\n",
      "Epoch: 170, Train Acc: 0.2963, Test Acc: 0.3333\n",
      "Epoch: 171, Train Acc: 0.3111, Test Acc: 0.2667\n",
      "Epoch: 172, Train Acc: 0.3000, Test Acc: 0.2667\n",
      "Epoch: 173, Train Acc: 0.3130, Test Acc: 0.3667\n",
      "Epoch: 174, Train Acc: 0.3019, Test Acc: 0.2667\n",
      "Epoch: 175, Train Acc: 0.3037, Test Acc: 0.3667\n",
      "Epoch: 176, Train Acc: 0.2907, Test Acc: 0.3000\n",
      "Epoch: 177, Train Acc: 0.3130, Test Acc: 0.2833\n",
      "Epoch: 178, Train Acc: 0.2926, Test Acc: 0.3167\n",
      "Epoch: 179, Train Acc: 0.2870, Test Acc: 0.3167\n",
      "Epoch: 180, Train Acc: 0.2963, Test Acc: 0.3500\n",
      "Epoch: 181, Train Acc: 0.3019, Test Acc: 0.3000\n",
      "Epoch: 182, Train Acc: 0.3130, Test Acc: 0.2667\n",
      "Epoch: 183, Train Acc: 0.3019, Test Acc: 0.3167\n",
      "Epoch: 184, Train Acc: 0.2944, Test Acc: 0.3667\n",
      "Epoch: 185, Train Acc: 0.2926, Test Acc: 0.2833\n",
      "Epoch: 186, Train Acc: 0.2981, Test Acc: 0.2833\n",
      "Epoch: 187, Train Acc: 0.3000, Test Acc: 0.3333\n",
      "Epoch: 188, Train Acc: 0.3056, Test Acc: 0.3833\n",
      "Epoch: 189, Train Acc: 0.2944, Test Acc: 0.3500\n",
      "Epoch: 190, Train Acc: 0.2963, Test Acc: 0.2833\n",
      "Epoch: 191, Train Acc: 0.3037, Test Acc: 0.3000\n",
      "Epoch: 192, Train Acc: 0.2815, Test Acc: 0.2833\n",
      "Epoch: 193, Train Acc: 0.2889, Test Acc: 0.3000\n",
      "Epoch: 194, Train Acc: 0.2889, Test Acc: 0.3333\n",
      "Epoch: 195, Train Acc: 0.3185, Test Acc: 0.3333\n",
      "Epoch: 196, Train Acc: 0.3093, Test Acc: 0.3167\n",
      "Epoch: 197, Train Acc: 0.3000, Test Acc: 0.3167\n",
      "Epoch: 198, Train Acc: 0.2907, Test Acc: 0.4000\n",
      "Epoch: 199, Train Acc: 0.3056, Test Acc: 0.3333\n",
      "Epoch: 200, Train Acc: 0.3111, Test Acc: 0.3333\n",
      "Epoch: 201, Train Acc: 0.3000, Test Acc: 0.2667\n",
      "Epoch: 202, Train Acc: 0.3167, Test Acc: 0.3167\n",
      "Epoch: 203, Train Acc: 0.3222, Test Acc: 0.3667\n",
      "Epoch: 204, Train Acc: 0.3241, Test Acc: 0.4000\n",
      "Epoch: 205, Train Acc: 0.3093, Test Acc: 0.3333\n",
      "Epoch: 206, Train Acc: 0.3019, Test Acc: 0.3500\n",
      "Epoch: 207, Train Acc: 0.3037, Test Acc: 0.3833\n",
      "Epoch: 208, Train Acc: 0.3056, Test Acc: 0.3167\n",
      "Epoch: 209, Train Acc: 0.3167, Test Acc: 0.3500\n",
      "Epoch: 210, Train Acc: 0.2981, Test Acc: 0.3333\n",
      "Epoch: 211, Train Acc: 0.3167, Test Acc: 0.3333\n",
      "Epoch: 212, Train Acc: 0.2963, Test Acc: 0.3167\n",
      "Epoch: 213, Train Acc: 0.3148, Test Acc: 0.2167\n",
      "Epoch: 214, Train Acc: 0.3093, Test Acc: 0.2000\n",
      "Epoch: 215, Train Acc: 0.3093, Test Acc: 0.3833\n",
      "Epoch: 216, Train Acc: 0.3185, Test Acc: 0.3500\n",
      "Epoch: 217, Train Acc: 0.2926, Test Acc: 0.2833\n",
      "Epoch: 218, Train Acc: 0.3389, Test Acc: 0.3167\n",
      "Epoch: 219, Train Acc: 0.3019, Test Acc: 0.3000\n",
      "Epoch: 220, Train Acc: 0.3352, Test Acc: 0.3833\n",
      "Epoch: 221, Train Acc: 0.3019, Test Acc: 0.3167\n",
      "Epoch: 222, Train Acc: 0.3111, Test Acc: 0.3333\n",
      "Epoch: 223, Train Acc: 0.3056, Test Acc: 0.3167\n",
      "Epoch: 224, Train Acc: 0.3130, Test Acc: 0.3167\n",
      "Epoch: 225, Train Acc: 0.3204, Test Acc: 0.2833\n",
      "Epoch: 226, Train Acc: 0.3130, Test Acc: 0.3167\n",
      "Epoch: 227, Train Acc: 0.2907, Test Acc: 0.3167\n",
      "Epoch: 228, Train Acc: 0.3074, Test Acc: 0.3667\n",
      "Epoch: 229, Train Acc: 0.2704, Test Acc: 0.3667\n",
      "Epoch: 230, Train Acc: 0.3407, Test Acc: 0.3333\n",
      "Epoch: 231, Train Acc: 0.3056, Test Acc: 0.3167\n",
      "Epoch: 232, Train Acc: 0.3111, Test Acc: 0.3333\n",
      "Epoch: 233, Train Acc: 0.3037, Test Acc: 0.3833\n",
      "Epoch: 234, Train Acc: 0.3130, Test Acc: 0.3500\n",
      "Epoch: 235, Train Acc: 0.3167, Test Acc: 0.4167\n",
      "Epoch: 236, Train Acc: 0.3111, Test Acc: 0.2833\n",
      "Epoch: 237, Train Acc: 0.3037, Test Acc: 0.2833\n",
      "Epoch: 238, Train Acc: 0.3111, Test Acc: 0.3000\n",
      "Epoch: 239, Train Acc: 0.3333, Test Acc: 0.3833\n",
      "Epoch: 240, Train Acc: 0.3019, Test Acc: 0.3333\n",
      "Epoch: 241, Train Acc: 0.3185, Test Acc: 0.3167\n",
      "Epoch: 242, Train Acc: 0.3056, Test Acc: 0.2833\n",
      "Epoch: 243, Train Acc: 0.3278, Test Acc: 0.4167\n",
      "Epoch: 244, Train Acc: 0.3056, Test Acc: 0.3667\n",
      "Epoch: 245, Train Acc: 0.3204, Test Acc: 0.3667\n",
      "Epoch: 246, Train Acc: 0.3278, Test Acc: 0.3833\n",
      "Epoch: 247, Train Acc: 0.2963, Test Acc: 0.2833\n",
      "Epoch: 248, Train Acc: 0.3074, Test Acc: 0.3500\n",
      "Epoch: 249, Train Acc: 0.3148, Test Acc: 0.3333\n",
      "Epoch: 250, Train Acc: 0.3185, Test Acc: 0.3167\n",
      "Epoch: 251, Train Acc: 0.3130, Test Acc: 0.3167\n",
      "Epoch: 252, Train Acc: 0.3296, Test Acc: 0.3000\n",
      "Epoch: 253, Train Acc: 0.3148, Test Acc: 0.3167\n",
      "Epoch: 254, Train Acc: 0.3130, Test Acc: 0.3000\n",
      "Epoch: 255, Train Acc: 0.3259, Test Acc: 0.2667\n",
      "Epoch: 256, Train Acc: 0.3296, Test Acc: 0.3667\n",
      "Epoch: 257, Train Acc: 0.3241, Test Acc: 0.3500\n",
      "Epoch: 258, Train Acc: 0.3630, Test Acc: 0.3333\n",
      "Epoch: 259, Train Acc: 0.3278, Test Acc: 0.3500\n",
      "Epoch: 260, Train Acc: 0.3389, Test Acc: 0.3500\n",
      "Epoch: 261, Train Acc: 0.3333, Test Acc: 0.3167\n",
      "Epoch: 262, Train Acc: 0.3352, Test Acc: 0.3667\n",
      "Epoch: 263, Train Acc: 0.3315, Test Acc: 0.2833\n",
      "Epoch: 264, Train Acc: 0.3389, Test Acc: 0.3500\n",
      "Epoch: 265, Train Acc: 0.3519, Test Acc: 0.4000\n",
      "Epoch: 266, Train Acc: 0.3426, Test Acc: 0.3500\n",
      "Epoch: 267, Train Acc: 0.3259, Test Acc: 0.3667\n",
      "Epoch: 268, Train Acc: 0.3537, Test Acc: 0.3833\n",
      "Epoch: 269, Train Acc: 0.3556, Test Acc: 0.3167\n",
      "Epoch: 270, Train Acc: 0.3278, Test Acc: 0.3333\n",
      "Epoch: 271, Train Acc: 0.3500, Test Acc: 0.3333\n",
      "Epoch: 272, Train Acc: 0.3500, Test Acc: 0.3667\n",
      "Epoch: 273, Train Acc: 0.3500, Test Acc: 0.3333\n",
      "Epoch: 274, Train Acc: 0.3556, Test Acc: 0.3833\n",
      "Epoch: 275, Train Acc: 0.3333, Test Acc: 0.3667\n",
      "Epoch: 276, Train Acc: 0.3389, Test Acc: 0.3667\n",
      "Epoch: 277, Train Acc: 0.3352, Test Acc: 0.3500\n",
      "Epoch: 278, Train Acc: 0.3389, Test Acc: 0.3333\n",
      "Epoch: 279, Train Acc: 0.3352, Test Acc: 0.3333\n",
      "Epoch: 280, Train Acc: 0.3481, Test Acc: 0.3500\n",
      "Epoch: 281, Train Acc: 0.3148, Test Acc: 0.3167\n",
      "Epoch: 282, Train Acc: 0.3500, Test Acc: 0.3500\n",
      "Epoch: 283, Train Acc: 0.3444, Test Acc: 0.2833\n",
      "Epoch: 284, Train Acc: 0.3407, Test Acc: 0.3167\n",
      "Epoch: 285, Train Acc: 0.3593, Test Acc: 0.3667\n",
      "Epoch: 286, Train Acc: 0.3537, Test Acc: 0.3667\n",
      "Epoch: 287, Train Acc: 0.3407, Test Acc: 0.3667\n",
      "Epoch: 288, Train Acc: 0.3500, Test Acc: 0.3500\n",
      "Epoch: 289, Train Acc: 0.3296, Test Acc: 0.2500\n",
      "Epoch: 290, Train Acc: 0.3556, Test Acc: 0.3333\n",
      "Epoch: 291, Train Acc: 0.3222, Test Acc: 0.3500\n",
      "Epoch: 292, Train Acc: 0.3389, Test Acc: 0.4000\n",
      "Epoch: 293, Train Acc: 0.3185, Test Acc: 0.3333\n",
      "Epoch: 294, Train Acc: 0.3241, Test Acc: 0.3500\n",
      "Epoch: 295, Train Acc: 0.3556, Test Acc: 0.4000\n",
      "Epoch: 296, Train Acc: 0.3370, Test Acc: 0.3000\n",
      "Epoch: 297, Train Acc: 0.3352, Test Acc: 0.3500\n",
      "Epoch: 298, Train Acc: 0.3481, Test Acc: 0.4333\n",
      "Epoch: 299, Train Acc: 0.3370, Test Acc: 0.3333\n",
      "Epoch: 300, Train Acc: 0.3593, Test Acc: 0.3833\n",
      "Epoch: 301, Train Acc: 0.3278, Test Acc: 0.3000\n",
      "Epoch: 302, Train Acc: 0.3500, Test Acc: 0.3167\n",
      "Epoch: 303, Train Acc: 0.3185, Test Acc: 0.2833\n",
      "Epoch: 304, Train Acc: 0.3407, Test Acc: 0.3333\n",
      "Epoch: 305, Train Acc: 0.3519, Test Acc: 0.3500\n",
      "Epoch: 306, Train Acc: 0.3426, Test Acc: 0.3333\n",
      "Epoch: 307, Train Acc: 0.3685, Test Acc: 0.3500\n",
      "Epoch: 308, Train Acc: 0.3630, Test Acc: 0.3500\n",
      "Epoch: 309, Train Acc: 0.3500, Test Acc: 0.3667\n",
      "Epoch: 310, Train Acc: 0.3648, Test Acc: 0.3833\n",
      "Epoch: 311, Train Acc: 0.3574, Test Acc: 0.3167\n",
      "Epoch: 312, Train Acc: 0.3278, Test Acc: 0.3333\n",
      "Epoch: 313, Train Acc: 0.3667, Test Acc: 0.3500\n",
      "Epoch: 314, Train Acc: 0.3593, Test Acc: 0.4167\n",
      "Epoch: 315, Train Acc: 0.3574, Test Acc: 0.3500\n",
      "Epoch: 316, Train Acc: 0.3407, Test Acc: 0.2833\n",
      "Epoch: 317, Train Acc: 0.3537, Test Acc: 0.3833\n",
      "Epoch: 318, Train Acc: 0.3667, Test Acc: 0.3333\n",
      "Epoch: 319, Train Acc: 0.3259, Test Acc: 0.3500\n",
      "Epoch: 320, Train Acc: 0.3370, Test Acc: 0.3333\n",
      "Epoch: 321, Train Acc: 0.3056, Test Acc: 0.2500\n",
      "Epoch: 322, Train Acc: 0.3407, Test Acc: 0.2667\n",
      "Epoch: 323, Train Acc: 0.3407, Test Acc: 0.3000\n",
      "Epoch: 324, Train Acc: 0.3593, Test Acc: 0.3500\n",
      "Epoch: 325, Train Acc: 0.3593, Test Acc: 0.4167\n",
      "Epoch: 326, Train Acc: 0.3593, Test Acc: 0.3500\n",
      "Epoch: 327, Train Acc: 0.3630, Test Acc: 0.3667\n",
      "Epoch: 328, Train Acc: 0.3315, Test Acc: 0.2833\n",
      "Epoch: 329, Train Acc: 0.3444, Test Acc: 0.3500\n",
      "Epoch: 330, Train Acc: 0.3315, Test Acc: 0.3000\n",
      "Epoch: 331, Train Acc: 0.3481, Test Acc: 0.3333\n",
      "Epoch: 332, Train Acc: 0.3704, Test Acc: 0.3500\n",
      "Epoch: 333, Train Acc: 0.3759, Test Acc: 0.3333\n",
      "Epoch: 334, Train Acc: 0.3481, Test Acc: 0.3500\n",
      "Epoch: 335, Train Acc: 0.3259, Test Acc: 0.2833\n",
      "Epoch: 336, Train Acc: 0.3556, Test Acc: 0.3167\n",
      "Epoch: 337, Train Acc: 0.3667, Test Acc: 0.4000\n",
      "Epoch: 338, Train Acc: 0.3741, Test Acc: 0.3500\n",
      "Epoch: 339, Train Acc: 0.3759, Test Acc: 0.3333\n",
      "Epoch: 340, Train Acc: 0.3722, Test Acc: 0.3500\n",
      "Epoch: 341, Train Acc: 0.3722, Test Acc: 0.3833\n",
      "Epoch: 342, Train Acc: 0.3852, Test Acc: 0.3500\n",
      "Epoch: 343, Train Acc: 0.3759, Test Acc: 0.3500\n",
      "Epoch: 344, Train Acc: 0.3463, Test Acc: 0.3333\n",
      "Epoch: 345, Train Acc: 0.3889, Test Acc: 0.3333\n",
      "Epoch: 346, Train Acc: 0.3778, Test Acc: 0.3000\n",
      "Epoch: 347, Train Acc: 0.3407, Test Acc: 0.3000\n",
      "Epoch: 348, Train Acc: 0.3667, Test Acc: 0.3000\n",
      "Epoch: 349, Train Acc: 0.3759, Test Acc: 0.4000\n",
      "Epoch: 350, Train Acc: 0.3667, Test Acc: 0.3667\n",
      "Epoch: 351, Train Acc: 0.3685, Test Acc: 0.3167\n",
      "Epoch: 352, Train Acc: 0.3741, Test Acc: 0.3333\n",
      "Epoch: 353, Train Acc: 0.3722, Test Acc: 0.3500\n",
      "Epoch: 354, Train Acc: 0.3778, Test Acc: 0.3167\n",
      "Epoch: 355, Train Acc: 0.3315, Test Acc: 0.2333\n",
      "Epoch: 356, Train Acc: 0.3667, Test Acc: 0.2833\n",
      "Epoch: 357, Train Acc: 0.3611, Test Acc: 0.3833\n",
      "Epoch: 358, Train Acc: 0.3648, Test Acc: 0.4000\n",
      "Epoch: 359, Train Acc: 0.3741, Test Acc: 0.3667\n",
      "Epoch: 360, Train Acc: 0.3907, Test Acc: 0.3333\n",
      "Epoch: 361, Train Acc: 0.3722, Test Acc: 0.3500\n",
      "Epoch: 362, Train Acc: 0.3963, Test Acc: 0.3333\n",
      "Epoch: 363, Train Acc: 0.3907, Test Acc: 0.3167\n",
      "Epoch: 364, Train Acc: 0.3556, Test Acc: 0.3333\n",
      "Epoch: 365, Train Acc: 0.3574, Test Acc: 0.3333\n",
      "Epoch: 366, Train Acc: 0.3537, Test Acc: 0.2333\n",
      "Epoch: 367, Train Acc: 0.3889, Test Acc: 0.3167\n",
      "Epoch: 368, Train Acc: 0.3815, Test Acc: 0.3500\n",
      "Epoch: 369, Train Acc: 0.3556, Test Acc: 0.3167\n",
      "Epoch: 370, Train Acc: 0.3833, Test Acc: 0.3500\n",
      "Epoch: 371, Train Acc: 0.3722, Test Acc: 0.3167\n",
      "Epoch: 372, Train Acc: 0.3778, Test Acc: 0.3333\n",
      "Epoch: 373, Train Acc: 0.3870, Test Acc: 0.4000\n",
      "Epoch: 374, Train Acc: 0.3722, Test Acc: 0.3333\n",
      "Epoch: 375, Train Acc: 0.3685, Test Acc: 0.3167\n",
      "Epoch: 376, Train Acc: 0.3722, Test Acc: 0.3167\n",
      "Epoch: 377, Train Acc: 0.3704, Test Acc: 0.3667\n",
      "Epoch: 378, Train Acc: 0.3481, Test Acc: 0.2667\n",
      "Epoch: 379, Train Acc: 0.3667, Test Acc: 0.3667\n",
      "Epoch: 380, Train Acc: 0.3704, Test Acc: 0.3333\n",
      "Epoch: 381, Train Acc: 0.3759, Test Acc: 0.3333\n",
      "Epoch: 382, Train Acc: 0.3685, Test Acc: 0.3500\n",
      "Epoch: 383, Train Acc: 0.3741, Test Acc: 0.3500\n",
      "Epoch: 384, Train Acc: 0.3481, Test Acc: 0.3500\n",
      "Epoch: 385, Train Acc: 0.3667, Test Acc: 0.3333\n",
      "Epoch: 386, Train Acc: 0.3796, Test Acc: 0.3333\n",
      "Epoch: 387, Train Acc: 0.3648, Test Acc: 0.2833\n",
      "Epoch: 388, Train Acc: 0.3852, Test Acc: 0.3500\n",
      "Epoch: 389, Train Acc: 0.3759, Test Acc: 0.3833\n",
      "Epoch: 390, Train Acc: 0.3611, Test Acc: 0.3000\n",
      "Epoch: 391, Train Acc: 0.3852, Test Acc: 0.3333\n",
      "Epoch: 392, Train Acc: 0.3889, Test Acc: 0.3000\n",
      "Epoch: 393, Train Acc: 0.3630, Test Acc: 0.2667\n",
      "Epoch: 394, Train Acc: 0.3648, Test Acc: 0.2500\n",
      "Epoch: 395, Train Acc: 0.3593, Test Acc: 0.3167\n",
      "Epoch: 396, Train Acc: 0.3944, Test Acc: 0.3000\n",
      "Epoch: 397, Train Acc: 0.3685, Test Acc: 0.3500\n",
      "Epoch: 398, Train Acc: 0.3630, Test Acc: 0.3500\n",
      "Epoch: 399, Train Acc: 0.3611, Test Acc: 0.3500\n",
      "Epoch: 400, Train Acc: 0.3685, Test Acc: 0.2833\n",
      "Epoch: 401, Train Acc: 0.3796, Test Acc: 0.3000\n",
      "Epoch: 402, Train Acc: 0.3759, Test Acc: 0.2833\n",
      "Epoch: 403, Train Acc: 0.3315, Test Acc: 0.2833\n",
      "Epoch: 404, Train Acc: 0.3630, Test Acc: 0.3667\n",
      "Epoch: 405, Train Acc: 0.3741, Test Acc: 0.3167\n",
      "Epoch: 406, Train Acc: 0.3870, Test Acc: 0.3833\n",
      "Epoch: 407, Train Acc: 0.3796, Test Acc: 0.3333\n",
      "Epoch: 408, Train Acc: 0.4000, Test Acc: 0.3167\n",
      "Epoch: 409, Train Acc: 0.3648, Test Acc: 0.3167\n",
      "Epoch: 410, Train Acc: 0.3796, Test Acc: 0.3500\n",
      "Epoch: 411, Train Acc: 0.3778, Test Acc: 0.3500\n",
      "Epoch: 412, Train Acc: 0.3944, Test Acc: 0.3500\n",
      "Epoch: 413, Train Acc: 0.3889, Test Acc: 0.2833\n",
      "Epoch: 414, Train Acc: 0.3870, Test Acc: 0.2500\n",
      "Epoch: 415, Train Acc: 0.3926, Test Acc: 0.3333\n",
      "Epoch: 416, Train Acc: 0.3722, Test Acc: 0.3500\n",
      "Epoch: 417, Train Acc: 0.3593, Test Acc: 0.3000\n",
      "Epoch: 418, Train Acc: 0.3722, Test Acc: 0.3500\n",
      "Epoch: 419, Train Acc: 0.3778, Test Acc: 0.3167\n",
      "Epoch: 420, Train Acc: 0.3759, Test Acc: 0.3667\n",
      "Epoch: 421, Train Acc: 0.3815, Test Acc: 0.3000\n",
      "Epoch: 422, Train Acc: 0.3852, Test Acc: 0.3167\n",
      "Epoch: 423, Train Acc: 0.3870, Test Acc: 0.3000\n",
      "Epoch: 424, Train Acc: 0.3741, Test Acc: 0.3500\n",
      "Epoch: 425, Train Acc: 0.3944, Test Acc: 0.3000\n",
      "Epoch: 426, Train Acc: 0.3833, Test Acc: 0.3333\n",
      "Epoch: 427, Train Acc: 0.3852, Test Acc: 0.3000\n",
      "Epoch: 428, Train Acc: 0.3815, Test Acc: 0.2667\n",
      "Epoch: 429, Train Acc: 0.3889, Test Acc: 0.3500\n",
      "Epoch: 430, Train Acc: 0.3833, Test Acc: 0.2833\n",
      "Epoch: 431, Train Acc: 0.3944, Test Acc: 0.3167\n",
      "Epoch: 432, Train Acc: 0.3833, Test Acc: 0.3167\n",
      "Epoch: 433, Train Acc: 0.3722, Test Acc: 0.3167\n",
      "Epoch: 434, Train Acc: 0.3944, Test Acc: 0.3167\n",
      "Epoch: 435, Train Acc: 0.3907, Test Acc: 0.2333\n",
      "Epoch: 436, Train Acc: 0.3944, Test Acc: 0.3500\n",
      "Epoch: 437, Train Acc: 0.3796, Test Acc: 0.3333\n",
      "Epoch: 438, Train Acc: 0.3852, Test Acc: 0.3167\n",
      "Epoch: 439, Train Acc: 0.3889, Test Acc: 0.2667\n",
      "Epoch: 440, Train Acc: 0.4019, Test Acc: 0.3167\n",
      "Epoch: 441, Train Acc: 0.3944, Test Acc: 0.3167\n",
      "Epoch: 442, Train Acc: 0.3870, Test Acc: 0.3000\n",
      "Epoch: 443, Train Acc: 0.3870, Test Acc: 0.3500\n",
      "Epoch: 444, Train Acc: 0.3926, Test Acc: 0.3167\n",
      "Epoch: 445, Train Acc: 0.3833, Test Acc: 0.3333\n",
      "Epoch: 446, Train Acc: 0.3833, Test Acc: 0.3333\n",
      "Epoch: 447, Train Acc: 0.3796, Test Acc: 0.2500\n",
      "Epoch: 448, Train Acc: 0.3833, Test Acc: 0.3500\n",
      "Epoch: 449, Train Acc: 0.3907, Test Acc: 0.2667\n",
      "Epoch: 450, Train Acc: 0.3870, Test Acc: 0.3167\n",
      "Epoch: 451, Train Acc: 0.4278, Test Acc: 0.3500\n",
      "Epoch: 452, Train Acc: 0.4241, Test Acc: 0.3333\n",
      "Epoch: 453, Train Acc: 0.3926, Test Acc: 0.2833\n",
      "Epoch: 454, Train Acc: 0.4111, Test Acc: 0.3500\n",
      "Epoch: 455, Train Acc: 0.4185, Test Acc: 0.3667\n",
      "Epoch: 456, Train Acc: 0.4037, Test Acc: 0.3333\n",
      "Epoch: 457, Train Acc: 0.3944, Test Acc: 0.3333\n",
      "Epoch: 458, Train Acc: 0.3796, Test Acc: 0.2833\n",
      "Epoch: 459, Train Acc: 0.3463, Test Acc: 0.3333\n",
      "Epoch: 460, Train Acc: 0.4074, Test Acc: 0.3167\n",
      "Epoch: 461, Train Acc: 0.4037, Test Acc: 0.3167\n",
      "Epoch: 462, Train Acc: 0.3907, Test Acc: 0.2833\n",
      "Epoch: 463, Train Acc: 0.3648, Test Acc: 0.3167\n",
      "Epoch: 464, Train Acc: 0.3815, Test Acc: 0.2333\n",
      "Epoch: 465, Train Acc: 0.4000, Test Acc: 0.3167\n",
      "Epoch: 466, Train Acc: 0.3981, Test Acc: 0.3167\n",
      "Epoch: 467, Train Acc: 0.4019, Test Acc: 0.3000\n",
      "Epoch: 468, Train Acc: 0.4037, Test Acc: 0.3167\n",
      "Epoch: 469, Train Acc: 0.3944, Test Acc: 0.2833\n",
      "Epoch: 470, Train Acc: 0.4019, Test Acc: 0.3333\n",
      "Epoch: 471, Train Acc: 0.4222, Test Acc: 0.3333\n",
      "Epoch: 472, Train Acc: 0.3889, Test Acc: 0.3333\n",
      "Epoch: 473, Train Acc: 0.4148, Test Acc: 0.3833\n",
      "Epoch: 474, Train Acc: 0.3833, Test Acc: 0.3000\n",
      "Epoch: 475, Train Acc: 0.3907, Test Acc: 0.3333\n",
      "Epoch: 476, Train Acc: 0.4315, Test Acc: 0.3333\n",
      "Epoch: 477, Train Acc: 0.4185, Test Acc: 0.3500\n",
      "Epoch: 478, Train Acc: 0.4167, Test Acc: 0.3500\n",
      "Epoch: 479, Train Acc: 0.3648, Test Acc: 0.2833\n",
      "Epoch: 480, Train Acc: 0.4111, Test Acc: 0.3500\n",
      "Epoch: 481, Train Acc: 0.4370, Test Acc: 0.3000\n",
      "Epoch: 482, Train Acc: 0.4093, Test Acc: 0.4000\n",
      "Epoch: 483, Train Acc: 0.4296, Test Acc: 0.3167\n",
      "Epoch: 484, Train Acc: 0.4037, Test Acc: 0.3500\n",
      "Epoch: 485, Train Acc: 0.4167, Test Acc: 0.3000\n",
      "Epoch: 486, Train Acc: 0.4037, Test Acc: 0.3000\n",
      "Epoch: 487, Train Acc: 0.3796, Test Acc: 0.3500\n",
      "Epoch: 488, Train Acc: 0.4148, Test Acc: 0.3167\n",
      "Epoch: 489, Train Acc: 0.4278, Test Acc: 0.3167\n",
      "Epoch: 490, Train Acc: 0.3981, Test Acc: 0.2667\n",
      "Epoch: 491, Train Acc: 0.4130, Test Acc: 0.3333\n",
      "Epoch: 492, Train Acc: 0.4000, Test Acc: 0.3667\n",
      "Epoch: 493, Train Acc: 0.3852, Test Acc: 0.3500\n",
      "Epoch: 494, Train Acc: 0.4019, Test Acc: 0.3667\n",
      "Epoch: 495, Train Acc: 0.4167, Test Acc: 0.3167\n",
      "Epoch: 496, Train Acc: 0.4037, Test Acc: 0.3000\n",
      "Epoch: 497, Train Acc: 0.4259, Test Acc: 0.3500\n",
      "Epoch: 498, Train Acc: 0.4315, Test Acc: 0.3333\n",
      "Epoch: 499, Train Acc: 0.4056, Test Acc: 0.3333\n",
      "Epoch: 500, Train Acc: 0.4167, Test Acc: 0.3667\n",
      "Epoch: 501, Train Acc: 0.4130, Test Acc: 0.3333\n",
      "Epoch: 502, Train Acc: 0.4167, Test Acc: 0.3167\n",
      "Epoch: 503, Train Acc: 0.4426, Test Acc: 0.3333\n",
      "Epoch: 504, Train Acc: 0.3963, Test Acc: 0.3333\n",
      "Epoch: 505, Train Acc: 0.4278, Test Acc: 0.3667\n",
      "Epoch: 506, Train Acc: 0.4185, Test Acc: 0.3667\n",
      "Epoch: 507, Train Acc: 0.4148, Test Acc: 0.3167\n",
      "Epoch: 508, Train Acc: 0.4407, Test Acc: 0.3500\n",
      "Epoch: 509, Train Acc: 0.4315, Test Acc: 0.3333\n",
      "Epoch: 510, Train Acc: 0.4259, Test Acc: 0.3333\n",
      "Epoch: 511, Train Acc: 0.4278, Test Acc: 0.3167\n",
      "Epoch: 512, Train Acc: 0.3889, Test Acc: 0.3333\n",
      "Epoch: 513, Train Acc: 0.4037, Test Acc: 0.3667\n",
      "Epoch: 514, Train Acc: 0.4296, Test Acc: 0.3500\n",
      "Epoch: 515, Train Acc: 0.4296, Test Acc: 0.3167\n",
      "Epoch: 516, Train Acc: 0.4259, Test Acc: 0.3333\n",
      "Epoch: 517, Train Acc: 0.3907, Test Acc: 0.3000\n",
      "Epoch: 518, Train Acc: 0.4185, Test Acc: 0.4000\n",
      "Epoch: 519, Train Acc: 0.4204, Test Acc: 0.3500\n",
      "Epoch: 520, Train Acc: 0.4111, Test Acc: 0.3833\n",
      "Epoch: 521, Train Acc: 0.4167, Test Acc: 0.3333\n",
      "Epoch: 522, Train Acc: 0.4296, Test Acc: 0.4000\n",
      "Epoch: 523, Train Acc: 0.4296, Test Acc: 0.3500\n",
      "Epoch: 524, Train Acc: 0.4296, Test Acc: 0.3500\n",
      "Epoch: 525, Train Acc: 0.4315, Test Acc: 0.3833\n",
      "Epoch: 526, Train Acc: 0.4296, Test Acc: 0.3333\n",
      "Epoch: 527, Train Acc: 0.4130, Test Acc: 0.3500\n",
      "Epoch: 528, Train Acc: 0.4519, Test Acc: 0.3500\n",
      "Epoch: 529, Train Acc: 0.4204, Test Acc: 0.3500\n",
      "Epoch: 530, Train Acc: 0.4296, Test Acc: 0.3500\n",
      "Epoch: 531, Train Acc: 0.4463, Test Acc: 0.3667\n",
      "Epoch: 532, Train Acc: 0.4296, Test Acc: 0.3500\n",
      "Epoch: 533, Train Acc: 0.4685, Test Acc: 0.3833\n",
      "Epoch: 534, Train Acc: 0.3574, Test Acc: 0.3167\n",
      "Epoch: 535, Train Acc: 0.4296, Test Acc: 0.3167\n",
      "Epoch: 536, Train Acc: 0.3907, Test Acc: 0.3167\n",
      "Epoch: 537, Train Acc: 0.4111, Test Acc: 0.3500\n",
      "Epoch: 538, Train Acc: 0.3963, Test Acc: 0.4000\n",
      "Epoch: 539, Train Acc: 0.3981, Test Acc: 0.3833\n",
      "Epoch: 540, Train Acc: 0.3889, Test Acc: 0.3167\n",
      "Epoch: 541, Train Acc: 0.4185, Test Acc: 0.3667\n",
      "Epoch: 542, Train Acc: 0.4222, Test Acc: 0.3500\n",
      "Epoch: 543, Train Acc: 0.4167, Test Acc: 0.4000\n",
      "Epoch: 544, Train Acc: 0.4204, Test Acc: 0.3833\n",
      "Epoch: 545, Train Acc: 0.4463, Test Acc: 0.3333\n",
      "Epoch: 546, Train Acc: 0.4241, Test Acc: 0.3833\n",
      "Epoch: 547, Train Acc: 0.3815, Test Acc: 0.3500\n",
      "Epoch: 548, Train Acc: 0.4315, Test Acc: 0.3833\n",
      "Epoch: 549, Train Acc: 0.4389, Test Acc: 0.3500\n",
      "Epoch: 550, Train Acc: 0.4278, Test Acc: 0.3667\n",
      "Epoch: 551, Train Acc: 0.4333, Test Acc: 0.3167\n",
      "Epoch: 552, Train Acc: 0.4278, Test Acc: 0.3333\n",
      "Epoch: 553, Train Acc: 0.4315, Test Acc: 0.3167\n",
      "Epoch: 554, Train Acc: 0.4389, Test Acc: 0.3167\n",
      "Epoch: 555, Train Acc: 0.4370, Test Acc: 0.3333\n",
      "Epoch: 556, Train Acc: 0.4019, Test Acc: 0.3333\n",
      "Epoch: 557, Train Acc: 0.4296, Test Acc: 0.3167\n",
      "Epoch: 558, Train Acc: 0.4259, Test Acc: 0.3333\n",
      "Epoch: 559, Train Acc: 0.4352, Test Acc: 0.4000\n",
      "Epoch: 560, Train Acc: 0.4333, Test Acc: 0.3833\n",
      "Epoch: 561, Train Acc: 0.4500, Test Acc: 0.3000\n",
      "Epoch: 562, Train Acc: 0.4481, Test Acc: 0.3333\n",
      "Epoch: 563, Train Acc: 0.4333, Test Acc: 0.3667\n",
      "Epoch: 564, Train Acc: 0.4444, Test Acc: 0.3000\n",
      "Epoch: 565, Train Acc: 0.4259, Test Acc: 0.3500\n",
      "Epoch: 566, Train Acc: 0.4278, Test Acc: 0.3000\n",
      "Epoch: 567, Train Acc: 0.4130, Test Acc: 0.3833\n",
      "Epoch: 568, Train Acc: 0.4185, Test Acc: 0.3000\n",
      "Epoch: 569, Train Acc: 0.4315, Test Acc: 0.3167\n",
      "Epoch: 570, Train Acc: 0.4352, Test Acc: 0.3000\n",
      "Epoch: 571, Train Acc: 0.4259, Test Acc: 0.3167\n",
      "Epoch: 572, Train Acc: 0.4370, Test Acc: 0.3333\n",
      "Epoch: 573, Train Acc: 0.4333, Test Acc: 0.3167\n",
      "Epoch: 574, Train Acc: 0.4259, Test Acc: 0.3167\n",
      "Epoch: 575, Train Acc: 0.4481, Test Acc: 0.3500\n",
      "Epoch: 576, Train Acc: 0.4278, Test Acc: 0.3833\n",
      "Epoch: 577, Train Acc: 0.4426, Test Acc: 0.3000\n",
      "Epoch: 578, Train Acc: 0.4130, Test Acc: 0.3333\n",
      "Epoch: 579, Train Acc: 0.4426, Test Acc: 0.3500\n",
      "Epoch: 580, Train Acc: 0.4315, Test Acc: 0.3833\n",
      "Epoch: 581, Train Acc: 0.4370, Test Acc: 0.3167\n",
      "Epoch: 582, Train Acc: 0.4574, Test Acc: 0.3500\n",
      "Epoch: 583, Train Acc: 0.4204, Test Acc: 0.3667\n",
      "Epoch: 584, Train Acc: 0.3963, Test Acc: 0.3000\n",
      "Epoch: 585, Train Acc: 0.4352, Test Acc: 0.3500\n",
      "Epoch: 586, Train Acc: 0.4278, Test Acc: 0.3500\n",
      "Epoch: 587, Train Acc: 0.4352, Test Acc: 0.3333\n",
      "Epoch: 588, Train Acc: 0.4444, Test Acc: 0.3333\n",
      "Epoch: 589, Train Acc: 0.4296, Test Acc: 0.3333\n",
      "Epoch: 590, Train Acc: 0.4148, Test Acc: 0.3667\n",
      "Epoch: 591, Train Acc: 0.4352, Test Acc: 0.3333\n",
      "Epoch: 592, Train Acc: 0.4519, Test Acc: 0.2833\n",
      "Epoch: 593, Train Acc: 0.4315, Test Acc: 0.3167\n",
      "Epoch: 594, Train Acc: 0.4648, Test Acc: 0.3333\n",
      "Epoch: 595, Train Acc: 0.4463, Test Acc: 0.3000\n",
      "Epoch: 596, Train Acc: 0.4296, Test Acc: 0.3000\n",
      "Epoch: 597, Train Acc: 0.4370, Test Acc: 0.3500\n",
      "Epoch: 598, Train Acc: 0.4389, Test Acc: 0.3667\n",
      "Epoch: 599, Train Acc: 0.4463, Test Acc: 0.3333\n",
      "Epoch: 600, Train Acc: 0.4352, Test Acc: 0.3167\n",
      "Epoch: 601, Train Acc: 0.4574, Test Acc: 0.3333\n",
      "Epoch: 602, Train Acc: 0.4648, Test Acc: 0.3167\n",
      "Epoch: 603, Train Acc: 0.4222, Test Acc: 0.3833\n",
      "Epoch: 604, Train Acc: 0.4148, Test Acc: 0.3667\n",
      "Epoch: 605, Train Acc: 0.4167, Test Acc: 0.3167\n",
      "Epoch: 606, Train Acc: 0.4111, Test Acc: 0.3333\n",
      "Epoch: 607, Train Acc: 0.4463, Test Acc: 0.3667\n",
      "Epoch: 608, Train Acc: 0.4556, Test Acc: 0.3500\n",
      "Epoch: 609, Train Acc: 0.4167, Test Acc: 0.3167\n",
      "Epoch: 610, Train Acc: 0.4278, Test Acc: 0.3333\n",
      "Epoch: 611, Train Acc: 0.4204, Test Acc: 0.3833\n",
      "Epoch: 612, Train Acc: 0.3926, Test Acc: 0.3167\n",
      "Epoch: 613, Train Acc: 0.4389, Test Acc: 0.3833\n",
      "Epoch: 614, Train Acc: 0.4148, Test Acc: 0.3333\n",
      "Epoch: 615, Train Acc: 0.4352, Test Acc: 0.3500\n",
      "Epoch: 616, Train Acc: 0.4500, Test Acc: 0.3333\n",
      "Epoch: 617, Train Acc: 0.4519, Test Acc: 0.3167\n",
      "Epoch: 618, Train Acc: 0.4333, Test Acc: 0.3167\n",
      "Epoch: 619, Train Acc: 0.4259, Test Acc: 0.3167\n",
      "Epoch: 620, Train Acc: 0.4537, Test Acc: 0.3833\n",
      "Epoch: 621, Train Acc: 0.4593, Test Acc: 0.3667\n",
      "Epoch: 622, Train Acc: 0.4574, Test Acc: 0.3667\n",
      "Epoch: 623, Train Acc: 0.4593, Test Acc: 0.3500\n",
      "Epoch: 624, Train Acc: 0.4444, Test Acc: 0.3000\n",
      "Epoch: 625, Train Acc: 0.4556, Test Acc: 0.3833\n",
      "Epoch: 626, Train Acc: 0.4574, Test Acc: 0.3500\n",
      "Epoch: 627, Train Acc: 0.4556, Test Acc: 0.3167\n",
      "Epoch: 628, Train Acc: 0.4185, Test Acc: 0.3167\n",
      "Epoch: 629, Train Acc: 0.4389, Test Acc: 0.3333\n",
      "Epoch: 630, Train Acc: 0.4296, Test Acc: 0.3167\n",
      "Epoch: 631, Train Acc: 0.4537, Test Acc: 0.3500\n",
      "Epoch: 632, Train Acc: 0.3981, Test Acc: 0.3333\n",
      "Epoch: 633, Train Acc: 0.3907, Test Acc: 0.3167\n",
      "Epoch: 634, Train Acc: 0.4407, Test Acc: 0.3167\n",
      "Epoch: 635, Train Acc: 0.4463, Test Acc: 0.3500\n",
      "Epoch: 636, Train Acc: 0.4537, Test Acc: 0.3167\n",
      "Epoch: 637, Train Acc: 0.4593, Test Acc: 0.3500\n",
      "Epoch: 638, Train Acc: 0.4519, Test Acc: 0.3167\n",
      "Epoch: 639, Train Acc: 0.4593, Test Acc: 0.3167\n",
      "Epoch: 640, Train Acc: 0.4463, Test Acc: 0.3833\n",
      "Epoch: 641, Train Acc: 0.4481, Test Acc: 0.3333\n",
      "Epoch: 642, Train Acc: 0.4111, Test Acc: 0.3167\n",
      "Epoch: 643, Train Acc: 0.4241, Test Acc: 0.3833\n",
      "Epoch: 644, Train Acc: 0.4574, Test Acc: 0.3500\n",
      "Epoch: 645, Train Acc: 0.4537, Test Acc: 0.3167\n",
      "Epoch: 646, Train Acc: 0.4389, Test Acc: 0.3667\n",
      "Epoch: 647, Train Acc: 0.4500, Test Acc: 0.3000\n",
      "Epoch: 648, Train Acc: 0.4296, Test Acc: 0.3167\n",
      "Epoch: 649, Train Acc: 0.4407, Test Acc: 0.3667\n",
      "Epoch: 650, Train Acc: 0.4463, Test Acc: 0.3333\n",
      "Epoch: 651, Train Acc: 0.4259, Test Acc: 0.3667\n",
      "Epoch: 652, Train Acc: 0.4370, Test Acc: 0.3167\n",
      "Epoch: 653, Train Acc: 0.4611, Test Acc: 0.3333\n",
      "Epoch: 654, Train Acc: 0.4000, Test Acc: 0.3000\n",
      "Epoch: 655, Train Acc: 0.4333, Test Acc: 0.3167\n",
      "Epoch: 656, Train Acc: 0.4370, Test Acc: 0.3833\n",
      "Epoch: 657, Train Acc: 0.4426, Test Acc: 0.2833\n",
      "Epoch: 658, Train Acc: 0.4389, Test Acc: 0.3500\n",
      "Epoch: 659, Train Acc: 0.4241, Test Acc: 0.3333\n",
      "Epoch: 660, Train Acc: 0.4537, Test Acc: 0.3833\n",
      "Epoch: 661, Train Acc: 0.4111, Test Acc: 0.3500\n",
      "Epoch: 662, Train Acc: 0.4593, Test Acc: 0.3333\n",
      "Epoch: 663, Train Acc: 0.4333, Test Acc: 0.2833\n",
      "Epoch: 664, Train Acc: 0.4519, Test Acc: 0.3333\n",
      "Epoch: 665, Train Acc: 0.4463, Test Acc: 0.3000\n",
      "Epoch: 666, Train Acc: 0.4593, Test Acc: 0.3333\n",
      "Epoch: 667, Train Acc: 0.4630, Test Acc: 0.3333\n",
      "Epoch: 668, Train Acc: 0.4074, Test Acc: 0.3000\n",
      "Epoch: 669, Train Acc: 0.4426, Test Acc: 0.3500\n",
      "Epoch: 670, Train Acc: 0.4204, Test Acc: 0.3000\n",
      "Epoch: 671, Train Acc: 0.4333, Test Acc: 0.3500\n",
      "Epoch: 672, Train Acc: 0.4481, Test Acc: 0.3167\n",
      "Epoch: 673, Train Acc: 0.4389, Test Acc: 0.3333\n",
      "Epoch: 674, Train Acc: 0.4500, Test Acc: 0.3500\n",
      "Epoch: 675, Train Acc: 0.4148, Test Acc: 0.3667\n",
      "Epoch: 676, Train Acc: 0.4574, Test Acc: 0.4000\n",
      "Epoch: 677, Train Acc: 0.4500, Test Acc: 0.2833\n",
      "Epoch: 678, Train Acc: 0.4444, Test Acc: 0.4000\n",
      "Epoch: 679, Train Acc: 0.3759, Test Acc: 0.3167\n",
      "Epoch: 680, Train Acc: 0.4630, Test Acc: 0.3500\n",
      "Epoch: 681, Train Acc: 0.4574, Test Acc: 0.3500\n",
      "Epoch: 682, Train Acc: 0.4537, Test Acc: 0.3167\n",
      "Epoch: 683, Train Acc: 0.4537, Test Acc: 0.3667\n",
      "Epoch: 684, Train Acc: 0.4481, Test Acc: 0.3000\n",
      "Epoch: 685, Train Acc: 0.4648, Test Acc: 0.3667\n",
      "Epoch: 686, Train Acc: 0.3981, Test Acc: 0.3333\n",
      "Epoch: 687, Train Acc: 0.4241, Test Acc: 0.3167\n",
      "Epoch: 688, Train Acc: 0.4222, Test Acc: 0.3833\n",
      "Epoch: 689, Train Acc: 0.4426, Test Acc: 0.3333\n",
      "Epoch: 690, Train Acc: 0.4630, Test Acc: 0.3667\n",
      "Epoch: 691, Train Acc: 0.4667, Test Acc: 0.3500\n",
      "Epoch: 692, Train Acc: 0.4296, Test Acc: 0.3500\n",
      "Epoch: 693, Train Acc: 0.4519, Test Acc: 0.4000\n",
      "Epoch: 694, Train Acc: 0.4481, Test Acc: 0.3833\n",
      "Epoch: 695, Train Acc: 0.4519, Test Acc: 0.3333\n",
      "Epoch: 696, Train Acc: 0.4389, Test Acc: 0.3667\n",
      "Epoch: 697, Train Acc: 0.4204, Test Acc: 0.3333\n",
      "Epoch: 698, Train Acc: 0.4630, Test Acc: 0.3500\n",
      "Epoch: 699, Train Acc: 0.4370, Test Acc: 0.3833\n",
      "Epoch: 700, Train Acc: 0.4556, Test Acc: 0.3667\n",
      "Epoch: 701, Train Acc: 0.4574, Test Acc: 0.3000\n",
      "Epoch: 702, Train Acc: 0.4370, Test Acc: 0.3667\n",
      "Epoch: 703, Train Acc: 0.3944, Test Acc: 0.2833\n",
      "Epoch: 704, Train Acc: 0.4222, Test Acc: 0.3333\n",
      "Epoch: 705, Train Acc: 0.4519, Test Acc: 0.3333\n",
      "Epoch: 706, Train Acc: 0.4704, Test Acc: 0.3667\n",
      "Epoch: 707, Train Acc: 0.3815, Test Acc: 0.2833\n",
      "Epoch: 708, Train Acc: 0.4370, Test Acc: 0.4000\n",
      "Epoch: 709, Train Acc: 0.4481, Test Acc: 0.3333\n",
      "Epoch: 710, Train Acc: 0.4593, Test Acc: 0.3667\n",
      "Epoch: 711, Train Acc: 0.4185, Test Acc: 0.3833\n",
      "Epoch: 712, Train Acc: 0.4407, Test Acc: 0.3333\n",
      "Epoch: 713, Train Acc: 0.3944, Test Acc: 0.3000\n",
      "Epoch: 714, Train Acc: 0.4370, Test Acc: 0.3833\n",
      "Epoch: 715, Train Acc: 0.4037, Test Acc: 0.3167\n",
      "Epoch: 716, Train Acc: 0.4333, Test Acc: 0.3667\n",
      "Epoch: 717, Train Acc: 0.4444, Test Acc: 0.3000\n",
      "Epoch: 718, Train Acc: 0.4556, Test Acc: 0.3333\n",
      "Epoch: 719, Train Acc: 0.4444, Test Acc: 0.3000\n",
      "Epoch: 720, Train Acc: 0.4519, Test Acc: 0.3333\n",
      "Epoch: 721, Train Acc: 0.4407, Test Acc: 0.3500\n",
      "Epoch: 722, Train Acc: 0.3852, Test Acc: 0.2833\n",
      "Epoch: 723, Train Acc: 0.4167, Test Acc: 0.3833\n",
      "Epoch: 724, Train Acc: 0.4074, Test Acc: 0.3000\n",
      "Epoch: 725, Train Acc: 0.4500, Test Acc: 0.3167\n",
      "Epoch: 726, Train Acc: 0.4463, Test Acc: 0.4167\n",
      "Epoch: 727, Train Acc: 0.4000, Test Acc: 0.3000\n",
      "Epoch: 728, Train Acc: 0.4630, Test Acc: 0.3000\n",
      "Epoch: 729, Train Acc: 0.4241, Test Acc: 0.3500\n",
      "Epoch: 730, Train Acc: 0.4296, Test Acc: 0.3333\n",
      "Epoch: 731, Train Acc: 0.4648, Test Acc: 0.3333\n",
      "Epoch: 732, Train Acc: 0.4389, Test Acc: 0.3667\n",
      "Epoch: 733, Train Acc: 0.4204, Test Acc: 0.3500\n",
      "Epoch: 734, Train Acc: 0.4500, Test Acc: 0.3000\n",
      "Epoch: 735, Train Acc: 0.4426, Test Acc: 0.3167\n",
      "Epoch: 736, Train Acc: 0.4481, Test Acc: 0.3000\n",
      "Epoch: 737, Train Acc: 0.4556, Test Acc: 0.3667\n",
      "Epoch: 738, Train Acc: 0.4519, Test Acc: 0.3000\n",
      "Epoch: 739, Train Acc: 0.4444, Test Acc: 0.3500\n",
      "Epoch: 740, Train Acc: 0.4370, Test Acc: 0.3000\n",
      "Epoch: 741, Train Acc: 0.4500, Test Acc: 0.3333\n",
      "Epoch: 742, Train Acc: 0.4259, Test Acc: 0.3000\n",
      "Epoch: 743, Train Acc: 0.4481, Test Acc: 0.3167\n",
      "Epoch: 744, Train Acc: 0.4722, Test Acc: 0.3167\n",
      "Epoch: 745, Train Acc: 0.4167, Test Acc: 0.3500\n",
      "Epoch: 746, Train Acc: 0.4574, Test Acc: 0.3500\n",
      "Epoch: 747, Train Acc: 0.4574, Test Acc: 0.3000\n",
      "Epoch: 748, Train Acc: 0.4037, Test Acc: 0.3667\n",
      "Epoch: 749, Train Acc: 0.4130, Test Acc: 0.3167\n",
      "Epoch: 750, Train Acc: 0.4407, Test Acc: 0.4000\n",
      "Epoch: 751, Train Acc: 0.4389, Test Acc: 0.2667\n",
      "Epoch: 752, Train Acc: 0.4611, Test Acc: 0.3167\n",
      "Epoch: 753, Train Acc: 0.4481, Test Acc: 0.3167\n",
      "Epoch: 754, Train Acc: 0.4537, Test Acc: 0.3000\n",
      "Epoch: 755, Train Acc: 0.4481, Test Acc: 0.3000\n",
      "Epoch: 756, Train Acc: 0.4611, Test Acc: 0.3000\n",
      "Epoch: 757, Train Acc: 0.4463, Test Acc: 0.3500\n",
      "Epoch: 758, Train Acc: 0.4315, Test Acc: 0.3333\n",
      "Epoch: 759, Train Acc: 0.4259, Test Acc: 0.3000\n",
      "Epoch: 760, Train Acc: 0.4556, Test Acc: 0.3500\n",
      "Epoch: 761, Train Acc: 0.4056, Test Acc: 0.3500\n",
      "Epoch: 762, Train Acc: 0.4593, Test Acc: 0.3333\n",
      "Epoch: 763, Train Acc: 0.4574, Test Acc: 0.3333\n",
      "Epoch: 764, Train Acc: 0.4537, Test Acc: 0.2833\n",
      "Epoch: 765, Train Acc: 0.4611, Test Acc: 0.3000\n",
      "Epoch: 766, Train Acc: 0.4481, Test Acc: 0.3000\n",
      "Epoch: 767, Train Acc: 0.4333, Test Acc: 0.3333\n",
      "Epoch: 768, Train Acc: 0.4574, Test Acc: 0.3167\n",
      "Epoch: 769, Train Acc: 0.4241, Test Acc: 0.2667\n",
      "Epoch: 770, Train Acc: 0.4426, Test Acc: 0.3167\n",
      "Epoch: 771, Train Acc: 0.4574, Test Acc: 0.3167\n",
      "Epoch: 772, Train Acc: 0.4519, Test Acc: 0.3000\n",
      "Epoch: 773, Train Acc: 0.4537, Test Acc: 0.3833\n",
      "Epoch: 774, Train Acc: 0.4574, Test Acc: 0.3833\n",
      "Epoch: 775, Train Acc: 0.4611, Test Acc: 0.3333\n",
      "Epoch: 776, Train Acc: 0.3963, Test Acc: 0.3500\n",
      "Epoch: 777, Train Acc: 0.3926, Test Acc: 0.2833\n",
      "Epoch: 778, Train Acc: 0.4389, Test Acc: 0.4000\n",
      "Epoch: 779, Train Acc: 0.4296, Test Acc: 0.2833\n",
      "Epoch: 780, Train Acc: 0.4574, Test Acc: 0.3500\n",
      "Epoch: 781, Train Acc: 0.4259, Test Acc: 0.2500\n",
      "Epoch: 782, Train Acc: 0.4278, Test Acc: 0.3333\n",
      "Epoch: 783, Train Acc: 0.4111, Test Acc: 0.2833\n",
      "Epoch: 784, Train Acc: 0.4407, Test Acc: 0.3833\n",
      "Epoch: 785, Train Acc: 0.4111, Test Acc: 0.2833\n",
      "Epoch: 786, Train Acc: 0.4333, Test Acc: 0.3667\n",
      "Epoch: 787, Train Acc: 0.4537, Test Acc: 0.2833\n",
      "Epoch: 788, Train Acc: 0.4352, Test Acc: 0.3167\n",
      "Epoch: 789, Train Acc: 0.4481, Test Acc: 0.3167\n",
      "Epoch: 790, Train Acc: 0.4426, Test Acc: 0.2833\n",
      "Epoch: 791, Train Acc: 0.4519, Test Acc: 0.3167\n",
      "Epoch: 792, Train Acc: 0.4352, Test Acc: 0.3000\n",
      "Epoch: 793, Train Acc: 0.4463, Test Acc: 0.2833\n",
      "Epoch: 794, Train Acc: 0.4463, Test Acc: 0.3167\n",
      "Epoch: 795, Train Acc: 0.4370, Test Acc: 0.3167\n",
      "Epoch: 796, Train Acc: 0.4537, Test Acc: 0.3333\n",
      "Epoch: 797, Train Acc: 0.4074, Test Acc: 0.3167\n",
      "Epoch: 798, Train Acc: 0.4593, Test Acc: 0.3000\n",
      "Epoch: 799, Train Acc: 0.4667, Test Acc: 0.3500\n",
      "Epoch: 800, Train Acc: 0.4370, Test Acc: 0.3167\n",
      "Epoch: 801, Train Acc: 0.4630, Test Acc: 0.3167\n",
      "Epoch: 802, Train Acc: 0.4537, Test Acc: 0.3000\n",
      "Epoch: 803, Train Acc: 0.4444, Test Acc: 0.3000\n",
      "Epoch: 804, Train Acc: 0.4407, Test Acc: 0.3500\n",
      "Epoch: 805, Train Acc: 0.4407, Test Acc: 0.3167\n",
      "Epoch: 806, Train Acc: 0.4593, Test Acc: 0.3000\n",
      "Epoch: 807, Train Acc: 0.4426, Test Acc: 0.3000\n",
      "Epoch: 808, Train Acc: 0.4444, Test Acc: 0.3500\n",
      "Epoch: 809, Train Acc: 0.4463, Test Acc: 0.2667\n",
      "Epoch: 810, Train Acc: 0.4630, Test Acc: 0.3333\n",
      "Epoch: 811, Train Acc: 0.4630, Test Acc: 0.3333\n",
      "Epoch: 812, Train Acc: 0.3944, Test Acc: 0.2833\n",
      "Epoch: 813, Train Acc: 0.4741, Test Acc: 0.3167\n",
      "Epoch: 814, Train Acc: 0.4593, Test Acc: 0.3667\n",
      "Epoch: 815, Train Acc: 0.4426, Test Acc: 0.2667\n",
      "Epoch: 816, Train Acc: 0.4556, Test Acc: 0.3000\n",
      "Epoch: 817, Train Acc: 0.4519, Test Acc: 0.3333\n",
      "Epoch: 818, Train Acc: 0.4315, Test Acc: 0.2833\n",
      "Epoch: 819, Train Acc: 0.4704, Test Acc: 0.3000\n",
      "Epoch: 820, Train Acc: 0.4574, Test Acc: 0.3000\n",
      "Epoch: 821, Train Acc: 0.4537, Test Acc: 0.3500\n",
      "Epoch: 822, Train Acc: 0.4463, Test Acc: 0.3333\n",
      "Epoch: 823, Train Acc: 0.4259, Test Acc: 0.3000\n",
      "Epoch: 824, Train Acc: 0.4278, Test Acc: 0.2500\n",
      "Epoch: 825, Train Acc: 0.4444, Test Acc: 0.2500\n",
      "Epoch: 826, Train Acc: 0.4389, Test Acc: 0.2500\n",
      "Epoch: 827, Train Acc: 0.4389, Test Acc: 0.3167\n",
      "Epoch: 828, Train Acc: 0.4167, Test Acc: 0.2500\n",
      "Epoch: 829, Train Acc: 0.4426, Test Acc: 0.3333\n",
      "Epoch: 830, Train Acc: 0.4204, Test Acc: 0.2833\n",
      "Epoch: 831, Train Acc: 0.4407, Test Acc: 0.3167\n",
      "Epoch: 832, Train Acc: 0.4259, Test Acc: 0.2833\n",
      "Epoch: 833, Train Acc: 0.4519, Test Acc: 0.3500\n",
      "Epoch: 834, Train Acc: 0.4407, Test Acc: 0.2667\n",
      "Epoch: 835, Train Acc: 0.4278, Test Acc: 0.3000\n",
      "Epoch: 836, Train Acc: 0.4222, Test Acc: 0.3000\n",
      "Epoch: 837, Train Acc: 0.4407, Test Acc: 0.3333\n",
      "Epoch: 838, Train Acc: 0.4611, Test Acc: 0.3333\n",
      "Epoch: 839, Train Acc: 0.4537, Test Acc: 0.3167\n",
      "Epoch: 840, Train Acc: 0.4407, Test Acc: 0.3333\n",
      "Epoch: 841, Train Acc: 0.4648, Test Acc: 0.3500\n",
      "Epoch: 842, Train Acc: 0.4204, Test Acc: 0.2667\n",
      "Epoch: 843, Train Acc: 0.4315, Test Acc: 0.2667\n",
      "Epoch: 844, Train Acc: 0.4389, Test Acc: 0.3833\n",
      "Epoch: 845, Train Acc: 0.4204, Test Acc: 0.3000\n",
      "Epoch: 846, Train Acc: 0.4685, Test Acc: 0.3667\n",
      "Epoch: 847, Train Acc: 0.4185, Test Acc: 0.3167\n",
      "Epoch: 848, Train Acc: 0.4667, Test Acc: 0.3333\n",
      "Epoch: 849, Train Acc: 0.4611, Test Acc: 0.3000\n",
      "Epoch: 850, Train Acc: 0.4537, Test Acc: 0.2833\n",
      "Epoch: 851, Train Acc: 0.4500, Test Acc: 0.3167\n",
      "Epoch: 852, Train Acc: 0.4593, Test Acc: 0.3500\n",
      "Epoch: 853, Train Acc: 0.4407, Test Acc: 0.2667\n",
      "Epoch: 854, Train Acc: 0.4389, Test Acc: 0.3333\n",
      "Epoch: 855, Train Acc: 0.4537, Test Acc: 0.3167\n",
      "Epoch: 856, Train Acc: 0.4611, Test Acc: 0.3667\n",
      "Epoch: 857, Train Acc: 0.4481, Test Acc: 0.2833\n",
      "Epoch: 858, Train Acc: 0.4593, Test Acc: 0.3167\n",
      "Epoch: 859, Train Acc: 0.4463, Test Acc: 0.3167\n",
      "Epoch: 860, Train Acc: 0.4222, Test Acc: 0.2333\n",
      "Epoch: 861, Train Acc: 0.4389, Test Acc: 0.3167\n",
      "Epoch: 862, Train Acc: 0.4556, Test Acc: 0.3500\n",
      "Epoch: 863, Train Acc: 0.4241, Test Acc: 0.3333\n",
      "Epoch: 864, Train Acc: 0.4741, Test Acc: 0.3833\n",
      "Epoch: 865, Train Acc: 0.4481, Test Acc: 0.2667\n",
      "Epoch: 866, Train Acc: 0.4519, Test Acc: 0.3167\n",
      "Epoch: 867, Train Acc: 0.4481, Test Acc: 0.2833\n",
      "Epoch: 868, Train Acc: 0.4574, Test Acc: 0.2833\n",
      "Epoch: 869, Train Acc: 0.4111, Test Acc: 0.2500\n",
      "Epoch: 870, Train Acc: 0.4481, Test Acc: 0.3667\n",
      "Epoch: 871, Train Acc: 0.4148, Test Acc: 0.2667\n",
      "Epoch: 872, Train Acc: 0.4537, Test Acc: 0.3333\n",
      "Epoch: 873, Train Acc: 0.4296, Test Acc: 0.2333\n",
      "Epoch: 874, Train Acc: 0.4667, Test Acc: 0.3333\n",
      "Epoch: 875, Train Acc: 0.4130, Test Acc: 0.3167\n",
      "Epoch: 876, Train Acc: 0.4722, Test Acc: 0.3333\n",
      "Epoch: 877, Train Acc: 0.4630, Test Acc: 0.3167\n",
      "Epoch: 878, Train Acc: 0.4130, Test Acc: 0.2500\n",
      "Epoch: 879, Train Acc: 0.4630, Test Acc: 0.3167\n",
      "Epoch: 880, Train Acc: 0.4241, Test Acc: 0.2833\n",
      "Epoch: 881, Train Acc: 0.4370, Test Acc: 0.3833\n",
      "Epoch: 882, Train Acc: 0.4389, Test Acc: 0.3000\n",
      "Epoch: 883, Train Acc: 0.4611, Test Acc: 0.3833\n",
      "Epoch: 884, Train Acc: 0.4685, Test Acc: 0.3167\n",
      "Epoch: 885, Train Acc: 0.4259, Test Acc: 0.3000\n",
      "Epoch: 886, Train Acc: 0.4463, Test Acc: 0.2667\n",
      "Epoch: 887, Train Acc: 0.4370, Test Acc: 0.2833\n",
      "Epoch: 888, Train Acc: 0.4426, Test Acc: 0.3167\n",
      "Epoch: 889, Train Acc: 0.4296, Test Acc: 0.2833\n",
      "Epoch: 890, Train Acc: 0.4204, Test Acc: 0.3000\n",
      "Epoch: 891, Train Acc: 0.4315, Test Acc: 0.3667\n",
      "Epoch: 892, Train Acc: 0.4093, Test Acc: 0.2667\n",
      "Epoch: 893, Train Acc: 0.4685, Test Acc: 0.3500\n",
      "Epoch: 894, Train Acc: 0.4741, Test Acc: 0.3833\n",
      "Epoch: 895, Train Acc: 0.4370, Test Acc: 0.3000\n",
      "Epoch: 896, Train Acc: 0.4463, Test Acc: 0.3500\n",
      "Epoch: 897, Train Acc: 0.4630, Test Acc: 0.3000\n",
      "Epoch: 898, Train Acc: 0.4593, Test Acc: 0.3667\n",
      "Epoch: 899, Train Acc: 0.4593, Test Acc: 0.3000\n",
      "Epoch: 900, Train Acc: 0.4685, Test Acc: 0.2833\n",
      "Epoch: 901, Train Acc: 0.4444, Test Acc: 0.2833\n",
      "Epoch: 902, Train Acc: 0.4407, Test Acc: 0.2667\n",
      "Epoch: 903, Train Acc: 0.4463, Test Acc: 0.2833\n",
      "Epoch: 904, Train Acc: 0.4537, Test Acc: 0.3333\n",
      "Epoch: 905, Train Acc: 0.4519, Test Acc: 0.3333\n",
      "Epoch: 906, Train Acc: 0.4778, Test Acc: 0.3833\n",
      "Epoch: 907, Train Acc: 0.4611, Test Acc: 0.3333\n",
      "Epoch: 908, Train Acc: 0.4500, Test Acc: 0.3167\n",
      "Epoch: 909, Train Acc: 0.4630, Test Acc: 0.3000\n",
      "Epoch: 910, Train Acc: 0.4556, Test Acc: 0.2833\n",
      "Epoch: 911, Train Acc: 0.4370, Test Acc: 0.2833\n",
      "Epoch: 912, Train Acc: 0.4574, Test Acc: 0.3167\n",
      "Epoch: 913, Train Acc: 0.4667, Test Acc: 0.3333\n",
      "Epoch: 914, Train Acc: 0.4500, Test Acc: 0.3167\n",
      "Epoch: 915, Train Acc: 0.4611, Test Acc: 0.3167\n",
      "Epoch: 916, Train Acc: 0.4167, Test Acc: 0.3167\n",
      "Epoch: 917, Train Acc: 0.4000, Test Acc: 0.2333\n",
      "Epoch: 918, Train Acc: 0.4426, Test Acc: 0.3833\n",
      "Epoch: 919, Train Acc: 0.4148, Test Acc: 0.2667\n",
      "Epoch: 920, Train Acc: 0.4630, Test Acc: 0.3500\n",
      "Epoch: 921, Train Acc: 0.4593, Test Acc: 0.3000\n",
      "Epoch: 922, Train Acc: 0.4519, Test Acc: 0.2667\n",
      "Epoch: 923, Train Acc: 0.4630, Test Acc: 0.3000\n",
      "Epoch: 924, Train Acc: 0.4574, Test Acc: 0.3000\n",
      "Epoch: 925, Train Acc: 0.4648, Test Acc: 0.3333\n",
      "Epoch: 926, Train Acc: 0.4352, Test Acc: 0.2667\n",
      "Epoch: 927, Train Acc: 0.4704, Test Acc: 0.3333\n",
      "Epoch: 928, Train Acc: 0.4537, Test Acc: 0.3167\n",
      "Epoch: 929, Train Acc: 0.4759, Test Acc: 0.3167\n",
      "Epoch: 930, Train Acc: 0.4500, Test Acc: 0.2667\n",
      "Epoch: 931, Train Acc: 0.4333, Test Acc: 0.2667\n",
      "Epoch: 932, Train Acc: 0.4704, Test Acc: 0.3667\n",
      "Epoch: 933, Train Acc: 0.4389, Test Acc: 0.2667\n",
      "Epoch: 934, Train Acc: 0.4556, Test Acc: 0.3000\n",
      "Epoch: 935, Train Acc: 0.4407, Test Acc: 0.2833\n",
      "Epoch: 936, Train Acc: 0.4426, Test Acc: 0.2833\n",
      "Epoch: 937, Train Acc: 0.4741, Test Acc: 0.3667\n",
      "Epoch: 938, Train Acc: 0.4444, Test Acc: 0.2833\n",
      "Epoch: 939, Train Acc: 0.4426, Test Acc: 0.3333\n",
      "Epoch: 940, Train Acc: 0.4611, Test Acc: 0.3333\n",
      "Epoch: 941, Train Acc: 0.4463, Test Acc: 0.2667\n",
      "Epoch: 942, Train Acc: 0.4426, Test Acc: 0.2500\n",
      "Epoch: 943, Train Acc: 0.4630, Test Acc: 0.3333\n",
      "Epoch: 944, Train Acc: 0.4444, Test Acc: 0.2833\n",
      "Epoch: 945, Train Acc: 0.4704, Test Acc: 0.3667\n",
      "Epoch: 946, Train Acc: 0.4537, Test Acc: 0.3500\n",
      "Epoch: 947, Train Acc: 0.4611, Test Acc: 0.3167\n",
      "Epoch: 948, Train Acc: 0.4315, Test Acc: 0.3167\n",
      "Epoch: 949, Train Acc: 0.4407, Test Acc: 0.3000\n",
      "Epoch: 950, Train Acc: 0.4537, Test Acc: 0.3667\n",
      "Epoch: 951, Train Acc: 0.4278, Test Acc: 0.2500\n",
      "Epoch: 952, Train Acc: 0.4796, Test Acc: 0.3333\n",
      "Epoch: 953, Train Acc: 0.4593, Test Acc: 0.3500\n",
      "Epoch: 954, Train Acc: 0.4222, Test Acc: 0.2833\n",
      "Epoch: 955, Train Acc: 0.4611, Test Acc: 0.3833\n",
      "Epoch: 956, Train Acc: 0.4722, Test Acc: 0.3833\n",
      "Epoch: 957, Train Acc: 0.4685, Test Acc: 0.3333\n",
      "Epoch: 958, Train Acc: 0.4019, Test Acc: 0.2667\n",
      "Epoch: 959, Train Acc: 0.4630, Test Acc: 0.3500\n",
      "Epoch: 960, Train Acc: 0.4741, Test Acc: 0.3333\n",
      "Epoch: 961, Train Acc: 0.4333, Test Acc: 0.2333\n",
      "Epoch: 962, Train Acc: 0.4704, Test Acc: 0.3167\n",
      "Epoch: 963, Train Acc: 0.4759, Test Acc: 0.3500\n",
      "Epoch: 964, Train Acc: 0.4278, Test Acc: 0.2667\n",
      "Epoch: 965, Train Acc: 0.4611, Test Acc: 0.3000\n",
      "Epoch: 966, Train Acc: 0.4481, Test Acc: 0.3500\n",
      "Epoch: 967, Train Acc: 0.4556, Test Acc: 0.2667\n",
      "Epoch: 968, Train Acc: 0.4481, Test Acc: 0.2833\n",
      "Epoch: 969, Train Acc: 0.4519, Test Acc: 0.3000\n",
      "Epoch: 970, Train Acc: 0.4630, Test Acc: 0.3333\n",
      "Epoch: 971, Train Acc: 0.4407, Test Acc: 0.3333\n",
      "Epoch: 972, Train Acc: 0.4315, Test Acc: 0.3667\n",
      "Epoch: 973, Train Acc: 0.4389, Test Acc: 0.2667\n",
      "Epoch: 974, Train Acc: 0.4556, Test Acc: 0.3000\n",
      "Epoch: 975, Train Acc: 0.4722, Test Acc: 0.3167\n",
      "Epoch: 976, Train Acc: 0.4537, Test Acc: 0.2833\n",
      "Epoch: 977, Train Acc: 0.4593, Test Acc: 0.3167\n",
      "Epoch: 978, Train Acc: 0.4704, Test Acc: 0.3000\n",
      "Epoch: 979, Train Acc: 0.4722, Test Acc: 0.3333\n",
      "Epoch: 980, Train Acc: 0.4519, Test Acc: 0.3500\n",
      "Epoch: 981, Train Acc: 0.4796, Test Acc: 0.3167\n",
      "Epoch: 982, Train Acc: 0.4204, Test Acc: 0.2333\n",
      "Epoch: 983, Train Acc: 0.4611, Test Acc: 0.3167\n",
      "Epoch: 984, Train Acc: 0.3981, Test Acc: 0.2833\n",
      "Epoch: 985, Train Acc: 0.4648, Test Acc: 0.3333\n",
      "Epoch: 986, Train Acc: 0.4722, Test Acc: 0.4000\n",
      "Epoch: 987, Train Acc: 0.4315, Test Acc: 0.2500\n",
      "Epoch: 988, Train Acc: 0.4333, Test Acc: 0.3333\n",
      "Epoch: 989, Train Acc: 0.4370, Test Acc: 0.2667\n",
      "Epoch: 990, Train Acc: 0.4500, Test Acc: 0.3333\n",
      "Epoch: 991, Train Acc: 0.4389, Test Acc: 0.3500\n",
      "Epoch: 992, Train Acc: 0.4426, Test Acc: 0.3167\n",
      "Epoch: 993, Train Acc: 0.4389, Test Acc: 0.3000\n",
      "Epoch: 994, Train Acc: 0.4500, Test Acc: 0.3333\n",
      "Epoch: 995, Train Acc: 0.4519, Test Acc: 0.3667\n",
      "Epoch: 996, Train Acc: 0.4704, Test Acc: 0.3833\n",
      "Epoch: 997, Train Acc: 0.4426, Test Acc: 0.2667\n",
      "Epoch: 998, Train Acc: 0.4611, Test Acc: 0.3167\n",
      "Epoch: 999, Train Acc: 0.4537, Test Acc: 0.3167\n",
      "Epoch: 1000, Train Acc: 0.4241, Test Acc: 0.2833\n"
     ]
    }
   ],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 1001):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
