{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä¸ƒ. è¯¯å·®åå‘ä¼ æ’­ç®—æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import gzip\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šä¸€èŠ‚æˆ‘ä»¬çœ‹åˆ°äº†ç¥ç»â½¹ç»œå¦‚ä½•ä½¿â½¤æ¢¯åº¦ä¸‹é™ç®—æ³•æ¥å­¦ä¹ ä»–ä»¬â¾ƒâ¾çš„æƒé‡å’Œåç½®ã€‚ä½†æ˜¯ï¼Œè¿™â¾¥è¿˜ç•™ä¸‹äº†â¼€ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬å¹¶æ²¡æœ‰è®¨è®ºå¦‚ä½•è®¡ç®—ä»£ä»·å‡½æ•°çš„æ¢¯åº¦ã€‚è¿™æ˜¯å¾ˆâ¼¤çš„ç¼ºå¤±ï¼æˆ‘ä»¬æ¥ä¸‹æ¥å­¦ä¹ è®¡ç®—è¿™äº›æ¢¯åº¦çš„å¿«é€Ÿç®—æ³•ï¼Œä¹Ÿå°±æ˜¯åå‘ä¼ æ’­ï¼ˆ`backpropagation`ï¼‰ã€‚\n",
    "\n",
    "åå‘ä¼ æ’­ç®—æ³•æœ€åˆåœ¨1970 å¹´ä»£è¢«æåŠï¼Œä½†æ˜¯â¼ˆä»¬ç›´åˆ°David Rumelhartã€Geoffrey Hinton å’ŒRonald Williams çš„è‘—åçš„1986 å¹´çš„è®ºâ½‚ä¸­æ‰è®¤è¯†åˆ°è¿™ä¸ªç®—æ³•çš„é‡è¦æ€§ã€‚è¿™ç¯‡è®ºâ½‚æè¿°äº†å¯¹â¼€äº›ç¥ç»â½¹ç»œåå‘ä¼ æ’­è¦â½ä¼ ç»Ÿçš„â½…æ³•æ›´å¿«ï¼Œè¿™ä½¿å¾—ä½¿â½¤ç¥ç»â½¹ç»œæ¥è§£å†³ä¹‹å‰â½†æ³•å®Œæˆçš„é—®é¢˜å˜å¾—å¯â¾ã€‚ç°åœ¨ï¼Œåå‘ä¼ æ’­ç®—æ³•å·²ç»æ˜¯ç¥ç»â½¹ç»œå­¦ä¹ çš„é‡è¦ç»„æˆéƒ¨åˆ†äº†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. ç¬¦å·çº¦å®š\n",
    "\n",
    "<div align=center>\n",
    "<img width=\"700\" src=\"../pictures/7.back_propagation.svg\"/>\n",
    "</div>\n",
    "\n",
    "<div align=center> \n",
    "    å›¾1 ç¥ç»ç½‘ç»œæ•°å­¦ç¬¦å·ç¤ºæ„å›¾\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å‡è®¾è¾“å…¥å±‚è¡¨ç¤ºä¸º$x$, è¾“å…¥å±‚åˆ°ç¬¬1ä¸ªéšè—å±‚çš„æƒé‡çŸ©é˜µè¡¨ç¤ºä¸º$w^1$, ç¬¬1ä¸ªéšè—å±‚çš„å‡€å€¼ä¸º$z^1$, æ¿€æ´»å€¼ä¸º$a^1$ï¼›è¾“å‡ºå±‚çš„å‡€å€¼ä¸º$z^L$, æ¿€æ´»å€¼ä¸º$a^L$ï¼Œå³éšè—å±‚åŠ è¾“å‡ºå±‚çš„æ•°é‡ä¸ºLã€‚ç¬¬lå±‚çš„ç¥ç»å…ƒä¸ªæ•°ä¸º$M_l$ã€‚\n",
    "\n",
    "$w_{jk}^l$è¡¨ç¤ºç¬¬$(l-1)$å±‚çš„ç¬¬$k$ä¸ªç¥ç»å…ƒåˆ°$l$å±‚çš„ç¬¬$j$ä¸ªç¥ç»å…ƒçš„è¿æ¥ä¸Šçš„æƒé‡ï¼Œl-1å’Œlå±‚é—´çš„æƒé‡çŸ©é˜µä¸º$w^l\\in \\mathbb{R}^{\\mathbf{M}_l\\times \\mathbf{M}_{l-1}}$ã€‚\n",
    "\n",
    "$b_j^l$è¡¨ç¤ºç¬¬l-1å±‚åˆ°ç¬¬lå±‚ç¬¬jä¸ªç¥ç»å…ƒçš„åç½®, lå±‚çš„åç½®å‘é‡è¡¨ç¤ºä¸º$b^l\\in \\mathbb{R}^{\\mathbf{M}_l}$ã€‚\n",
    "\n",
    "$z_j^l$è¡¨ç¤ºç¬¬lå±‚ç¬¬jä¸ªç¥ç»å…ƒçš„å‡€å€¼, lå±‚çš„å‡€å€¼å‘é‡è¡¨ç¤ºä¸º$z^l\\in \\mathbb{R}^{\\mathbf{M}_l}$ã€‚\n",
    "\n",
    "$\\sigma^l$è¡¨ç¤ºåº”ç”¨äºç¬¬lå±‚ç¥ç»å…ƒå‡€å€¼çš„æ¿€æ´»å‡½æ•°ã€‚\n",
    "\n",
    "$a_j^l$è¡¨ç¤ºç¬¬lå±‚ç¬¬jä¸ªç¥ç»å…ƒçš„æ¿€æ´»å€¼, lå±‚çš„æ¿€æ´»å€¼è¡¨ç¤ºä¸º$a^l\\in \\mathbb{R}^{\\mathbf{M}_l}$ã€‚\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "z_j^l &= \\sum_k w_{jk}^la_k^{l-1}+b_j^l \\\\\n",
    "a_j^l &= \\sigma^l(z_j^l)\\\\\n",
    "\\text{æˆ–è€…è¡¨ç¤ºä¸ºå‘é‡çŸ©é˜µå½¢å¼}\\\\\n",
    "z^l &= w^la^{l-1}+b^l \\\\\n",
    "a^l &= \\sigma^l(z^l)\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"1200\" src=\"../pictures/7.computational_graph.svg\"/>\n",
    "</div>\n",
    "\n",
    "<div align=center>\n",
    "    å›¾2 è®¡ç®—å›¾\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åå‘ä¼ æ’­çš„å››ä¸ªåŸºæœ¬æ–¹ç¨‹\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta^L&=\\frac{\\partial{C}}{\\partial{a^l}}\\odot R'(z^L) \\\\\n",
    "\\delta^l&=((w^{l+1})^T\\delta^{l+1})\\odot\\sigma'(z^l) \\\\\n",
    "\\frac{\\partial{C}}{\\partial{b_j^l}}&=\\delta_j^l \\text{ or } \\frac{\\partial{C}}{\\partial{b^l}}=\\delta^l \\in \\mathbb{R}^{M_l}\\\\\n",
    "\\frac{\\partial{C}}{\\partial{w_{jk}^l}}&=a_k^{l-1}\\delta_j^l \\text{ or } \\frac{\\partial{C}}{\\partial{w^l}}=\\delta^l (a^{l-1})^T\\in \\mathbb{R}^{M_l\\times M_{l-1}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åå‘ä¼ æ’­å…¶å®æ˜¯å¯¹æƒé‡å’Œåç½®å˜åŒ–å½±å“ä»£ä»·å‡½æ•°è¿‡ç¨‹çš„ç†è§£ã€‚æœ€ç»ˆæçš„å«ä¹‰å…¶å®å°±æ˜¯è®¡ç®—åå¯¼æ•°$\\frac{\\partial{C}}{\\partial{w^l_{jk}}}$ å’Œ$\\frac{\\partial{C}}{\\partial{b^l}}$ã€‚ä½†æ˜¯ä¸ºäº†è®¡ç®—è¿™äº›å€¼ï¼Œæˆ‘ä»¬â¾¸å…ˆå¼•â¼Šâ¼€ä¸ªä¸­é—´é‡ï¼Œ$\\delta_j^l$ï¼Œè¿™ä¸ªæˆ‘ä»¬ç§°ä¸ºç¬¬lå±‚ç¬¬jä¸ªç¥ç»å…ƒä¸Šçš„è¯¯å·®ã€‚\n",
    "\n",
    "åå‘ä¼ æ’­å°†ç»™å‡ºè®¡ç®—è¯¯å·®$\\delta_j^l$çš„æµç¨‹ï¼Œç„¶åå°†å…¶å…³è”åˆ°è®¡ç®—$\\frac{\\partial{C}}{\\partial{w^l_{jk}}}$ å’Œ$\\frac{\\partial{C}}{\\partial{b^l}}$ä¸Šã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"800\" src=\"../pictures/7.error_z.svg\"/>\n",
    "</div>\n",
    "\n",
    "<div align=center>\n",
    "    å›¾3 è¯¯å·®å›¾\n",
    "</div>\n",
    "\n",
    "å‡å®šåœ¨å‰é¦ˆä¿¡æ¯ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œlå±‚ç¬¬iä¸ªç¥ç»å…ƒçš„å‡€å€¼$z_i^l$å¢åŠ äº†$\\Delta z_i^l$ï¼Œåˆ™æœ€ç»ˆæŸå¤±å‡½æ•°çš„å¢é‡åº”ä¸º$\\frac{\\partial C}{\\partial z_i^l}\\Delta z_i^l$ã€‚\n",
    "\n",
    "å‡è®¾$\\frac{\\partial C}{\\partial z_i^l}$æœ‰â¼€ä¸ªå¾ˆâ¼¤çš„å€¼ï¼ˆæˆ–æ­£æˆ–è´Ÿï¼‰ã€‚é‚£ä¹ˆå¯ä»¥é€šè¿‡é€‰æ‹©ä¸$\\frac{\\partial C}{\\partial z_i^l}$ç›¸åç¬¦å·çš„$\\Delta z_i^l$æ¥é™ä½ä»£ä»·ã€‚ç›¸åï¼Œå¦‚æœ$\\frac{\\partial C}{\\partial z_i^l}$æ¥è¿‘0ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¹¶ä¸èƒ½é€šè¿‡æ‰°åŠ¨å¸¦æƒè¾“â¼Š$z_j^l$æ¥æ”¹å–„å¤ªå¤šä»£ä»·ã€‚è¿™æ—¶å€™ç¥ç»å…ƒå·²ç»å¾ˆæ¥è¿‘æœ€ä¼˜äº†2ã€‚æ‰€ä»¥è¿™â¾¥æœ‰â¼€ç§å¯å‘å¼çš„è®¤è¯†ï¼Œ $\\frac{\\partial C}{\\partial z_j^l}$æ˜¯lå±‚ç¥ç»å…ƒjçš„è¯¯å·®çš„åº¦é‡ã€‚\n",
    "\n",
    "æŒ‰ç…§ä¸Šâ¾¯çš„æè¿°ï¼Œæˆ‘ä»¬å®šä¹‰lå±‚çš„ç¬¬jä¸ªç¥ç»å…ƒä¸Šçš„è¯¯å·®$\\delta_i^l$ä¸ºï¼š\n",
    "$$\n",
    "\\delta_j^l = \\frac{\\partial C}{\\partial z_j^l}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æŒ‰ç…§æˆ‘ä»¬é€šå¸¸çš„æƒ¯ä¾‹ï¼Œæˆ‘ä»¬ä½¿â½¤$\\delta^l$è¡¨â½°å…³è”äºl å±‚çš„è¯¯å·®å‘é‡ã€‚åå‘ä¼ æ’­ä¼šæä¾›ç»™æˆ‘ä»¬â¼€ç§è®¡ç®—æ¯å±‚çš„$\\delta^l$çš„â½…æ³•ï¼Œç„¶åå°†è¿™äº›è¯¯å·®å’Œæœ€ç»ˆæˆ‘ä»¬éœ€è¦çš„é‡$\\frac{\\partial C}{\\partial w_{jk}^l}$å’Œ$\\frac{\\partial C}{\\partial b_j^l}$è”ç³»èµ·æ¥ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (BP1). è¾“å‡ºå±‚çš„è¯¯å·®é¡¹$\\delta^L$\n",
    "æ¯ä¸ªå…ƒç´ å®šä¹‰å¦‚ä¸‹ï¼š\n",
    "$$\n",
    "\\delta_j^L=\\frac{\\partial C}{\\partial a_j^L}\\sigma'(z_j^L)\n",
    "$$\n",
    "\n",
    "è¿™æ˜¯â¼€ä¸ªâ¾®å¸¸â¾ƒç„¶çš„è¡¨è¾¾å¼ã€‚å³å¼ç¬¬â¼€ä¸ªé¡¹$\\frac{\\partial C}{\\partial a_j^L}$è¡¨â½°ä»£ä»·éšç€jå±‚è¾“å‡ºæ¿€æ´»å€¼çš„å˜åŒ–â½½å˜åŒ–çš„é€Ÿåº¦ã€‚å‡å¦‚Cä¸å¤ªä¾èµ–â¼€ä¸ªç‰¹å®šçš„è¾“å‡ºç¥ç»å…ƒjï¼Œé‚£ä¹ˆ$\\frac{\\partial C}{\\partial a_j^L}$å°±ä¼šå¾ˆâ¼©ï¼Œè¿™ä¹Ÿæ˜¯æˆ‘ä»¬æƒ³è¦çš„æ•ˆæœã€‚å³å¼ç¬¬â¼†é¡¹$\\sigma'(z_j^L)$åˆ»ç”»äº†åœ¨$z_j^L$å¤„æ¿€æ´»å‡½æ•°$\\sigma$å˜åŒ–çš„é€Ÿåº¦ã€‚\n",
    "\n",
    "ä¸Šå¼ä¹Ÿå¯ä»¥é‡æ–°å†™æˆçŸ©é˜µå½¢å¼\n",
    "$$\n",
    "\\delta^L=\\Delta_aC\\odot R'(z^L)\n",
    "$$\n",
    "\n",
    "ä¾‹å¦‚ï¼Œå¦‚æœæŸå¤±å‡½æ•°ä¸ºè¯¯å·®å¹³æ–¹å’Œæ—¶ï¼Œæˆ‘ä»¬æœ‰$\\Delta_aC=(a^L-y)$ï¼Œå› æ­¤å¯å¾—$\\delta_L=(a^L-y)\\odot \\sigma'(z^L)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (BP2). ä½¿ç”¨l+1å±‚è¯¯å·®$\\delta^{l+1}$è®¡ç®—lå±‚çš„è¯¯å·®$\\delta^{l}$: \n",
    "$$\n",
    "\\delta^l=((w^{l+1})^T\\delta^{l+1})\\odot\\sigma'(z^l)\n",
    "$$\n",
    "\n",
    "å‡è®¾æˆ‘ä»¬çŸ¥é“l+1å±‚çš„è¯¯å·®$\\delta^{l+1}$ã€‚å½“æˆ‘ä»¬åº”â½¤è½¬ç½®çš„æƒé‡çŸ©é˜µ$(w^{l+1})^T$ ï¼Œæˆ‘ä»¬å¯ä»¥å‡­ç›´è§‰åœ°æŠŠå®ƒçœ‹ä½œæ˜¯åœ¨æ²¿ç€â½¹ç»œåå‘ç§»åŠ¨è¯¯å·®ï¼Œç»™äº†æˆ‘ä»¬åº¦é‡åœ¨lå±‚è¾“å‡ºçš„è¯¯å·®â½…æ³•ã€‚ç„¶åï¼Œæˆ‘ä»¬è¿›â¾Hadamard ä¹˜ç§¯è¿ç®—$\\odot\\sigma'(z^l)$ã€‚è¿™ä¼šè®©è¯¯å·®é€šè¿‡l å±‚çš„æ¿€æ´»å‡½æ•°åå‘ä¼ é€’å›æ¥å¹¶ç»™å‡ºåœ¨ç¬¬l å±‚çš„å¸¦æƒè¾“â¼Šçš„è¯¯å·®$\\delta$ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**é€šè¿‡ç»„åˆ(BP1) å’Œ(BP2)ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—ä»»ä½•å±‚çš„è¯¯å·®$\\delta^l$ã€‚â¾¸å…ˆä½¿â½¤(BP1) è®¡ç®—$\\delta^L$ï¼Œç„¶ååº”â½¤â½…ç¨‹(BP2) æ¥è®¡ç®—$\\delta^{L-1}$ï¼Œç„¶åå†æ¬¡â½¤â½…ç¨‹(BP2)æ¥è®¡ç®—$\\delta^{L-2}$ï¼Œå¦‚æ­¤â¼€æ­¥â¼€æ­¥åœ°åå‘ä¼ æ’­å®Œæ•´ä¸ªâ½¹ç»œã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (BP3). ä»£ä»·å‡½æ•°å…³äºâ½¹ç»œä¸­ä»»æ„åç½®çš„æ”¹å˜ç‡:\n",
    "$$\n",
    "\\frac{\\partial{C}}{\\partial{b_j^l}}=\\delta_j^l \\\\\n",
    "\\text{ or } \\\\\n",
    "\\frac{\\partial{C}}{\\partial{b^l}}=\\delta^l \\in \\mathbb{R}^{M_l}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=center>\n",
    "<img width=\"800\" src=\"../pictures/7.bp3-4.svg\"/>\n",
    "</div>\n",
    "\n",
    "<div align=center>\n",
    "    å›¾4 BP(3)-(4)ç¤ºæ„å›¾\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (BP4). ä»£ä»·å‡½æ•°å…³äºæƒé‡çš„æ”¹å˜ç‡\n",
    "$$\n",
    "\\frac{\\partial{C}}{\\partial{w_{jk}^l}}=a_k^{l-1}\\delta_j^l \\\\\n",
    "\\text{ or } \\\\\n",
    "\\frac{\\partial{C}}{\\partial{w^l}}=\\delta^l (a^{l-1})^T\\in \\mathbb{R}^{M_l\\times M_{l-1}}\n",
    "$$\n",
    "\n",
    "å½“æ¿€æ´»å€¼$a_k^{l-1}$å¾ˆâ¼©ï¼Œä¾‹å¦‚$a_k^{l-1}\\simeq 0$æ—¶ï¼Œæ¢¯åº¦$\\frac{\\partial{C}}{\\partial{w_{jk}^l}}$ä¹Ÿä¼šè¶‹å‘å¾ˆâ¼©ã€‚è¿™\n",
    "æ ·ï¼Œæˆ‘ä»¬å°±è¯´æƒé‡ç¼“æ…¢å­¦ä¹ ï¼Œè¡¨â½°åœ¨æ¢¯åº¦ä¸‹é™çš„æ—¶å€™ï¼Œè¿™ä¸ªæƒé‡ä¸ä¼šæ”¹å˜å¤ªå¤šã€‚æ¢â¾”ä¹‹ï¼Œ(BP4)çš„â¼€ä¸ªç»“æœå°±æ˜¯æ¥â¾ƒä½æ¿€æ´»å€¼ç¥ç»å…ƒçš„æƒé‡å­¦ä¹ ä¼šâ¾®å¸¸ç¼“æ…¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- äº¤å‰ç†µé£é™©å‡½æ•°$\\mathbf{R(z^L, y)}=-y\\cdot\\log{a^L}$å…³äº$z^L$çš„æ¢¯åº¦ä¸º\n",
    "> $a^L=\\mathrm{softmax}(z^L), \\frac{\\partial{C}}{\\partial{a_i^L}}=-y_i\\frac{1}{a_i^L}$\n",
    ">\n",
    "> $\\frac{\\partial{C}}{\\partial{a^L}} = -y\\odot (a^L)^{-1} = (-y_1\\frac{1}{a_1^L}, -y_2\\frac{1}{a_2^L}, ..., -y_{M_L}\\frac{1}{a_{M_L}^L})$\n",
    "\n",
    "å½“$i=j$æ—¶, æœ‰$\\frac{\\partial{a_i}}{\\partial{b_j}}=a_i(1-a_i)$; å½“$i\\neq j$æ—¶, æœ‰$\\frac{\\partial{a_i}}{\\partial{b_j}}=-a_ia_j$, å› æ­¤æœ‰\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{a^L}}{\\partial{z^L}} = \\begin{bmatrix} \n",
    "a_1^L(1-a_1^L) & -a_1^La_2^L & ... & -a_1^La_j^L & ... & -a_1^La_{M_L}^L \\\\ \n",
    "-a_2^La_1^L & a_2^L(1-a_2^L) & ... & a_2^La_j^L & ... & -a_2^La_{M_L}^L \\\\\n",
    "... & ... & ... & ... & ... & ....\\\\\n",
    "-a_{M_L}^La_1^L & -a_{M_L}^La_2^L & ... & -a_{M_L}^La_j^L & ... & a_{M_L}^L(1-a_{M_L}^L)\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å› æ­¤ï¼Œç»“åˆé“¾å¼æ³•åˆ™ï¼Œæœ‰\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial{C}}{\\partial{z^L}} &= \\frac{\\partial{C}}{\\partial{a^L}} \\frac{\\partial{a^L}}{\\partial{z^L}} \\\\\n",
    "&= (\\frac{\\partial{C}}{\\partial{a^L}}\\frac{\\partial{a^L}}{\\partial{z^L_1}}, \\frac{\\partial{C}}{\\partial{a^L}}\\frac{\\partial{a^L}}{\\partial{z^L_2}}, ..., \\frac{\\partial{C}}{\\partial{a^L}}\\frac{\\partial{a^L}}{\\partial{z^L_{M_L}}})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "å‡å®š$y_i$=1, åˆ™æœ‰$\\frac{\\partial{C}}{\\partial{z^L}}=(a^L_1, a^L_2, ..., a^L_{i}-1, ..., a^L_{M_L})$, å› æ­¤å¯ä»¥å†™æˆ: $\\frac{\\partial{C}}{\\partial{z^L}}=a^L-y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹\n",
    "\n",
    "åå‘ä¼ æ’­æ–¹ç¨‹ç»™å‡ºäº†ä¸€ç§è®¡ç®—ä»£ä»·å‡½æ•°æ¢¯åº¦çš„æ–¹æ³•ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹ç®—æ³•æè¿°:\n",
    "\n",
    "**è¾“å…¥: è®­ç»ƒé›†{features, labels}, è®­ç»ƒå›åˆæ•°max_epochs, å­¦ä¹ ç‡lr, æ‰¹é‡å¤§å°batch_size**\n",
    "**è¾“å‡º: è®­ç»ƒå¥½çš„å‰é¦ˆç¥ç»ç½‘ç»œ**\n",
    "**ç®—æ³•è¿‡ç¨‹:**\n",
    "- åˆå§‹åŒ–å½“å‰å›åˆepoch=1, \n",
    "- å¦‚æœepoch <= max_epochs, æ‰§è¡Œä»¥ä¸‹æ“ä½œ\n",
    "    - æ‰“ä¹±è®­ç»ƒé›†çš„æ’åº\n",
    "    - ç”±å‰é€æ‰¹å–å‡ºbatch_sizeä¸ªæ ·æœ¬ï¼Œç„¶ååšä»¥ä¸‹è®¡ç®—ï¼Œç›´åˆ°å–å®Œæ‰€æœ‰æ ·æœ¬ä¸ºæ­¢\n",
    "        - å‰é¦ˆè®¡ç®—æ¯ä¸€å±‚çš„å‡€å€¼$z^l$å’Œæ¿€æ´»å€¼$a^l$ï¼Œç›´åˆ°æœ€åä¸€å±‚\n",
    "        - åå‘ä¼ æ’­è®¡ç®—æ¯ä¸€å±‚çš„è¯¯å·®$\\delta^l$(*å…¬å¼bp1, bp2*)\n",
    "        - è®¡ç®—æŸå¤±å‡½æ•°å¯¹å„å±‚é—´æƒé‡çŸ©é˜µ$w^l$å’Œåç½®å‘é‡$b^l$çš„åå¯¼æ•°(*å…¬å¼bp3, bp4*)\n",
    "        - æ›´æ–°æƒé‡çŸ©é˜µå’Œæƒé‡çŸ©é˜µ\n",
    "        $$\n",
    "        \\begin{aligned}\n",
    "        w^l &:= w^l - lr*\\frac{(\\delta^l(a(l-1)^T))}{\\mathrm{batch\\_size}} \\\\\n",
    "        b^l &:= b^l - lr*mean(\\delta^l, axis=1)\n",
    "        \\end{aligned}\n",
    "        $$\n",
    "    - æ›´æ–°epoch := epoch + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN:\n",
    "    def __init__(self, features, labels, params, batch_size=256):\n",
    "        '''\n",
    "        features: ç‰¹å¾\n",
    "        labels: æ ‡ç­¾\n",
    "        paramså…ƒç´ : (æƒé‡çŸ©é˜µ, åç½®å‘é‡, æ¿€æ´»å‡½æ•°, æ¿€æ´»å‡½æ•°çš„å¯¼æ•°)\n",
    "        æ³¨æ„: ä¸ä»¥ä¸Šç¬¦å·ä¿æŒä¸€è‡´ï¼Œæƒé‡çš„å½¢çŠ¶ä¸º (M_{l}, M_{l-1}), åç½®çš„å½¢çŠ¶ä¸º (1, M_{l})\n",
    "        '''\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.params = params\n",
    "        self.train_iter = self.data_loader(batch_size=256)\n",
    "    \n",
    "    def data_loader(self, batch_size, is_one_hot=True):\n",
    "        '''\n",
    "        æ„å»ºå°æ‰¹é‡æ•°æ®é›†\n",
    "        '''\n",
    "        if is_one_hot:\n",
    "            hot_labels = torch.zeros(self.features.shape[0], 10)\n",
    "            x_indices = np.arange(self.features.shape[0]).tolist()\n",
    "            y_indices = self.labels.byte().tolist()\n",
    "            hot_labels[x_indices, y_indices] = 1\n",
    "            dataset = TensorDataset(self.features, hot_labels)\n",
    "        else:\n",
    "            dataset = TensorDataset(self.features, self.labels)\n",
    "\n",
    "        return DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        ç¥ç»å…ƒå‰é¦ˆä¼ é€’ä¿¡æ¯\n",
    "        '''\n",
    "        self.z_list, self.a_list = [], [X]  # è®°å½•å„å±‚çš„å‡€å€¼å’Œæ¿€æ´»å€¼\n",
    "        y = X  # åˆå§‹åŒ–è¾“å…¥features\n",
    "        for weight, bias, func, _ in self.params:\n",
    "            z = y@torch.transpose(weight, 0, 1) + bias.reshape(1, -1)  # (N, M_{l-1}) @ (M_{l-1}, M_{l}) + (1, M_{l}), broadcast\n",
    "            if func:\n",
    "                if func.__name__ == 'softmax':\n",
    "                    y = func(z, dim=1)\n",
    "                else:\n",
    "                    y = func(z)\n",
    "            else:\n",
    "                y = z\n",
    "                \n",
    "            self.z_list.append(z)\n",
    "            self.a_list.append(y)\n",
    "        return y.double()\n",
    "    \n",
    "    def cal_neuron_errors(self, y):\n",
    "        '''\n",
    "        è®¡ç®—ç¥ç»å…ƒçš„è¯¯å·®delta\n",
    "        '''\n",
    "        # è¾“å‡ºå±‚è¯¯å·®\n",
    "        error_L = self.a_list[-1] - y\n",
    "        self.error_list = [error_L]\n",
    "        for i in range(len(self.params)-1):  # ä»è¾“å‡ºå±‚è‡³è¾“å…¥å±‚ï¼Œé€å±‚è®¡ç®—\n",
    "            weight = self.params[-i-1][0]  # æƒé‡çŸ©é˜µ\n",
    "            der_f = self.params[-i-1][-1]  # æ¿€æ´»å‡½æ•°çš„å¯¼æ•°\n",
    "            error_up = self.error_list[-1]  # ä¸Šä¸€å±‚çš„è¯¯å·®\n",
    "            z = self.z_list[-i-2]  # å½“å‰å±‚çš„å‡€å€¼\n",
    "            error = error_up@weight * der_f(z)  #  (N, M_{l})@(M_{l}, M_{l-1}) = (N, M_{l-1})\n",
    "            self.error_list.append(error)\n",
    "            \n",
    "        self.error_list.reverse()  # é€†åºï¼Œä¸ºäº†åé¢çš„æ›´æ–°\n",
    "    \n",
    "    def cal_params_partial(self):\n",
    "        '''\n",
    "        è®¡ç®—æŸå¤±å‡½æ•°å…³äºæƒé‡å’Œåç½®çš„åå¯¼æ•°\n",
    "        '''\n",
    "        self.der_weight_list = []  # æƒé‡æ¢¯åº¦\n",
    "        self.der_bias_list = []  # åç½®æ¢¯åº¦\n",
    "        for i in range(len(self.params)):\n",
    "            a_out = self.a_list[i]  # l-1å±‚æ¿€æ´»å€¼\n",
    "            error_in = self.error_list[i]  # lå±‚è¯¯å·®\n",
    "            # ä»¥ä¸‹è®¡ç®—å‡ºæ¥çš„æ˜¯æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„der_weightæ„æˆçš„çŸ©é˜µï¼Œå½’çº¦æˆ1ç»´ï¼Œå¯é‡‡ç”¨å‡å€¼æˆ–æ±‚å’Œçš„å½¢å¼\n",
    "            der_weight = torch.transpose(error_in, 0, 1)@a_out / self.a_list[0].shape[0]  # (M_{l}, N) @ (N, M{l-1})\n",
    "            der_bias = torch.mean(torch.transpose(error_in, 0, 1), axis=1)  # (M_{l}, N)\n",
    "            self.der_weight_list.append(der_weight)\n",
    "            self.der_bias_list.append(der_bias)\n",
    "        \n",
    "    def backward(self, y):\n",
    "        '''\n",
    "        è¯¯å·®åå‘ä¼ æ’­ç®—æ³•å®ç°\n",
    "        '''\n",
    "        self.cal_neuron_errors(y)\n",
    "        self.cal_params_partial()\n",
    "    \n",
    "    def cross_entropy(self, X, y):\n",
    "        '''\n",
    "        é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°\n",
    "        labels: one-hotå½¢å¼\n",
    "        hat_y: softmaxä¹‹åå¯¹åº”æ¦‚ç‡å‘é‡ï¼Œå¤šå±‚æ„ŸçŸ¥æœºçš„è¾“å‡º\n",
    "        '''\n",
    "        hat_y = self.forward(X)\n",
    "        if len(y.shape) == 2:\n",
    "            crossEnt = -torch.dot(y.reshape(-1), torch.log10(hat_y.float()).reshape(-1)) / y.shape[0]  # å±•å¼€æˆ1ç»´ï¼Œç‚¹ç§¯\n",
    "        elif len(y.shape) == 1:\n",
    "            crossEnt = -torch.mean(torch.log10(hat_y[torch.arange(y.shape[0]), y.long()]))\n",
    "        else:\n",
    "            print(\"Wrong format of y!\")\n",
    "        return crossEnt\n",
    "    \n",
    "    def accuracy(self, y, hat_y, is_one_hot=False):\n",
    "        '''\n",
    "        y: æ ‡ç­¾, one-hot\n",
    "        hat_y: æ ‡ç­¾é¢„æµ‹æ¦‚ç‡, one-hot\n",
    "        is_one_hot: yæ˜¯å¦ä¸ºone-hotå½¢å¼\n",
    "        '''\n",
    "        if is_one_hot:\n",
    "            precision = torch.sum(torch.max(y, axis=1)[1] == torch.max(hat_y, axis=1)[1]).numpy() / y.shape[0]\n",
    "        else:\n",
    "            precision = torch.sum((y == torch.max(hat_y, axis=1)[1]).byte()).numpy() / y.shape[0]\n",
    "        return precision\n",
    "    \n",
    "    def minibatch_sgd_trainer(self, max_epochs=10, lr=0.1):\n",
    "        '''\n",
    "        è®­ç»ƒ\n",
    "        '''\n",
    "        for epoch in range(max_epochs):\n",
    "            for X, y in self.train_iter:\n",
    "                self.forward(X)  # å‰å‘ä¼ æ’­\n",
    "                self.backward(y)  # è¯¯å·®åå‘ä¼ æ’­\n",
    "                for i in range(len(self.params)):  # æ›´æ–°æƒé‡\n",
    "                    self.params[i][0] -= lr*self.der_weight_list[i]\n",
    "                    self.params[i][1] -= lr*self.der_bias_list[i]\n",
    "            \n",
    "            loss = self.cross_entropy(self.features, self.labels)\n",
    "            accu = self.accuracy(self.labels, self.forward(self.features))\n",
    "            print(f\"ç¬¬{epoch+1}ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:{loss:.4f}, åˆ†ç±»å‡†ç¡®ç‡{accu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_relu(x):\n",
    "    '''\n",
    "    reluæ¿€æ´»å‡½æ•°çš„å¯¼æ•°\n",
    "    '''\n",
    "    d = torch.zeros_like(x)\n",
    "    d[x > 0] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_softmax(x):\n",
    "    '''\n",
    "    softmaxæ¿€æ´»å‡½æ•°çš„å¯¼æ•°\n",
    "    '''\n",
    "    d = torch.softmax(x, dim=1)\n",
    "    return d*(1-d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. æ¡ˆä¾‹-`fashion-mnist`æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è£…è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"\n",
    "    Load MNIST data from `path`\n",
    "    \"\"\"\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz'% kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz'% kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
    "    \n",
    "    features = transforms.ToTensor()(images)  # (h, w, c) -> (c, h, w)\n",
    "    labels = torch.LongTensor(labels)\n",
    "\n",
    "    return features[0], labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['çŸ­è¢–åœ†é¢†Tæ¤', 'è£¤å­', 'å¥—è¡«', 'è¿è¡£è£™', 'å¤–å¥—', 'å‡‰é‹', 'è¡¬è¡«', 'è¿åŠ¨é‹','åŒ…', 'çŸ­é´']\n",
    "text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoyu/miniforge3/envs/pyg_env/lib/python3.10/site-packages/torchvision/transforms/functional.py:154: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    }
   ],
   "source": [
    "features, labels = load_mnist(path=\"../dataset/fashion_mnist\")\n",
    "test_features, test_labels = load_mnist(path=\"../dataset/fashion_mnist\", kind=\"t10k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "W1 = torch.tensor(np.random.normal(0, 0.01, (num_hiddens, num_inputs)), dtype=torch.float)\n",
    "b1 = torch.zeros(num_hiddens, dtype=torch.float)\n",
    "W2 = torch.tensor(np.random.normal(0, 0.01, (num_outputs, num_hiddens)), dtype=torch.float)\n",
    "b2 = torch.zeros(num_outputs, dtype=torch.float)\n",
    "init_params = [[W1, b1, torch.relu, d_relu], [W2, b2, torch.softmax, d_softmax]]\n",
    "\n",
    "fnn = FNN(features, labels, init_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬1ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2958, åˆ†ç±»å‡†ç¡®ç‡0.7429\n",
      "ç¬¬2ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2721, åˆ†ç±»å‡†ç¡®ç‡0.7674\n",
      "ç¬¬3ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2270, åˆ†ç±»å‡†ç¡®ç‡0.8141\n",
      "ç¬¬4ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2080, åˆ†ç±»å‡†ç¡®ç‡0.8327\n",
      "ç¬¬5ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2264, åˆ†ç±»å‡†ç¡®ç‡0.8076\n",
      "ç¬¬6ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2261, åˆ†ç±»å‡†ç¡®ç‡0.8079\n",
      "ç¬¬7ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1966, åˆ†ç±»å‡†ç¡®ç‡0.8410\n",
      "ç¬¬8ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1944, åˆ†ç±»å‡†ç¡®ç‡0.8413\n",
      "ç¬¬9ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1985, åˆ†ç±»å‡†ç¡®ç‡0.8393\n",
      "ç¬¬10ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1855, åˆ†ç±»å‡†ç¡®ç‡0.8501\n",
      "ç¬¬11ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1737, åˆ†ç±»å‡†ç¡®ç‡0.8613\n",
      "ç¬¬12ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1983, åˆ†ç±»å‡†ç¡®ç‡0.8339\n",
      "ç¬¬13ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1757, åˆ†ç±»å‡†ç¡®ç‡0.8584\n",
      "ç¬¬14ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1696, åˆ†ç±»å‡†ç¡®ç‡0.8606\n",
      "ç¬¬15ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1710, åˆ†ç±»å‡†ç¡®ç‡0.8617\n",
      "ç¬¬16ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1733, åˆ†ç±»å‡†ç¡®ç‡0.8581\n",
      "ç¬¬17ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1738, åˆ†ç±»å‡†ç¡®ç‡0.8591\n",
      "ç¬¬18ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1743, åˆ†ç±»å‡†ç¡®ç‡0.8552\n",
      "ç¬¬19ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1678, åˆ†ç±»å‡†ç¡®ç‡0.8606\n",
      "ç¬¬20ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1628, åˆ†ç±»å‡†ç¡®ç‡0.8673\n",
      "ç¬¬21ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1595, åˆ†ç±»å‡†ç¡®ç‡0.8697\n",
      "ç¬¬22ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1619, åˆ†ç±»å‡†ç¡®ç‡0.8662\n",
      "ç¬¬23ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1640, åˆ†ç±»å‡†ç¡®ç‡0.8643\n",
      "ç¬¬24ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1729, åˆ†ç±»å‡†ç¡®ç‡0.8518\n",
      "ç¬¬25ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1657, åˆ†ç±»å‡†ç¡®ç‡0.8649\n",
      "ç¬¬26ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1577, åˆ†ç±»å‡†ç¡®ç‡0.8710\n",
      "ç¬¬27ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1655, åˆ†ç±»å‡†ç¡®ç‡0.8590\n",
      "ç¬¬28ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1504, åˆ†ç±»å‡†ç¡®ç‡0.8767\n",
      "ç¬¬29ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1788, åˆ†ç±»å‡†ç¡®ç‡0.8489\n",
      "ç¬¬30ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1540, åˆ†ç±»å‡†ç¡®ç‡0.8720\n",
      "ç¬¬31ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1611, åˆ†ç±»å‡†ç¡®ç‡0.8640\n",
      "ç¬¬32ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1550, åˆ†ç±»å‡†ç¡®ç‡0.8710\n",
      "ç¬¬33ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1508, åˆ†ç±»å‡†ç¡®ç‡0.8746\n",
      "ç¬¬34ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1771, åˆ†ç±»å‡†ç¡®ç‡0.8527\n",
      "ç¬¬35ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1577, åˆ†ç±»å‡†ç¡®ç‡0.8690\n",
      "ç¬¬36ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1780, åˆ†ç±»å‡†ç¡®ç‡0.8459\n",
      "ç¬¬37ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1771, åˆ†ç±»å‡†ç¡®ç‡0.8553\n",
      "ç¬¬38ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1635, åˆ†ç±»å‡†ç¡®ç‡0.8623\n",
      "ç¬¬39ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1598, åˆ†ç±»å‡†ç¡®ç‡0.8700\n",
      "ç¬¬40ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.1605, åˆ†ç±»å‡†ç¡®ç‡0.8675\n"
     ]
    }
   ],
   "source": [
    "fnn.minibatch_sgd_trainer(max_epochs=40, lr=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•é›†ä¸Šçš„äº¤å‰ç†µä¸º0.1884, æµ‹è¯•é›†çš„å‡†ç¡®ç‡ä¸º:0.8445\n"
     ]
    }
   ],
   "source": [
    "test_crossEn = fnn.cross_entropy(test_features, test_labels)\n",
    "test_accu = fnn.accuracy(test_labels, fnn.forward(test_features), is_one_hot=False)\n",
    "print(f\"æµ‹è¯•é›†ä¸Šçš„äº¤å‰ç†µä¸º{test_crossEn:.4f}, æµ‹è¯•é›†çš„å‡†ç¡®ç‡ä¸º:{test_accu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9013\n"
     ]
    }
   ],
   "source": [
    "p = 0.9\n",
    "succ_list = []\n",
    "n = 10000\n",
    "num = 0\n",
    "for i in range(n):\n",
    "    if p > np.random.rand():\n",
    "        succ_list.append(i)\n",
    "        num += 1\n",
    "        \n",
    "print(num / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. åˆå§‹åŒ–å’Œæ­£åˆ™åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 å‚æ•°åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¥ç»ç½‘ç»œçš„å‚æ•°å­¦ä¹ æ˜¯ä¸€ä¸ªéå‡¸ä¼˜åŒ–é—®é¢˜ï¼å½“ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•æ¥è¿›è¡Œä¼˜åŒ–ç½‘ç»œå‚æ•°æ—¶ï¼Œå‚æ•°åˆå§‹å€¼çš„é€‰å–ååˆ†å…³é”®ï¼Œå…³ç³»åˆ°ç½‘ç»œçš„ä¼˜åŒ–æ•ˆç‡å’Œæ³›åŒ–èƒ½åŠ›ï¼\n",
    "\n",
    "å‚æ•°åˆå§‹åŒ–çš„æ–¹å¼é€šå¸¸æœ‰ä»¥ä¸‹ä¸‰ç§ï¼š\n",
    "\n",
    "- é¢„è®­ç»ƒåˆå§‹åŒ–ï¼šä¸åŒçš„å‚æ•°åˆå§‹å€¼ä¼šæ”¶æ•›åˆ°ä¸åŒçš„å±€éƒ¨æœ€ä¼˜è§£ï¼è™½ç„¶è¿™äº›å±€éƒ¨æœ€ä¼˜è§£åœ¨è®­ç»ƒé›†ä¸Šçš„æŸå¤±æ¯”è¾ƒæ¥è¿‘ï¼Œä½†æ˜¯å®ƒä»¬çš„æ³›åŒ–èƒ½åŠ›å·®å¼‚å¾ˆå¤§ï¼ä¸€ä¸ªå¥½çš„åˆå§‹å€¼ä¼šä½¿å¾—ç½‘ç»œæ”¶æ•›åˆ°ä¸€ä¸ªæ³›åŒ–èƒ½åŠ›é«˜çš„å±€éƒ¨æœ€ä¼˜è§£ï¼é€šå¸¸æƒ…å†µä¸‹ï¼Œä¸€ä¸ªå·²ç»åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šè®­ç»ƒè¿‡çš„æ¨¡å‹å¯ä»¥æä¾›ä¸€ä¸ªå¥½çš„å‚æ•°åˆå§‹å€¼ï¼Œè¿™ç§åˆå§‹åŒ–æ–¹æ³•ç§°ä¸º**é¢„è®­ç»ƒåˆå§‹åŒ–(`Pre-trained Initialization`)**ï¼é¢„è®­ç»ƒä»»åŠ¡å¯ä»¥ä¸ºç›‘ç£å­¦ä¹ æˆ–æ— ç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼ç”±äºæ— ç›‘ç£å­¦ä¹ ä»»åŠ¡æ›´å®¹æ˜“è·å–å¤§è§„æ¨¡çš„è®­ç»ƒæ•°æ®ï¼Œå› æ­¤è¢«å¹¿æ³›é‡‡ç”¨ï¼é¢„è®­ç»ƒæ¨¡å‹åœ¨ç›®æ ‡ä»»åŠ¡ä¸Šçš„å­¦ä¹ è¿‡ç¨‹ä¹Ÿç§°ä¸º**ç²¾è°ƒ(`Fine-Tuning`)**ï¼\n",
    "- éšæœºåˆå§‹åŒ–ï¼šåœ¨çº¿æ€§æ¨¡å‹çš„è®­ç»ƒï¼ˆæ¯”å¦‚æ„ŸçŸ¥å™¨å’ŒLogistic å›å½’ï¼‰ä¸­ï¼Œæˆ‘ä»¬ä¸€èˆ¬å°†å‚æ•°å…¨éƒ¨åˆå§‹åŒ–ä¸º0ï¼ä½†æ˜¯è¿™åœ¨ç¥ç»ç½‘ç»œçš„è®­ç»ƒä¸­ä¼šå­˜åœ¨ä¸€äº›é—®é¢˜ï¼å› ä¸ºå¦‚æœå‚æ•°éƒ½ä¸º0ï¼Œåœ¨ç¬¬ä¸€éå‰å‘è®¡ç®—æ—¶ï¼Œæ‰€æœ‰çš„éšè—å±‚ç¥ç»å…ƒçš„æ¿€æ´»å€¼éƒ½ç›¸åŒï¼›åœ¨åå‘ä¼ æ’­æ—¶ï¼Œæ‰€æœ‰æƒé‡çš„æ›´æ–°ä¹Ÿéƒ½ç›¸åŒï¼Œè¿™æ ·ä¼šå¯¼è‡´éšè—å±‚ç¥ç»å…ƒæ²¡æœ‰åŒºåˆ†æ€§ï¼è¿™ç§ç°è±¡ä¹Ÿç§°ä¸º**å¯¹ç§°æƒé‡ç°è±¡**ï¼ä¸ºäº†æ‰“ç ´è¿™ä¸ªå¹³è¡¡ï¼Œæ¯”è¾ƒå¥½çš„æ–¹å¼æ˜¯å¯¹æ¯ä¸ªå‚æ•°éƒ½**éšæœºåˆå§‹åŒ–(`Random Initialization`)**ï¼Œä½¿å¾—ä¸åŒç¥ç»å…ƒä¹‹é—´çš„åŒºåˆ†æ€§æ›´å¥½ï¼\n",
    "- å›ºå®šå€¼åˆå§‹åŒ–ï¼šå¯¹äºä¸€äº›ç‰¹æ®Šçš„å‚æ•°ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®ç»éªŒç”¨ä¸€ä¸ªç‰¹æ®Šçš„å›ºå®šå€¼æ¥è¿›è¡Œåˆå§‹åŒ–ï¼æ¯”å¦‚åç½®(Bias)é€šå¸¸ç”¨0æ¥åˆå§‹åŒ–ï¼Œä½†æ˜¯æœ‰æ—¶å¯ä»¥è®¾ç½®æŸäº›ç»éªŒå€¼ä»¥æé«˜ä¼˜åŒ–æ•ˆç‡ï¼å¯¹äºä½¿ç”¨ReLU çš„ç¥ç»å…ƒï¼Œæœ‰æ—¶ä¹Ÿå¯ä»¥å°†åç½®è®¾ä¸º0.01ï¼Œä½¿å¾—ReLU ç¥ç»å…ƒåœ¨è®­ç»ƒåˆæœŸæ›´å®¹æ˜“æ¿€æ´»ï¼Œä»è€Œè·å¾—ä¸€å®šçš„æ¢¯åº¦æ¥è¿›è¡Œè¯¯å·®åå‘ä¼ æ’­ï¼\n",
    "\n",
    "è™½ç„¶é¢„è®­ç»ƒåˆå§‹åŒ–é€šå¸¸å…·æœ‰æ›´å¥½çš„æ”¶æ•›æ€§å’Œæ³›åŒ–æ€§ï¼Œä½†æ˜¯çµæ´»æ€§ä¸å¤Ÿï¼Œä¸èƒ½åœ¨ç›®æ ‡ä»»åŠ¡ä¸Šä»»æ„åœ°è°ƒæ•´ç½‘ç»œç»“æ„ï¼å› æ­¤ï¼Œå¥½çš„éšæœºåˆå§‹åŒ–æ–¹æ³•å¯¹è®­ç»ƒç¥ç»ç½‘ç»œæ¨¡å‹æ¥è¯´ä¾ç„¶ååˆ†é‡è¦ï¼è¿™é‡Œæˆ‘ä»¬ä»‹ç»ä¸‰ç±»å¸¸ç”¨çš„éšæœºåˆå§‹åŒ–æ–¹æ³•ï¼š\n",
    "- åŸºäºå›ºå®šæ–¹å·®çš„å‚æ•°åˆå§‹åŒ–\n",
    "- åŸºäºæ–¹å·®ç¼©æ”¾çš„å‚æ•°åˆå§‹åŒ–\n",
    "- æ­£äº¤åˆå§‹åŒ–æ–¹æ³•ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.zeros_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "def random_small_init(m, scale=0.01):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.normal_(m.weight, mean=0., std=scale)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias, mean=0., std=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_init(linear)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0051,  0.0157,  0.0030, -0.0016],\n",
       "        [ 0.0133,  0.0264, -0.0001,  0.0176],\n",
       "        [-0.0156, -0.0055,  0.0014,  0.0201],\n",
       "        [ 0.0014, -0.0157, -0.0102, -0.0113],\n",
       "        [-0.0110,  0.0058,  0.0138,  0.0004]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_small_init(linear)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 åŸºäºå›ºå®šæ–¹å·®çš„å‚æ•°åˆå§‹åŒ–\n",
    "\n",
    "- é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–ï¼šä½¿ç”¨ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒ$N(0,\\sigma^2)$å¯¹æ¯ä¸ªå‚æ•°è¿›è¡Œéšæœºåˆå§‹åŒ–ï¼\n",
    "- å‡åŒ€åˆ†å¸ƒåˆå§‹åŒ–ï¼šåœ¨ä¸€ä¸ªç»™å®šçš„åŒºé—´$[-r, r]$å†…é‡‡ç”¨å‡åŒ€åˆ†å¸ƒæ¥åˆå§‹åŒ–å‚æ•°ï¼å‡è®¾éšæœºå˜é‡xåœ¨åŒºé—´$[a, b]$å†…å‡åŒ€åˆ†å¸ƒï¼Œåˆ™å…¶æ–¹å·®ä¸º$var(x)=\\frac{(b-a)^2}{12}$. å› æ­¤ï¼Œè‹¥ä½¿ç”¨åŒºé—´ä¸º$[-r, r]$çš„å‡åˆ†åˆ†å¸ƒæ¥é‡‡æ ·ï¼Œå¹¶æ»¡è¶³$var(x)=\\sigma^2$æ—¶ï¼Œåˆ™ğ‘Ÿçš„å–å€¼ä¸º$r=\\sqrt{3\\sigma^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_init(m, limit=0.1):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.uniform_(m.weight, -limit, limit)\n",
    "        if m.bias is not None:\n",
    "            init.uniform_(m.bias, -limit, limit)\n",
    "\n",
    "def normal_init(m, mean=0.0, std=0.05):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.normal_(m.weight, mean, std)\n",
    "        if m.bias is not None:\n",
    "            init.normal_(m.bias, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0966, -0.0815,  0.0951, -0.0038],\n",
       "        [ 0.0082, -0.0410,  0.0604, -0.0348],\n",
       "        [ 0.0560, -0.0570,  0.0083, -0.0569],\n",
       "        [ 0.0684,  0.0224, -0.0690, -0.0007],\n",
       "        [-0.0090,  0.0278, -0.0242,  0.0561]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniform_init(linear)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0252,  0.0729,  0.0522,  0.0355],\n",
       "        [-0.0187,  0.0922, -0.0352,  0.0004],\n",
       "        [-0.0791, -0.0533,  0.0084, -0.0010],\n",
       "        [-0.0042,  0.0024,  0.0125,  0.0231],\n",
       "        [ 0.0244, -0.0016,  0.0383, -0.0605]], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_init(linear)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 åŸºäºæ–¹å·®ç¼©æ”¾çš„å‚æ•°åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| åˆå§‹åŒ–æ–¹æ³• | æ¿€æ´»å‡½æ•° | å‡åŒ€åˆ†å¸ƒ$[-r, r]$ | é«˜æ–¯åˆ†å¸ƒ $N(0, \\sigma^2)$ |\n",
    "| ----: | ----: | ----: | ----: |\n",
    "| Xavier | Logistic | $r=4\\sqrt{\\frac{6}{M_{l-1}+M_l}}$ | $\\sigma^2=16\\times \\frac{2}{M_{l-1}+M_l}$ |\n",
    "| Xavier | tanh | $r=\\sqrt{\\frac{6}{M_{l-1}+M_l}}$ | $\\sigma^2=\\frac{2}{M_{l-1}+M_l}$ |\n",
    "| He | reLu | $r=\\sqrt{\\frac{6}{M_{l-1}}}$ | $\\sigma^2=\\frac{2}{M_{l-1}}$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_uniform_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "def xavier_normal_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2737, -0.6806, -0.5349, -0.7650],\n",
       "        [ 0.7183,  0.4407, -0.4204,  0.2533],\n",
       "        [ 0.4537,  0.7934, -0.4715, -0.7976],\n",
       "        [-0.4746,  0.3190, -0.3391, -0.1280],\n",
       "        [ 0.6417, -0.5027,  0.7957,  0.4687]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xavier_uniform_init(linear)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def he_uniform_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "def he_normal_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.7659,  0.4525, -0.8623,  0.0508],\n",
       "        [-0.4903, -0.4842, -0.5590, -0.0270],\n",
       "        [-1.8107,  0.5373, -1.7465,  0.3396],\n",
       "        [ 1.5636,  0.0913,  0.7725, -1.4994],\n",
       "        [-0.0165, -0.7294, -0.6631, -0.3167]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_normal_init(linear)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.3 æ­£äº¤åˆå§‹åŒ–\n",
    "\n",
    "ç”¨äºä¿æŒæ¯å±‚è¾“å…¥çš„ç‰¹å¾åˆ†å¸ƒåœ¨å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­æ—¶ä¿æŒä¸å˜ã€‚å…·ä½“æ¥è¯´ï¼Œå¯¹äºæ¯ä¸€å±‚çš„æƒé‡çŸ©é˜µè¿›è¡Œæ­£äº¤åŒ–å¤„ç†ã€‚è¿™ç§æ–¹æ³•ç‰¹åˆ«é€‚åˆäºå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ï¼Œå¯ä»¥æœ‰æ•ˆé˜²æ­¢æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonal_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.orthogonal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3259,  0.0148,  0.8493,  0.4147],\n",
       "        [-0.8332, -0.0798, -0.3650,  0.1123],\n",
       "        [-0.1414,  0.7852, -0.2349,  0.3226],\n",
       "        [ 0.0054,  0.6042,  0.2626, -0.5326],\n",
       "        [-0.4238, -0.1090,  0.1462, -0.6540]], requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthogonal_init(linear)\n",
    "linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 æ­£åˆ™åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 $l_1$å’Œ$l_2$æ­£åˆ™åŒ–\n",
    "**â„“1å’Œâ„“2** æ­£åˆ™åŒ–æ˜¯æœºå™¨å­¦ä¹ ä¸­æœ€å¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œé€šè¿‡çº¦æŸå‚æ•°çš„â„“1 å’Œâ„“2èŒƒæ•°æ¥å‡å°æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šçš„è¿‡æ‹Ÿåˆç°è±¡.\n",
    "$$\n",
    "\\theta^*=\\text{arg}\\min \\frac{1}{N}\\sum_{n=1}^N \\mathbf{L}(y^{(n)},f(x^{(n)};\\theta))+\\lambda \\mathrm{â„“_p}(\\theta)\n",
    "$$\n",
    "å…¶ä¸­$\\mathbf{L(\\cdot)}$ä¸ºæŸå¤±å‡½æ•°ï¼ŒNä¸ºè®­ç»ƒæ ·æœ¬ï¼Œ$f(\\cdot)$ä¸ºå¾…å­¦ä¹ çš„ç¥ç»ç½‘ç»œï¼Œ$\\theta$ä¸ºå‚æ•°ï¼Œ$â„“_p$ä¸ºèŒƒæ•°å‡½æ•°ï¼Œğ‘ çš„å–å€¼é€šå¸¸ä¸º{1, 2} ä»£è¡¨$â„“_1$ å’Œ$â„“_2$ èŒƒæ•°ï¼Œğœ† ä¸ºæ­£åˆ™åŒ–ç³»æ•°ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 æƒé‡è¡°å‡\n",
    "\n",
    "**æƒé‡è¡°å‡(Weight Decay)** æ˜¯ä¸€ç§æœ‰æ•ˆçš„æ­£åˆ™åŒ–æ–¹æ³•(`Hanson et al., 1989`)ï¼Œåœ¨æ¯æ¬¡å‚æ•°æ›´æ–°æ—¶ï¼Œå¼•å…¥ä¸€ä¸ªè¡°å‡ç³»æ•°ï¼\n",
    "$$\n",
    "\\begin{aligned}\n",
    "W^l &:= (1-\\beta)W^l - \\alpha \\frac{\\partial C}{\\partial W^l}\\\\\n",
    "b^l &:= (1-\\beta)b^l - \\alpha \\frac{\\partial C}{\\partial b^l}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "å…¶ä¸­$\\alpha$ä¸ºå­¦ä¹ ç‡ï¼Œ$\\beta$ä¸ºæƒé‡è¡°å‡ç³»æ•°ï¼Œä¸€èˆ¬å–å€¼æ¯”è¾ƒå°ï¼Œæ¯”å¦‚0.0005ï¼åœ¨æ ‡å‡†çš„éšæœºæ¢¯åº¦ä¸‹é™ä¸­ï¼Œæƒé‡è¡°å‡æ­£åˆ™åŒ–å’Œ$â„“_2$æ­£åˆ™åŒ–çš„æ•ˆæœç›¸åŒï¼å› æ­¤ï¼Œæƒé‡è¡°å‡åœ¨ä¸€äº›æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­é€šè¿‡$â„“_2$æ­£åˆ™åŒ–æ¥å®ç°ï¼ä½†æ˜¯ï¼Œè¾ƒä¸ºå¤æ‚çš„ä¼˜åŒ–æ–¹æ³•ï¼ˆæ¯”å¦‚Adamï¼‰ä¸­ï¼Œæƒé‡è¡°å‡æ­£åˆ™åŒ–å’Œ$â„“_2$æ­£åˆ™åŒ–å¹¶ä¸ç­‰ä»·."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 æå‰ç»ˆæ­¢\n",
    "**æå‰åœæ­¢(Early Stop)** å¯¹äºæ·±åº¦ç¥ç»ç½‘ç»œæ¥è¯´æ˜¯ä¸€ç§ç®€å•æœ‰æ•ˆçš„æ­£åˆ™åŒ–æ–¹æ³•ï¼ç”±äºæ·±åº¦ç¥ç»ç½‘ç»œçš„æ‹Ÿåˆèƒ½åŠ›éå¸¸å¼ºï¼Œå› æ­¤æ¯”è¾ƒå®¹æ˜“åœ¨è®­ç»ƒé›†ä¸Šè¿‡æ‹Ÿåˆï¼åœ¨ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ³•è¿›è¡Œä¼˜åŒ–æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå’Œè®­ç»ƒé›†ç‹¬ç«‹çš„æ ·æœ¬é›†åˆï¼Œç§°ä¸ºéªŒè¯é›†ï¼ˆValidation Setï¼‰ï¼Œå¹¶ç”¨éªŒè¯é›†ä¸Šçš„é”™è¯¯æ¥ä»£æ›¿æœŸæœ›é”™è¯¯ï¼å½“éªŒè¯é›†ä¸Šçš„é”™è¯¯ç‡ä¸å†ä¸‹é™ï¼Œå°±åœæ­¢è¿­ä»£ï¼ç„¶è€Œåœ¨å®é™…æ“ä½œä¸­ï¼ŒéªŒè¯é›†ä¸Šçš„é”™è¯¯ç‡å˜åŒ–æ›²çº¿å¾ˆå¯èƒ½æ˜¯å…ˆå‡é«˜å†é™ä½ï¼å› æ­¤ï¼Œæå‰åœæ­¢çš„å…·ä½“åœæ­¢æ ‡å‡†éœ€è¦æ ¹æ®å®é™…ä»»åŠ¡è¿›è¡Œä¼˜åŒ–(`Prechelt, 1998`)ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 ä¸¢å¼ƒæ³•`dropout`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“è®­ç»ƒä¸€ä¸ªæ·±åº¦ç¥ç»ç½‘ç»œæ—¶ï¼Œ æˆ‘ä»¬å¯ä»¥éšæœºä¸¢å¼ƒä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼ˆåŒæ—¶ä¸¢å¼ƒå…¶å¯¹åº”çš„è¿æ¥è¾¹ï¼‰æ¥é¿å…è¿‡æ‹Ÿåˆï¼Œè¿™ç§æ–¹æ³•ç§°ä¸º**ä¸¢å¼ƒæ³•ï¼ˆDropout Methodï¼‰** [Srivastava et al., 2014]ï¼æ¯æ¬¡é€‰æ‹©ä¸¢å¼ƒçš„ç¥ç»å…ƒæ˜¯éšæœºçš„ï¼æœ€ç®€å•çš„æ–¹æ³•æ˜¯è®¾ç½®ä¸€ä¸ªå›ºå®šçš„æ¦‚ç‡ğ‘ï¼å¯¹æ¯ä¸€ä¸ªç¥ç»å…ƒéƒ½ä»¥æ¦‚ç‡ğ‘ æ¥åˆ¤å®šè¦ä¸è¦ä¿ç•™, è‹¥$p=1$ï¼Œåˆ™æ„å‘³ç€éœ€è¦ä¿ç•™è¯¥ç¥ç»å…ƒï¼›è‹¥$p=0$, åˆ™æ„å‘³ç€ä¸ä¿ç•™è¯¥ç¥ç»å…ƒï¼å¯¹äºä¸€ä¸ªç¥ç»å±‚$y=f(W@x + b)$ï¼Œæˆ‘ä»¬å¯ä»¥å¼•å…¥ä¸€ä¸ªæ©è”½å‡½æ•°`mask(â‹…)` ä½¿å¾—$y=f(W@mask(x) + b)$ï¼æ©è”½å‡½æ•°mask(â‹…) çš„å®šä¹‰ä¸º\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{mask}(x)=\\begin{cases} m \\odot x \\text{  è®­ç»ƒæ—¶}\\\\\n",
    "px \\text{  æµ‹è¯•æ—¶}\\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "æˆ–è€…\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\mathrm{mask}(x)=\\begin{cases} m \\odot \\frac{x}{p} \\text{  è®­ç»ƒæ—¶}\\\\\n",
    "x \\text{  æµ‹è¯•æ—¶}\\\\\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropoutæ¦‚ç‡è®¾ç½®ä¸º0.5\n",
    "dropout = nn.Dropout(p=0.1)\n",
    "# å‡è®¾æœ‰ä¸€å±‚çš„è¾“å‡º\n",
    "layer_output = torch.randn(4, 5)  # éšæœºç”Ÿæˆä¸€äº›æ•°æ®\n",
    "# åº”ç”¨Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output with Dropout during training:\n",
      "tensor([[-2.3158,  1.2802,  0.6884,  1.1302,  0.8604],\n",
      "        [ 0.8891,  0.8564,  2.3151,  0.5656,  0.2610],\n",
      "        [-0.8781, -0.2319,  1.2873,  1.0985,  0.1818],\n",
      "        [ 0.5214,  0.1659, -0.0000, -0.0000,  1.0159]])\n"
     ]
    }
   ],
   "source": [
    "output_during_training = dropout(layer_output)\n",
    "# è¾“å‡ºæŸ¥çœ‹\n",
    "print(\"Output with Dropout during training:\")\n",
    "print(output_during_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (layer1): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (layer2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(784, 256)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.layer2 = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)  # åœ¨ç¬¬ä¸€å±‚ååº”ç”¨Dropout\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "# æ³¨æ„ï¼šæ¨¡å‹è®­ç»ƒæ—¶ä¼šåº”ç”¨Dropoutï¼Œæµ‹è¯•æ—¶éœ€å…³é—­Dropout\n",
    "model = MyModel()\n",
    "model.train()  # ç¡®ä¿æ˜¯è®­ç»ƒæ¨¡å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `model.train()`å’Œ`model.eval()`çš„åŒºåˆ«åœ¨äºè®­ç»ƒæ—¶ï¼Œæ¨¡å‹ä¸­çš„dropoutå±‚ä¼šä¿ç•™ï¼Œè€Œåœ¨æµ‹è¯•æ—¶ï¼Œdropoutå±‚ä¼šè¢«ç§»é™¤ï¼æ­¤å¤–ï¼Œå¯¹äºä¸€äº›ç‰¹æ®Šçš„å±‚ï¼Œæ¯”å¦‚Batch Normalizationå±‚ï¼Œè®­ç»ƒæ—¶å’Œæµ‹è¯•æ—¶çš„è¡Œä¸ºä¹Ÿæ˜¯ä¸åŒçš„ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 3.3333, 0.0000, 3.3333, 3.3333],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [3.3333, 0.0000, 3.3333, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 3.3333, 0.0000, 0.0000],\n",
       "        [3.3333, 3.3333, 3.3333, 0.0000, 3.3333],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 3.3333],\n",
       "        [3.3333, 3.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [3.3333, 3.3333, 3.3333, 3.3333, 0.0000],\n",
       "        [0.0000, 0.0000, 3.3333, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 3.3333, 3.3333],\n",
       "        [0.0000, 0.0000, 0.0000, 3.3333, 3.3333],\n",
       "        [0.0000, 3.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 3.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 3.3333, 0.0000, 0.0000],\n",
       "        [3.3333, 0.0000, 0.0000, 3.3333, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 3.3333],\n",
       "        [0.0000, 0.0000, 3.3333, 0.0000, 0.0000],\n",
       "        [0.0000, 3.3333, 3.3333, 3.3333, 3.3333]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randint(1, high=10, size=(20, 5))\n",
    "p = 0.3\n",
    "b = p*torch.ones_like(a)\n",
    "torch.bernoulli(b) / p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN2:\n",
    "    def __init__(self, features, labels, params, prob_dropout, batch_size=256):\n",
    "        '''\n",
    "        features: ç‰¹å¾\n",
    "        labels: æ ‡ç­¾\n",
    "        paramså…ƒç´ : (æƒé‡çŸ©é˜µ, åç½®å‘é‡, æ¿€æ´»å‡½æ•°, æ¿€æ´»å‡½æ•°çš„å¯¼æ•°)\n",
    "        æ³¨æ„: æƒé‡çš„å½¢å¼ä¸º (M_{l}, M_{l-1}), åç½®çš„å½¢å¼ä¸º (1, M_{l})\n",
    "        '''\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.params = params\n",
    "        self.prob_dropout = prob_dropout  # å¯¹éšè—å±‚è¿›è¡Œdropoutæ“ä½œ\n",
    "        self.train_iter = self.data_loader(batch_size=256)\n",
    "    \n",
    "    def data_loader(self, batch_size, is_one_hot=True):\n",
    "        '''\n",
    "        æ„å»ºå°æ‰¹é‡æ•°æ®é›†\n",
    "        '''\n",
    "        if is_one_hot:\n",
    "            hot_labels = torch.zeros(self.features.shape[0], 10)\n",
    "            x_indices = np.arange(self.features.shape[0]).tolist()\n",
    "            y_indices = self.labels.byte().tolist()\n",
    "            hot_labels[x_indices, y_indices] = 1\n",
    "            dataset = TensorDataset(self.features, hot_labels)\n",
    "        else:\n",
    "            dataset = TensorDataset(self.features, self.labels)\n",
    "\n",
    "        return DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    def mask(self, X, p):\n",
    "        '''\n",
    "        X: è¾“å…¥\n",
    "        p: ç¥ç»å…ƒçš„ä¿ç•™æ¦‚ç‡\n",
    "        è‹¥è¾“å…¥Xé™¤ä»¥æ¦‚ç‡pï¼Œåˆ™ä½¿Xçš„æœŸæœ›ä¿æŒä¸å˜, é¢„æµ‹æ—¶,ç¥ç»ç½‘ç»œçš„æƒé‡ä¸ç”¨è½¬æ¢ï¼›\n",
    "        è‹¥è®­ç»ƒæ—¶æŒ‰æ­£å¸¸çš„è¾“å…¥è®­ç»ƒXï¼Œé¢„æµ‹æ—¶ç¥ç»ç½‘ç»œä¸­å¯¹åº”çš„æƒé‡éœ€ä¹˜p\n",
    "        '''\n",
    "        if p == 0:\n",
    "            return torch.zeros_like(X)\n",
    "        elif p == 1:\n",
    "            return X\n",
    "        else:\n",
    "            prob = p*torch.ones_like(X)\n",
    "            return X*torch.bernoulli(prob)/p\n",
    "    \n",
    "    def train_forward(self, X):\n",
    "        '''\n",
    "        è®­ç»ƒç”¨ç¥ç»å…ƒå‰é¦ˆä¼ é€’ä¿¡æ¯: ä¾ç…§æ¦‚ç‡péšæœºå…³é—­ä¸€äº›ç¥ç»å…ƒ\n",
    "        '''\n",
    "        y = X  # åˆå§‹åŒ–è¾“å…¥features\n",
    "        self.z_list, self.a_list = [], [y]  # è®°å½•å„å±‚çš„å‡€å€¼å’Œæ¿€æ´»å€¼\n",
    "        for i, (weight, bias, func, _) in enumerate(self.params, start=1):\n",
    "            p = self.prob_dropout[i]\n",
    "            z = y@torch.transpose(weight, 0, 1) + bias.reshape(1, -1)  # (N, M_{l-1}) @ (M_{l-1}, M_{l}) + (1, M_{l}), broadcast\n",
    "            mask_z = self.mask(z, p)\n",
    "            if func:\n",
    "                if func.__name__ == 'softmax':\n",
    "                    y = func(mask_z, dim=1)\n",
    "                else:\n",
    "                    y = func(mask_z)\n",
    "            else:\n",
    "                y = mask_z\n",
    "            \n",
    "            self.z_list.append(mask_z)\n",
    "            self.a_list.append(y)\n",
    "        return y.double()\n",
    "    \n",
    "    def predict_forward(self, X):\n",
    "        '''\n",
    "        é¢„æµ‹ç”¨ç¥ç»å…ƒå‰é¦ˆä¼ é€’ä¿¡æ¯: ä½¿ç”¨æ‰€æœ‰ç¥ç»å…ƒ\n",
    "        '''\n",
    "        y = X  # åˆå§‹åŒ–è¾“å…¥features\n",
    "        for i, (weight, bias, func, _) in enumerate(self.params):\n",
    "            z = y@torch.transpose(weight, 0, 1) + bias.reshape(1, -1)\n",
    "            if func:\n",
    "                if func.__name__ == 'softmax':\n",
    "                    y = func(z, dim=1)\n",
    "                else:\n",
    "                    y = func(z)\n",
    "            else:\n",
    "                y = z\n",
    "\n",
    "        return y.double()\n",
    "    \n",
    "    def cal_neuron_errors(self, y):\n",
    "        '''\n",
    "        è®¡ç®—ç¥ç»å…ƒçš„è¯¯å·®\n",
    "        '''\n",
    "        # è¾“å‡ºå±‚è¯¯å·®\n",
    "        error_L = self.a_list[-1] - y\n",
    "        self.error_list = [error_L]\n",
    "        for i in range(len(self.params)-1):\n",
    "            weight = self.params[-i-1][0]  # æƒé‡çŸ©é˜µ\n",
    "            der_f = self.params[-i-1][-1]  # å¯¼æ•°\n",
    "            error_up = self.error_list[-1]  # ä¸Šä¸€å±‚çš„è¯¯å·®\n",
    "            z = self.z_list[-i-2]  # å½“å‰å±‚çš„å‡€å€¼\n",
    "            error = error_up@weight * der_f(z)  #  (N, M_{l})@(M_{l}, M_{l-1}) = (N, M_{l-1})\n",
    "            self.error_list.append(error)\n",
    "            \n",
    "        self.error_list.reverse()\n",
    "    \n",
    "    def cal_params_partial(self):\n",
    "        '''\n",
    "        è®¡ç®—æŸå¤±å‡½æ•°å…³äºæƒé‡å’Œåç½®çš„åå¯¼æ•°\n",
    "        '''\n",
    "        self.der_weight_list = []\n",
    "        self.der_bias_list = []\n",
    "        for i in range(len(self.params)):\n",
    "            a_out = self.a_list[i]\n",
    "            error_in = self.error_list[i]\n",
    "            # ä»¥ä¸‹è®¡ç®—å‡ºæ¥çš„æ˜¯æ¯ä¸ªæ ·æœ¬å¯¹åº”çš„der_weightæ„æˆçš„çŸ©é˜µï¼Œå½’çº¦æˆ1ç»´ï¼Œå¯é‡‡ç”¨å‡å€¼æˆ–æ±‚å’Œçš„å½¢å¼\n",
    "            der_weight = torch.transpose(error_in, 0, 1)@a_out / self.a_list[0].shape[0]  # (M_{l}, N) @ (N, M{l-1})\n",
    "            der_bias = torch.mean(torch.transpose(error_in, 0, 1), axis=1)  # (M_{l}, N)\n",
    "            self.der_weight_list.append(der_weight)\n",
    "            self.der_bias_list.append(der_bias)\n",
    "        \n",
    "    def backward(self, y):\n",
    "        '''\n",
    "        è¯¯å·®åå‘ä¼ æ’­ç®—æ³•å®ç°\n",
    "        '''\n",
    "        self.cal_neuron_errors(y)\n",
    "        self.cal_params_partial()\n",
    "\n",
    "    def cross_entropy(self, y, hat_y):\n",
    "        '''\n",
    "        é‡‡ç”¨äº¤å‰ç†µæŸå¤±å‡½æ•°\n",
    "        y: one-hotå½¢å¼\n",
    "        hat_y: softmaxä¹‹åå¯¹åº”æ¦‚ç‡å‘é‡ï¼Œå¤šå±‚æ„ŸçŸ¥æœºçš„è¾“å‡º\n",
    "        '''\n",
    "        if len(y.shape) == 2:\n",
    "            crossEnt = -torch.dot(y.reshape(-1), torch.log10(hat_y.float()).reshape(-1)) / y.shape[0]  # å±•å¼€æˆ1ç»´ï¼Œç‚¹ç§¯\n",
    "        elif len(y.shape) == 1:\n",
    "            crossEnt = -torch.mean(torch.log10(hat_y[torch.arange(y.shape[0]), y.long()]))\n",
    "        else:\n",
    "            print(\"Wrong format of y!\")\n",
    "        return crossEnt\n",
    "    \n",
    "    def accuracy(self, y, hat_y, is_one_hot=False):\n",
    "        '''\n",
    "        y: æ ‡ç­¾, one-hot\n",
    "        hat_y: æ ‡ç­¾é¢„æµ‹æ¦‚ç‡, one-hot\n",
    "        is_one_hot: yæ˜¯å¦ä¸ºone-hotå½¢å¼\n",
    "        '''\n",
    "        if is_one_hot:\n",
    "            precision = torch.sum(torch.max(y, axis=1)[1] == torch.max(hat_y, axis=1)[1]).numpy() / y.shape[0]\n",
    "        else:\n",
    "            precision = torch.sum((y == torch.max(hat_y, axis=1)[1]).byte()).numpy() / y.shape[0]\n",
    "        return precision\n",
    "    \n",
    "    def minibatch_sgd_trainer(self, max_epochs=10, lr=0.1, decay=0.0005):\n",
    "        '''\n",
    "        è®­ç»ƒ\n",
    "        lr: å­¦ä¹ ç‡\n",
    "        decay: æƒé‡è¡°å‡ç³»æ•°\n",
    "        '''\n",
    "        for epoch in range(max_epochs):\n",
    "            for X, y in self.train_iter:\n",
    "                self.train_forward(X)  # å‰å‘ä¼ æ’­\n",
    "                self.backward(y)  # è¯¯å·®åå‘ä¼ æ’­\n",
    "                for i in range(len(self.params)):\n",
    "                    self.params[i][0] = (1 - decay)*self.params[i][0] - lr*self.der_weight_list[i]\n",
    "                    self.params[i][1] = (1 - decay)*self.params[i][1] - lr*self.der_bias_list[i]\n",
    "            \n",
    "            hat_labels = self.predict_forward(self.features)\n",
    "            loss = self.cross_entropy(self.labels, hat_labels)\n",
    "            accu = self.accuracy(self.labels, hat_labels)\n",
    "            print(f\"ç¬¬{epoch+1}ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:{loss:.4f}, åˆ†ç±»å‡†ç¡®ç‡{accu:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "W1 = torch.tensor(np.random.normal(0, 2/num_inputs, (num_hiddens, num_inputs)), dtype=torch.float)\n",
    "b1 = torch.zeros(num_hiddens, dtype=torch.float)\n",
    "W2 = torch.tensor(np.random.normal(0, 2/num_hiddens, (num_outputs, num_hiddens)), dtype=torch.float)\n",
    "b2 = torch.zeros(num_outputs, dtype=torch.float)\n",
    "init_params = [[W1, b1, torch.relu, d_relu], [W2, b2, torch.softmax, d_softmax]]\n",
    "prob_dropout = [0.95, 0.5, 1]  # [è¾“å…¥å±‚, éšè—å±‚, è¾“å‡ºå±‚]\n",
    "\n",
    "fnn2 = FNN2(features, labels, init_params, prob_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç¬¬1ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.9618, åˆ†ç±»å‡†ç¡®ç‡0.4646\n",
      "ç¬¬2ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.7850, åˆ†ç±»å‡†ç¡®ç‡0.5147\n",
      "ç¬¬3ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.5936, åˆ†ç±»å‡†ç¡®ç‡0.5990\n",
      "ç¬¬4ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.4973, åˆ†ç±»å‡†ç¡®ç‡0.6266\n",
      "ç¬¬5ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.4396, åˆ†ç±»å‡†ç¡®ç‡0.6800\n",
      "ç¬¬6ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.4021, åˆ†ç±»å‡†ç¡®ç‡0.6919\n",
      "ç¬¬7ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3756, åˆ†ç±»å‡†ç¡®ç‡0.7115\n",
      "ç¬¬8ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3583, åˆ†ç±»å‡†ç¡®ç‡0.7064\n",
      "ç¬¬9ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3435, åˆ†ç±»å‡†ç¡®ç‡0.7259\n",
      "ç¬¬10ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3325, åˆ†ç±»å‡†ç¡®ç‡0.7330\n",
      "ç¬¬11ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3239, åˆ†ç±»å‡†ç¡®ç‡0.7321\n",
      "ç¬¬12ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3198, åˆ†ç±»å‡†ç¡®ç‡0.7215\n",
      "ç¬¬13ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3109, åˆ†ç±»å‡†ç¡®ç‡0.7416\n",
      "ç¬¬14ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3086, åˆ†ç±»å‡†ç¡®ç‡0.7413\n",
      "ç¬¬15ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3016, åˆ†ç±»å‡†ç¡®ç‡0.7461\n",
      "ç¬¬16ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3013, åˆ†ç±»å‡†ç¡®ç‡0.7462\n",
      "ç¬¬17ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2982, åˆ†ç±»å‡†ç¡®ç‡0.7511\n",
      "ç¬¬18ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2916, åˆ†ç±»å‡†ç¡®ç‡0.7523\n",
      "ç¬¬19ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2878, åˆ†ç±»å‡†ç¡®ç‡0.7600\n",
      "ç¬¬20ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2865, åˆ†ç±»å‡†ç¡®ç‡0.7596\n",
      "ç¬¬21ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2817, åˆ†ç±»å‡†ç¡®ç‡0.7589\n",
      "ç¬¬22ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2794, åˆ†ç±»å‡†ç¡®ç‡0.7639\n",
      "ç¬¬23ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2774, åˆ†ç±»å‡†ç¡®ç‡0.7664\n",
      "ç¬¬24ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2772, åˆ†ç±»å‡†ç¡®ç‡0.7656\n",
      "ç¬¬25ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2746, åˆ†ç±»å‡†ç¡®ç‡0.7610\n",
      "ç¬¬26ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2721, åˆ†ç±»å‡†ç¡®ç‡0.7694\n",
      "ç¬¬27ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2712, åˆ†ç±»å‡†ç¡®ç‡0.7737\n",
      "ç¬¬28ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2664, åˆ†ç±»å‡†ç¡®ç‡0.7756\n",
      "ç¬¬29ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2668, åˆ†ç±»å‡†ç¡®ç‡0.7728\n",
      "ç¬¬30ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2644, åˆ†ç±»å‡†ç¡®ç‡0.7771\n",
      "ç¬¬31ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2621, åˆ†ç±»å‡†ç¡®ç‡0.7825\n",
      "ç¬¬32ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2601, åˆ†ç±»å‡†ç¡®ç‡0.7829\n",
      "ç¬¬33ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2627, åˆ†ç±»å‡†ç¡®ç‡0.7814\n",
      "ç¬¬34ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2567, åˆ†ç±»å‡†ç¡®ç‡0.7845\n",
      "ç¬¬35ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2552, åˆ†ç±»å‡†ç¡®ç‡0.7898\n",
      "ç¬¬36ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2528, åˆ†ç±»å‡†ç¡®ç‡0.7904\n",
      "ç¬¬37ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2516, åˆ†ç±»å‡†ç¡®ç‡0.7940\n",
      "ç¬¬38ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2503, åˆ†ç±»å‡†ç¡®ç‡0.7945\n",
      "ç¬¬39ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2493, åˆ†ç±»å‡†ç¡®ç‡0.7941\n",
      "ç¬¬40ä¸ªå›åˆ, è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.2475, åˆ†ç±»å‡†ç¡®ç‡0.7973\n"
     ]
    }
   ],
   "source": [
    "fnn2.minibatch_sgd_trainer(max_epochs=40, lr=0.1, decay=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•é›†ä¸Šçš„äº¤å‰ç†µä¸º0.2557, æµ‹è¯•é›†çš„å‡†ç¡®ç‡ä¸º:0.7890\n"
     ]
    }
   ],
   "source": [
    "hat_test_labels = fnn2.predict_forward(test_features)\n",
    "test_crossEn = fnn2.cross_entropy(test_labels, hat_test_labels)\n",
    "test_accu = fnn2.accuracy(test_labels, hat_test_labels, is_one_hot=False)\n",
    "print(f\"æµ‹è¯•é›†ä¸Šçš„äº¤å‰ç†µä¸º{test_crossEn:.4f}, æµ‹è¯•é›†çš„å‡†ç¡®ç‡ä¸º:{test_accu:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ç”±torchæ¨¡å—å®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, dim_in=784, dim_hidden=256, dim_out=10, p=0.1):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(dim_in, dim_hidden)\n",
    "        self.dropout1 = nn.Dropout(p=p)\n",
    "        self.layer2 = nn.Linear(dim_hidden, dim_out)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.dropout1(x)  # åœ¨ç¬¬ä¸€å±‚ååº”ç”¨Dropout\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(TensorDataset(features, labels), batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.4142, åˆ†ç±»å‡†ç¡®ç‡0.8564\n",
      "è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3611, åˆ†ç±»å‡†ç¡®ç‡0.8721\n",
      "è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3551, åˆ†ç±»å‡†ç¡®ç‡0.8734\n",
      "è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:0.3178, åˆ†ç±»å‡†ç¡®ç‡0.8837\n"
     ]
    }
   ],
   "source": [
    "# æ„å»ºè®­ç»ƒå®ä¾‹\n",
    "net = Net(p=0.1)\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1, weight_decay=0.00001)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# è®­ç»ƒæ¨¡å¼\n",
    "net.train()\n",
    "for i in range(20):\n",
    "    for X, y in dataloader:\n",
    "        trainer.zero_grad()\n",
    "        l = loss(net(X), y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "    \n",
    "    if (i+1) % 5 == 0:\n",
    "        net.eval()  # è¯„ä¼°æ¨¡å¼\n",
    "        with torch.no_grad():\n",
    "            hat_labels = net(features)\n",
    "            l = loss(hat_labels, labels)\n",
    "            accu = accuracy_score(labels, torch.max(hat_labels, axis=1)[1])\n",
    "            print(f\"è®­ç»ƒé›†äº¤å‰ç†µæŸå¤±ä¸º:{l:.4f}, åˆ†ç±»å‡†ç¡®ç‡{accu:.4f}\")\n",
    "        \n",
    "        net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æµ‹è¯•é›†äº¤å‰ç†µæŸå¤±ä¸º:0.3786, åˆ†ç±»å‡†ç¡®ç‡0.8587\n"
     ]
    }
   ],
   "source": [
    "net.eval()  # è¯„ä¼°æ¨¡å¼\n",
    "with torch.no_grad():\n",
    "    hat_test_labels = net(test_features)\n",
    "    l = loss(hat_test_labels, test_labels)\n",
    "    accu = accuracy_score(test_labels, torch.max(hat_test_labels, axis=1)[1])\n",
    "    print(f\"æµ‹è¯•é›†äº¤å‰ç†µæŸå¤±ä¸º:{l:.4f}, åˆ†ç±»å‡†ç¡®ç‡{accu:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å‚è€ƒèµ„æ–™\n",
    "1. é‚±é”¡é¹. ç¥ç»ç½‘ç»œä¸æœºå™¨å­¦ä¹ . 2020.\n",
    "2. [é˜¿æ–¯é¡¿Â·å¼ ã€ææ²ã€æ‰å¡é‡Œ C. ç«‹é¡¿ã€äºšå†å±±å¤§ J. æ–¯è«æ‹‰ç­‰. åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ . 2020.](https://github.com/d2l-ai/d2l-zh)\n",
    "3. [åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ (Pytochå®ç°)](https://github.com/ShusenTang/Dive-into-DL-PyTorch)\n",
    "4. Michael Nielsen. Neural network and deep learning. 2016."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
