{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四. 朴素贝叶斯法\n",
    "\n",
    "朴素贝叶斯法(naive Bayes)法是基于贝叶斯定理与特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入输出的联合概率分布；然后基于此模型，对给定的输入x，利用贝叶斯定理求出后验概率最大的输出y。朴素贝叶斯实现简单，学习与预测的效率都很高，是一种常用方法。\n",
    "\n",
    "以下内容包括朴素贝叶斯的学习与分类、朴素贝叶斯的参数估计方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 朴素贝叶斯的学习与分类\n",
    "\n",
    "### 1.1 基本方法\n",
    "输入空间$\\chi\\subset \\mathbf{R^n}$为n维向量的集合，输出空间为类标记集合$Y=\\{c_1,c_2,...,c_K\\}$。输入空间为特征向量$x\\in X$，输出类标记$y\\in Y$。$X$是定义在输入空间$\\mathbb{\\chi}$上的随机变量，$Y$是定义在输出空间$\\mathbb{Y}$上的随机变量。$P(X,Y)$是$X$和$Y$的联合概率分布。训练数据集为\n",
    "$$\n",
    "T = \\{(x_1,y_1), (x_2, y_2), ..., (x_N, y_N)\\}\n",
    "$$\n",
    "由$P(X,Y)$独立同分布产生。\n",
    "\n",
    "假定$Y$的先验概率分布为\n",
    "$$\n",
    "P(Y=c_k),k=1,2,...,K\n",
    "$$\n",
    "条件概率分布\n",
    "$$\n",
    "P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k),k=1,2,...,K\n",
    "$$\n",
    "据此学习到联合概率分布$P(X,Y)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯对条件概率分布作了条件独立性的假设，因此被称为“朴素”贝叶斯。具体而言\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(X=x|Y=c_k)&=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k)\\\\\n",
    "&=\\prod_{j=1}^nP(X^{(j)}=x^{(j)}|Y=c_k)\n",
    "\\end{aligned}\n",
    "$$\n",
    "朴素贝叶斯学习到的是生成数据的机制，所以属于生成模型。条件独立假设等于是说用于分类的特征在类确定的条件下是条件独立的。这一假设使朴素贝叶斯变得简单，但有时会牺牲一定的分类准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴树贝叶斯分类时，对给定的输入x，通过学习到的模型计算后验分布$P(Y=c_k|X=x)$，将后验概率最大的类作为x的类输出。后验概率计算根据贝叶斯定理得出\n",
    "$$\n",
    "P(Y=c_k|X=x)=\\frac{P(X=x|Y=c_k)P(Y=c_k)}{\\sum_kP(X=x|Y=c_k)P(Y=c_k)}\n",
    "$$\n",
    "结合条件独立性假设，有\n",
    "$$\n",
    "P(Y=c_k|X=x)=\\frac{P(Y=c_k)\\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)}{\\sum_kP(Y=c_k)\\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)},k=1,2...,K\n",
    "$$\n",
    "以上即为朴素贝叶斯的基本公式。于是，朴素贝叶斯分类器可表示为\n",
    "$$\n",
    "y=f(x)=\\mathrm{arg}\\max_{c_k}\\frac{P(Y=c_k)\\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)}{\\sum_kP(Y=c_k)\\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)}\n",
    "$$\n",
    "注意到，分母对所有的$c_k$都是相同的，所以以上最大化问题可以简化为\n",
    "$$\n",
    "y=f(x)=\\mathrm{arg}\\max_{c_k}P(Y=c_k)\\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 朴素贝叶斯的参数估计\n",
    "\n",
    "### 2.1 极大似然估计\n",
    "先验概率$P(Y=c_k)$极大似然估计为\n",
    "$$\n",
    "P(Y=c_k)=\\frac{\\sum_{i=1}^{N}I(y_i=c_k)}{N},k=1,2,...,K\n",
    "$$\n",
    "设第j个特征$x^{(j)}$可能取值的集合为$\\{a_{j1},a_{j2},...,a_{jS_j}\\}$，条件概率$P(X^{(j)}=a_{jl}|Y=c_k)$的极大似然估计是\n",
    "$$\n",
    "P(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl,y_i=c_k})}{\\sum_{i=1}^NI(y_i=c_k)}\\\\\n",
    "j=1,2,...,n;\\\\\n",
    "l=1,2,...,S_j;\\\\\n",
    "k=1,2,...,K\n",
    "$$\n",
    "上式中，$x_i^{(j)}$是第i个样本的第j个特征；$a_{jl}$是第j个特征可能取的第l个值；I为指示函数。\n",
    "$\\sum_{i=1}^NI(y_i=c_k)$为类别$c_k$的频数；$\\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl,y_i=c_k})$为类别$c_k$中属性$x_i^{(j)}$的值为$a_{jl}$的频数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 学习与分类算法\n",
    "\n",
    ">算法4.1  朴素贝叶斯算法（naive Bayes algorithm）\n",
    ">\n",
    ">输入: 训练集$T = \\{(x_1,y_1), (x_2, y_2), ..., (x_N, y_N)\\}$, 其中$x_i=(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})^T$，$x_i^{(j)}$表示第i个样本的第j个特征，$x_i^{(j)}\\in \\{a_{j1},a_{j2},...,a_{jn}\\}$，$a_{jl}$是第j个特征可能取的第l个值，$j=1,2,...,n;l=1,2,...,S_j;y_i\\in\\{c_1,c_2,...,c_K\\}$；实例$x$;\n",
    ">\n",
    ">输出：实例$x$的分类。\n",
    ">\n",
    ">算法过程：\n",
    ">\n",
    ">(1) 计算先验概率及条件概率\n",
    ">$$\n",
    "P(Y=c_k)=\\frac{\\sum_{i=1}^{N}I(y_i=c_k)}{N},k=1,2,...,K\\\\\n",
    "P(X^{(j)}=a_{jl}|Y=c_k)=\\frac{\\sum_{i=1}^{N}I(x_i^{(j)}=a_{jl,y_i=c_k})}{\\sum_{i=1}^NI(y_i=c_k)}\\\\\n",
    "j=1,2,...,n;\\\\\n",
    "l=1,2,...,S_j;\\\\\n",
    "k=1,2,...,K\n",
    "$$\n",
    ">(2) 对于给定的实例$x_i=(x_i^{(1)},x_i^{(2)},...,x_i^{(n)})^T$计算\n",
    ">$$\n",
    "P(Y=c_k)\\prod_jP(X^{(j)}=x^{(j)}|Y=c_k),k=1,2,...,K\n",
    "$$\n",
    ">(3) 确定实例$x$的类\n",
    ">$$\n",
    "y=f(x)=\\mathrm{arg}\\max_{c_k}P(Y=c_k)\\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例4.1数据集\n",
    "X = np.array([\n",
    "    [1, 'S'],\n",
    "    [1, 'M'],\n",
    "    [1, 'M'],\n",
    "    [1, 'S'],\n",
    "    [1, 'S'],\n",
    "    [2, 'S'],\n",
    "    [2, 'M'],\n",
    "    [2, 'M'],\n",
    "    [2, 'L'],\n",
    "    [2, 'L'],\n",
    "    [3, 'L'],\n",
    "    [3, 'M'],\n",
    "    [3, 'M'],\n",
    "    [3, 'L'],\n",
    "    [3, 'L']])\n",
    "y = np.array([-1, -1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15, 2), (15,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def naiveBayes(X, y):\n",
    "    labels = set(y)\n",
    "    attrs = {i: set(X[:, i]) for i in range(X.shape[1])}\n",
    "    P_y = {c: np.sum(y == c) for c in labels}\n",
    "    P_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
