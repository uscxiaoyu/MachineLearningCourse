{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二. k近邻算法\n",
    "\n",
    "k近邻法(`k-nearest neighbor, k-NN`)是一种基本分类和回归方法(`Cover & Hart, 1968`)。k近邻法的输入为实例的特征向量，对应于特征空间的点，输出为实例的类别，可以取多类。分类时，对新的实例，根据其k个最近邻的训练实例的类别，根据其k个最近邻的训练实例的类别，通过多数表决等方式进行预测。\n",
    "\n",
    "k近邻法不具显式的学习过程，k值的选择、距离度量以及分类决策规则是k近邻法的三要素。难点在于如何高效地定位到输入实例的k个最近邻居。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. k近邻算法\n",
    "\n",
    "**算法3.1（k近邻法）**\n",
    "- 输入：训练数据集\n",
    "$$\n",
    "T=\\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\\}\n",
    "$$\n",
    "其中，$x_i\\in\\mathbf{x}\\subset \\mathbf{R^n}$为实例的特征向量，$y_i\\in \\mathbf{y}=\\{c_1,c_2,...,c_K\\}$为实例的类别，$i=1,2,...,N$；实例特征向量$x$；\n",
    "- 输出：实例$x$的所属类$y$\n",
    "- 算法过程\n",
    "    - 根据给定的距离度量，在训练集$T$中找出与$x$最近邻的$k$个点，涵盖这$k$个点的$x$的近邻记作$N_K(x)$\n",
    "    - 在$N_k(x)$中根据分类决策规则决定$x$类别$y$\n",
    "    $$\n",
    "    y=\\mathrm{arg} \\max_{c_j} \\sum_{x_i\\in N_k(x)} I(y_i=c_i),i=1,2,...,N;j=1,2,...,K\n",
    "    $$\n",
    "    上式中，I为指示函数，即当$y_i=c_j$时$I$为1，否则$I$为0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 距离度量\n",
    "\n",
    "- $L_p$距离\n",
    "\n",
    "设特征空间$\\mathbf{X}$是n维实数向量空间$\\mathbf{R^n}$，$x_i, x_j\\in \\mathbf{x}, x_i = (x^{(1)}_i,x^{(2)}_i,...,x^{(n)}_i)^T,x_j=(x_j^{(1)}, x_j^{(2)},... ,x_j^{(n)})^T,x_i,x_j$的$L_p$距离定义为\n",
    "$$\n",
    "L_p(x_i,x_j)=\\left(\\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^p\\right)^{\\frac{1}{p}}\n",
    "$$\n",
    "这里$p\\ge 1$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当$p=2$时，称为欧式距离(`Euclidean distance`)，即\n",
    "$$\n",
    "L_2(x_i,x_j)=\\left(\\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|^2\\right)^{\\frac{1}{2}}\n",
    "$$\n",
    "\n",
    "当$p=1$时，称为曼哈顿距离(`Manhattan distance`)，即\n",
    "$$\n",
    "L_1(x_i,x_j)=\\left(\\sum_{l=1}^n|x_i^{(l)}-x_j^{(l)}|\\right)\n",
    "$$\n",
    "\n",
    "当$p=\\infty$时，它是各个坐标距离的最大值，即\n",
    "$$\n",
    "L_{\\infty}(x_i,x_j)=\\max_l|x_i^{(l)}-x_j^{(l)}|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(xi, xj, p=2):\n",
    "    return np.sum((np.abs(xi - xj))**p)**(1/p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(x1, x2, p=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 线性搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search_knn(x, X, k):\n",
    "    dist_list = []\n",
    "    for i in range(len(X)):\n",
    "        dist_list.append([distance(X[i], x), i])\n",
    "        \n",
    "    top_k = sorted(dist_list)[:k]\n",
    "    return top_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. `kd`树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 构造`kd`树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，kd树是存储k维空间数据的树结构，这里的k与k近邻中的的k意义不同。通常，依次选择坐标轴对空间划分，选择训练实例点在选定坐标轴上的中位数为切分点，这样得到的kd树是平衡的。\n",
    "\n",
    "kd树是一种对k维空间中的实例点进行存储以便对其进行快速检索的树型数据结构。kd树是二叉树，表示对k维空间的一个划分。构造kd树相当于不断地用垂直于坐标轴的超平面将k维空间切分，构成一系列的k维超矩形区域。\n",
    "\n",
    "kd树的每一个结点对应于一个k维矩形区域。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**算法3.2（构造平衡kd数）**\n",
    "- 输入：k维空间数据集$T=\\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\\}$，其中$x_i = (x^{(1)}_i,x^{(2)}_i,...,x^{(n)}_i)^T,i=1,2,...,N$\n",
    "- 输出：kd平衡树\n",
    "- 算法过程：\n",
    "    - 开始：构造根结点，根结点对应于包含T的k维空间的超矩形区域。选择以$x^{(1)}$为坐标轴，以T中所有实例的$x^{(1)}$坐标的*中位数*为切分点，将根结点对应的超矩形区域切分成两个子区域。切分由通过切分点并与坐标轴$x^{(1)}$垂直的超平面实现。由根结点生成深度为1的左右子结点：左子区域对应$x^{(1)}$小于切分点的子区域，右子区域对应$x^{(1)}$大于切分点的子区域。将落在切分超平面上的实例点保存在根结点。\n",
    "    - 重复：对深度为j的结点，选择$x^{(l)}$为切分的坐标轴，$l=(j\\ \\text{mod}\\ k) + 1$，以该节点的区域所有实例的$x^{(1)}$坐标的中位数为切分点，将该结点对应的超矩形区域切分为两个子区域。切分由通过切分点并与坐标轴$x^{(j)}$垂直的超平面实现。由根结点生成深度为$j+1$的左右子结点：左子区域对应$x^{(l)}$小于切分点的子区域，右子区域对应$x^{(l)}$大于切分点的子区域。将落在切分超平面上的实例点保存在该结点。\n",
    "    - 直到两个区域没有实例存在时停止。从而形成kd树的区域划分。\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：\n",
    "- 如果使用中位数，非叶结点上可能没有数据，如何处理？\n",
    "- 多个数据保留在非叶结点上，如何处理？\n",
    "- 倒数第二层只有2个结点，继续分时缺少右子结点，如何继续往下分？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. 基于递归生成kd树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结点如何生长？\n",
    "- 如果结点对应数据个数不大于1，则停止增长\n",
    "- 如果结点对应数据个数大于1，则继续生成两个后代结点\n",
    "    - 按照指定维度的数据切分为两部分，下分给两个后代节点\n",
    "\n",
    "可以利用递归思想生成kd树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_node_id(start=0, step=1):\n",
    "    '''\n",
    "    用于生成结点编号\n",
    "    '''\n",
    "    node_id = start\n",
    "    while True:\n",
    "        yield node_id\n",
    "        node_id += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_kdTree_recur(X, y, k, dim, node_id=0, kd_tree=nx.DiGraph()):\n",
    "    '''\n",
    "    X: ndarray\n",
    "    y: ndarray\n",
    "    k: 实例的维度\n",
    "    dim: 当前结点所处的维度\n",
    "    node_id: 当前结点的编号\n",
    "    '''\n",
    "    if node_id == 0:  # 根结点\n",
    "        kd_tree.add_node(node_id)\n",
    "        \n",
    "    if y.size >= 2:  # 如果有两个以上的结点，继续往下分\n",
    "        x_dim = X[:, dim]  # 取当前维度数据\n",
    "        next_dim = (dim + 1) % k  # 获取下一代结点数据的切分维度\n",
    "        s_indices = np.argsort(x_dim)  # 获取按x_dim由小到大排序的各特征索引\n",
    "        m = len(s_indices) // 2  # 中间或中间靠左的索引\n",
    "        l_indices = s_indices[:m]  # 左子区域索引\n",
    "        m_idx = s_indices[m]  # 留在结点上的数据索引\n",
    "        r_indices = s_indices[m + 1:]  # 右子区域索引\n",
    "        l_X, l_y = X[l_indices], y[l_indices]\n",
    "        r_X, r_y = X[r_indices], y[r_indices]\n",
    "        l_node_id = next(nodeId_gen)  # 获取下一个结点编号\n",
    "        r_node_id = next(nodeId_gen)\n",
    "        # 添加当前结点到子节点的连边\n",
    "        kd_tree.add_edges_from([(node_id, l_node_id), (node_id, r_node_id)])  \n",
    "        kd_tree.nodes[node_id][\"l_succ\"] = l_node_id\n",
    "        kd_tree.nodes[node_id][\"r_succ\"] = r_node_id\n",
    "        kd_tree.nodes[node_id][\"point\"] = (X[m_idx], y[m_idx])  # 当前结点上的数据\n",
    "        kd_tree = gen_kdTree_recur(l_X, l_y, k, next_dim, l_node_id, kd_tree)  # 递归左子结点\n",
    "        kd_tree = gen_kdTree_recur(r_X, r_y, k, next_dim, r_node_id, kd_tree)  # 递归左子结点\n",
    "    else:  # 如果少于2个结点，则将当前结点设为叶结点\n",
    "        kd_tree.nodes[node_id]['node_type'] = 'leaf'\n",
    "        p_node_id = list(kd_tree.predecessors(node_id))[0]\n",
    "        # 有些叶结点可能没有数据，为了简化接下来的搜索程序，该结点取父结点的数据\n",
    "        kd_tree.nodes[node_id][\"point\"] = (X[0], y[0]) if y.size == 1 else kd_tree.nodes[p_node_id][\"point\"]\n",
    "            \n",
    "    return kd_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(low=0, high=100, size=(10000, 6))\n",
    "y = np.ones(X.shape[0], dtype=np.int)\n",
    "y[np.random.rand(y.size) < 0.5] = 0\n",
    "dim = 0\n",
    "nodeId_gen = generate_node_id(start=0)  # 用于生成结点编号\n",
    "root_nodeId = next(nodeId_gen)\n",
    "tree = gen_kdTree_recur(X, y, k=X.shape[1], dim=0, node_id=root_nodeId, kd_tree=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11809"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. 基于循环生成kd树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kd_tree(X, y):\n",
    "    '''\n",
    "    X: ndarray\n",
    "    y: ndarray\n",
    "    '''\n",
    "    k = X.shape[1]  # X的维度k\n",
    "    kd_tree = nx.DiGraph()\n",
    "    node_id = 0\n",
    "    no_tag_nodes = [node_id]\n",
    "    kd_tree.add_node(node_id)\n",
    "    kd_tree.nodes[node_id][\"X\"] = X\n",
    "    kd_tree.nodes[node_id][\"y\"] = y\n",
    "    kd_tree.nodes[node_id][\"node_type\"] = 'root'\n",
    "    i = 0\n",
    "    while no_tag_nodes:\n",
    "        new_nodes = []\n",
    "        dim = i % k  # 当前的维度\n",
    "        for node in no_tag_nodes:\n",
    "            c_X = kd_tree.nodes[node][\"X\"]\n",
    "            c_y = kd_tree.nodes[node][\"y\"]\n",
    "            x_dim = c_X[:, dim]\n",
    "            if len(x_dim) >= 2:  # 如果有2个以上样本，则继续分\n",
    "                kd_tree.nodes[node][\"dim\"] = dim  # 结点的切分维度\n",
    "                s_indices = np.argsort(x_dim)\n",
    "                m = len(s_indices)//2  # 中间的索引\n",
    "                l_indices = s_indices[:m]  # 左子区域\n",
    "                m_idx = s_indices[m]  # 留在结点上\n",
    "                r_indices = s_indices[m + 1: ]  # 右子区域\n",
    "                l_X, l_y = c_X[l_indices], c_y[l_indices]\n",
    "                r_X, r_y = c_X[r_indices], c_y[r_indices]\n",
    "                \n",
    "                # 左子结点\n",
    "                node_id += 1\n",
    "                kd_tree.add_edge(node, node_id)\n",
    "                kd_tree.nodes[node_id][\"X\"] = l_X\n",
    "                kd_tree.nodes[node_id][\"y\"] = l_y\n",
    "                kd_tree.nodes[node_id]['node_type'] = 'non_leaf'\n",
    "                kd_tree.nodes[node][\"l_succ\"] = node_id\n",
    "                new_nodes.append(node_id)\n",
    "                \n",
    "                # 右子结点\n",
    "                node_id += 1\n",
    "                kd_tree.add_edge(node, node_id)\n",
    "                kd_tree.nodes[node_id]['node_type'] = 'non_leaf'\n",
    "                new_nodes.append(node_id)\n",
    "                kd_tree.nodes[node_id][\"X\"] = r_X\n",
    "                kd_tree.nodes[node_id][\"y\"] = r_y\n",
    "                kd_tree.nodes[node][\"r_succ\"] = node_id                    \n",
    "                \n",
    "                # 结点node上的数据\n",
    "                kd_tree.nodes[node][\"point\"] = (c_X[m_idx], c_y[m_idx])\n",
    "            else:\n",
    "                kd_tree.nodes[node]['node_type'] = 'leaf'\n",
    "                if len(x_dim) == 1:\n",
    "                    kd_tree.nodes[node][\"point\"] = (c_X[0], c_y[0])\n",
    "                else:  # 若不存在数据\n",
    "                    p_node = list(kd_tree.predecessors(node))[0]\n",
    "                    kd_tree.nodes[node][\"point\"] = kd_tree.nodes[p_node][\"point\"]  # 设为父结点的数据\n",
    "            \n",
    "        i += 1\n",
    "        no_tag_nodes = new_nodes\n",
    "        \n",
    "    return kd_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]), 1, array([], dtype=int64))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 2\n",
    "a = np.arange(i)\n",
    "a[:int(i/2)], a[int(i/2)], a[int(i/2) + 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 随机生成实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randint(low=0, high=100, size=(100, 6))\n",
    "y = np.ones(X.shape[0], dtype=np.int)\n",
    "y[np.random.rand(y.size) < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "kd_tree = generate_kd_tree(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kd_tree.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_type': 'leaf',\n",
       " 'X': array([], shape=(0, 6), dtype=int64),\n",
       " 'y': array([], dtype=int64),\n",
       " 'point': (array([70, 97, 74, 68, 96, 14]), 1)}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kd_tree.nodes[126]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 基于kd树搜索目标数据的最优k近邻\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**算法3.3 （基于kd树的k最优近邻搜索）**\n",
    "\n",
    "- 输入: 已构造的`kd`树，目标点`x`，邻居数量`k`\n",
    "- 输出: x的k个最近邻`k_list`\n",
    "- 算法过程\n",
    "    - (1)在`kd`树中找到包含目标点`x`的**某一**叶结点：\n",
    "        - 从根节点出发，递归地向下访问`kd`树：如果目标点x当前维的坐标小于等于切分点的坐标，则移动到左子结点；否则移动到右子结点，直到子结点为叶结点为止；\n",
    "        - 令叶结点为当前结点`node`；\n",
    "    - (2)计算`node`至`x`的距离，并将`node`保存至回退历史列表`back_list`，将`(dist(node, x), node)`保存至`k_list`;\n",
    "    - (3)如果`node`是根结点，则跳转至(4); 否则，进行以下循环\n",
    "        - (3.1)获取`node`的父结点`p_node`;\n",
    "        - (3.2)如果`p_node`不在`back_list`中，则将`p_node`添加至`back_list`，并计算x到`p_node`和`p_node`所在切割面的距离`dist_x_pnode`、`dist_x_div`；\n",
    "            - (3.2.1)判断是否将`p_node`添加至`k_list`: \n",
    "                - 如果`k_list`中的元素个数小于k，则将`(dist_pnode_x, p_node)`保存至`k_list`，并对`k_list`按距离从小到大排序；\n",
    "                - 否则，如果`dist_pnode_x`小于`k_list`的最大距离，则`(dist_pnode_x, p_node)`替换`k_list`的最后一个元素，对`k_list`按距离从小到大排序;\n",
    "            - (3.2.2)判断是否遍历`p_node`的另一分支：\n",
    "                - 如果`dist_x_div`小于`k_list`的最大距离，则遍历`p_node`的另一分支，得到其距离`x`最近的点，并将其设为下一轮需判断的结点`node`；并将`node`保存至回退历史列表`back_list`，计算`node`至`x`的距离`dist_node_x`，并根据(3.2.1)过程判断是否应将`node`添加至`k_list`;\n",
    "                - 否则更新`node := p_node`;\n",
    "        - (3.3)否则，更新`node := p_node`;\n",
    "    - (4)返回`k_list`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题:\n",
    "- 搜索时，如果目标数据刚好处在分割平面上，如何处理？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在kd树中找到包含目标数据x的叶结点，如果x处于的交界面上，则可选择任意方向往下遍历至叶结点，在搜索最近邻时必将搜索其它结点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_kd_tree(x, node, kd_tree):\n",
    "    '''\n",
    "    搜索node在哪个区域(叶结点)\n",
    "    '''\n",
    "    if kd_tree.nodes[node]['node_type'] != 'leaf':\n",
    "        dim = kd_tree.nodes[node]['dim']\n",
    "        median = kd_tree.nodes[node][\"point\"][0][dim]\n",
    "        if x[dim] <= median:  # 如果刚好处在内部结点所在的切割面上，则往左子节点走\n",
    "            return search_kd_tree(x, kd_tree.nodes[node]['l_succ'], kd_tree)\n",
    "        else:  # 右子结点\n",
    "            return search_kd_tree(x, kd_tree.nodes[node]['r_succ'], kd_tree)\n",
    "    else:\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15,  3, 42, 44, 55, 30])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(low=0, high=100, size=6)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "leaf (array([ 1, 22,  0, 12,  4, 29]), 0.0)\n"
     ]
    }
   ],
   "source": [
    "n = search_kd_tree(x, 0, kd_tree)\n",
    "print(n)\n",
    "print(kd_tree.nodes[n]['node_type'], kd_tree.nodes[n]['point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 辅助函数，将列表元素压缩为1维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(a_list, result=[]):\n",
    "    for a in a_list:\n",
    "        if isinstance(a, list):\n",
    "            result = flatten(a, result=result)\n",
    "        else:\n",
    "            result.append(a)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, [2, [3, [4, [5, [6], [7]]]]]]\n",
    "flat_a = flatten(a, result=[])\n",
    "flat_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 从叶节点回退，并寻找k个最近邻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_neighbors(x, node, k, kd_tree):\n",
    "    '''\n",
    "    从叶结点x回退\n",
    "    k_list保存离x最近的k个点\n",
    "    '''\n",
    "    dist_node_x = distance(x, kd_tree.nodes[node]['point'][0])\n",
    "    k_list = [[dist_node_x, node]]  # 保存k个最近邻居\n",
    "    back_list = [node]  # 回退历史\n",
    "    while kd_tree.nodes[node]['node_type'] != 'root':\n",
    "        p_node = list(kd_tree.predecessors(node))[0]\n",
    "        if p_node not in back_list:  # 如果p_node没有在回退过程中被评估\n",
    "            back_list.append(p_node)\n",
    "            dim = kd_tree.nodes[p_node]['dim']  # 父结点的切分维度\n",
    "            p_x = kd_tree.nodes[p_node]['point'][0]  # 父结点保存的数据x\n",
    "            dist_pnode_x = distance(x, p_x)  # x到p_node的距离\n",
    "            dist_div_x = np.abs(p_x[dim] - x[dim])  # x 到 p_node所在切割面的距离\n",
    "            # 决定是否往k_list中添加p_node\n",
    "            if len(k_list) < k or dist_pnode_x < k_list[-1][0]:  # 不足k个近邻 or 小于k_list中距离最远的点\n",
    "                k_list.append([dist_pnode_x, p_node])\n",
    "                k_list = sorted(k_list)[:k]\n",
    "            \n",
    "            # 决定是否向上回退或者往node兄弟结点搜索\n",
    "            if dist_div_x < k_list[-1][0]:  # 到父结点分割平面的距离小于k_list中最远的点\n",
    "                sibling_nodes = list(kd_tree.successors(p_node))\n",
    "                sibling_nodes.remove(node)\n",
    "                t_node = sibling_nodes[0]  # node的兄弟结点\n",
    "                node = search_kd_tree(x, t_node, kd_tree)  # t_node距x最近的叶结点, 由node往上回退\n",
    "                back_list.append(node)\n",
    "                dist_node_x = distance(x, kd_tree.nodes[node]['point'][0])\n",
    "                if len(k_list) < k or dist_node_x < k_list[-1][0]:  # 决定是否将该叶结点加入到k_list\n",
    "                    k_list.append([dist_node_x, node])\n",
    "                    k_list = sorted(k_list)[:k]\n",
    "            else:  # 如果父结点分割面的距离大于当前最近距离，则设置当前结点为p_node，继续下一轮循环\n",
    "                node = p_node\n",
    "        else:  # 如果p_node结点已被遍历\n",
    "            node = p_node\n",
    "            \n",
    "    return k_list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 20, 74, 13, 23, 17])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(low=0, high=100, size=6)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "time elapsed:  0.002401\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "n = search_kd_tree(x, 0, kd_tree)\n",
    "print(n)\n",
    "k_list = find_k_neighbors(x, n, 3, kd_tree)\n",
    "print(f\"time elapsed: {time.perf_counter() - t1: .6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[44.21538193886829, 15], [53.094255809833136, 35], [54.433445601027316, 8]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed:  0.001247\n"
     ]
    }
   ],
   "source": [
    "# 对比：线性搜索\n",
    "t1 = time.perf_counter()\n",
    "k_list2 = line_search_knn(x, X, k=3)\n",
    "print(f\"time elapsed: {time.perf_counter() - t1: .6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[44.21538193886829, 70], [53.094255809833136, 87], [54.433445601027316, 51]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 决策规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 分类\n",
    "k近邻法中的分类决策规则往往是多数表决，即由输入实例的k个近邻的训练实例中的多数类决定新输入实例的类。\n",
    "\n",
    "多数表决规则有如下解释：如果分类的损失函数为0-1损失函数，分类函数为\n",
    "$$\n",
    "f: \\mathbf{R^n} \\rightarrow \\{c_1,c_2,...,c_K\\}\n",
    "$$\n",
    "那么误分类的概率是\n",
    "$$\n",
    "P(Y\\neq f(X))=1-P(Y=f(X))\n",
    "$$\n",
    "对于给定的实例$x\\in \\chi$，其最近邻的k个训练实例点构成集合$N_k(x)$。如果涵盖$N_k(x)$的区域的类别是$c_j$，那么误分类率是\n",
    "$$\n",
    "\\frac{1}{k}\\sum_{x_i\\in N_k(x)}I(y_i\\neq c_j)=1-\\frac{1}{k}\\sum_{x_i\\in N_k(x)}I(y_i=c_j)\n",
    "$$\n",
    "要使误分类率最小即经验风险最小，就要使$\\sum_{x_i\\in N_k(x)}I(y_i=c_j)$最大，所以多数表决规则等价于经验风险最小化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(x, k_list, kd_tree):\n",
    "    y_dict = {}\n",
    "    for _, node in k_list:\n",
    "        y = kd_tree.nodes[node]['point'][1]\n",
    "        if y in y_dict:\n",
    "            y_dict[y] += 1\n",
    "        else:\n",
    "            y_dict[y] = 1\n",
    "    print(y_dict)\n",
    "    return sorted(list(y_dict.items()), key=lambda x: x[1])[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 2, 0: 1}\n"
     ]
    }
   ],
   "source": [
    "y = majority_vote(x, k_list, kd_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 回归\n",
    "\n",
    "取`k`近邻对应y的平均值为输入实例的预测值\n",
    "$$\n",
    "\\hat{y} = \\frac{1}{k}\\sum_{x_i\\in N_k(x)}y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_k_nn(x, k_list, kd_tree):\n",
    "    y_list = []\n",
    "    for _, node in k_list:\n",
    "        y = kd_tree.nodes[node]['point'][1]\n",
    "        y_list.append(y)\n",
    "        \n",
    "    return sum(y_list) / len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = average_k_nn(x, k_list, kd_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
