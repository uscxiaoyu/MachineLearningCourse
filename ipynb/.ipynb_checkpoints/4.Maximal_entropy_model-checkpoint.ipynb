{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四. 最大熵模型\n",
    "\n",
    "最大熵模型(maximum entropy)由最大熵原理推导实现。最大熵原理认为，学习概率模型时，在所有可能的概率模型中，熵最大的模型是最好的模型。通过约束条件来确定概率模型的集合。所以，最大熵愿意也可表述为**在满足约束条件的模型集合中选取熵最大的模型**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设离散随机变量X的概率分布是$P(X)$，则其熵为\n",
    "$$\n",
    "H(P)=-\\sum_x P(x)\\log P(x)\n",
    "$$\n",
    "熵满足$0\\geq H(P) \\leq \\log|X|$，其中$|X|$是$X$的取值个数。\n",
    "\n",
    "直观地，最大熵原理认为要选择的概率模型首先必须满足已有的事实，即约束条件。在无更多信息的情况下，哪些不确定的部分是”等可能的“。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 定义\n",
    "\n",
    "假设分类模型是一个条件概率分布$P(Y|X), X\\in \\mathbf{X} \\subset \\mathbf{R^n}$表示输入，$Y\\in \\mathbf{Y}$表示输出，$\\mathbf{X,Y}$分别表示输入和输出集合。即对于给定的输入X，以条件概率$P(Y|X)$输出Y。\n",
    "\n",
    "给定一个训练集\n",
    "$$\n",
    "T=\\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\\}\n",
    "$$\n",
    "学习的目标是用最大熵原理选择最好的分类模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定训练集，可以确定联合分布$P(X,Y)$的经验分布和边缘分布$P(X)$的经验分布，分别以$\\tilde{P}(X,Y)$和$\\tilde{P}(X)$表示\n",
    "$$\n",
    "\\tilde{P}(X=x,Y=y)=\\frac{v(X=x,Y=y)}{N}\\\\\n",
    "\\tilde{P}(X=x)=\\frac{v(X=x)}{N}\n",
    "$$\n",
    "其中$v(X=x,Y=y)$表示训练数据中样本$(x,y)$出现的频率，$v(X=x)$表示$x$出现的频率，$N$表示训练样本容量。\n",
    "\n",
    "用特征函数$f(x,y)$描述输入x和输出y之间的某一个事实：\n",
    "$$\n",
    "\\begin{equation}\n",
    "f(x,y)=\\begin{cases}\n",
    "1,\\text{(x,y)满足某一事实}\\\\\n",
    "0,\\text{否则}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "特征函数$f(x,y)$关于经验分布$\\tilde{P}(X,Y)$的期望值，用$E_{\\tilde{P}}(f)$表示\n",
    "$$\n",
    "E_{\\tilde{P}}(f)=\\sum_{x,y}\\tilde{P}(X=x,Y=y)f(x,y)\n",
    "$$\n",
    "特征函数$f(x,y)$关于模型$P(Y|X)$与经验分布$\\tilde{P}(X)$的期望值\n",
    "$$\n",
    "E_P(f)=\\sum_{x,y}\\tilde{P}(x)P(y|x)f(x,y)\n",
    "$$\n",
    "如果模型能获取训练数据中的信息，可以假定这两个期望值相等$E_P(f)=E_{\\tilde{P}}(f)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义6.3 （最大熵模型）** 假设满足所有约束条件的模型集合为\n",
    "$$\n",
    "C=\\{P\\in\\mathbf{P}|E_P(f_i)=E_{\\tilde{P}}(f_i),i=1,2,...,n\\}\n",
    "$$\n",
    "定义在条件概率分布$P(Y|X)$上的条件熵为\n",
    "$$\n",
    "H(P)=-\\sum_{x,y}\\tilde{P}(x)P(y|x)\\log_2 P(y|x)\n",
    "$$\n",
    "则模型集合$C$中条件熵$H(P)$最大的模型称为最大熵模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 最大熵模型的学习\n",
    "\n",
    "最大熵模型的学习可以形式化为约束最优化问题。\n",
    "$$\n",
    "\\min_{P\\in C} -H(P)=\\sum_{x,y}\\tilde{P}(x)P(y|x)\\log_2 P(y|x)\\\\\n",
    "\\text{s.t.    } E_P(f_i)-E_{\\tilde{P}}(f_i)=0,i=1,2,...,n\\\\\n",
    "\\sum_y P(y|x)=1\n",
    "$$\n",
    "以上优化问题的解即为最大熵模型学习的解。引入拉格朗日乘子$w_0,w_1,...,w_n$，定义拉格朗日函数$L(P,w)$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L(P,w)&=\n",
    "-H(P)+w_0(1-\\sum_y P(y|x))+\\sum_{i=1}^nw_i(E_{\\tilde{P}}(f_i)-E_P(f_i))\\\\\n",
    "&=\\sum_{x,y}\\tilde{P}(x)P(y|x)\\log P(y|x)+w_0\\left(1-\\sum_yP(y|x)\\right)+\\sum_{i=1}^nw_i\\left(\\sum_{x,y}\\tilde{P}(x,y)f_i(x,y)-\\sum_{x,y}\\tilde{P}(x)P(y|x)f_i(x,y) \\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最优化的原始问题是\n",
    "$$\n",
    "\\min_{P\\in C}\\max_w L(P,w)\n",
    "$$\n",
    "其对偶问题为\n",
    "$$\n",
    "\\max_w\\min_{P\\in C} L(P,w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求解可得最大熵模型:\n",
    "$$\n",
    "P_w(y|x)=\\frac{1}{Z_w(x)}exp\\left(\\sum_{i=1}^n w_if_i(x,y)\\right)\n",
    "$$\n",
    "其中, $Z_w(x)=\\sum_y exp\\left(\\sum_{i=1}^n w_if_i(x,y)\\right)$为规范化因子；$f_i(x,y)$是特征函数; $w_i$是特征的权值。\n",
    "\n",
    "可通过求解以下极大化问题得到最优的$w$\n",
    "$$\n",
    "\\max_w \\Psi(w)\n",
    "$$\n",
    "记为$w^*=\\text{arg}\\max_w \\Psi(w)$。进而得到最优的最大熵模型$P^*=P_{w^*}=P_{w^*}(y|x)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 最大熵的学习为具体求解最大熵模型的对数似然函数极大化或对偶函数极大化的问题（两者等价，具体见p102证明），即求解出$w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**算法6.2 （最大熵模型学习的拟牛顿法BFGS算法）**\n",
    "- 输入：特征函数$f_1,f_2,...,f_n$；经验分布$\\tilde{P}(x,y)$，目标函数$f(w)$，梯度$g(w)=\\bigtriangledown f(w)$，精度$\\epsilon$\n",
    "- 输出：最优参数值$w^*$；最优模型$P_{w^*}(y|x)$\n",
    "- 算法过程：\n",
    "    - 选定初始点$w^{(0)}$，取$B_0$为正定对称矩阵，置$k=0$\n",
    "    - 计算$g_k=g(w^{(k)})$。若$||g_k||<\\epsilon$，则停止计算，得$w^*=w^{(k)}$；否则转(3)\n",
    "    - 由$B_kP_k=-g_k$，求出$p_k$;\n",
    "    - 一维搜索：求$\\lambda_k$使得$f(w^{(k)}+\\lambda_kp_k)=\\min_{\\lambda\\geq 0}f(w^{(k)}+\\lambda p_k)$\n",
    "    - 置$w^{(k+1)}=w^k+\\lambda p_k$\n",
    "    - 计算$g_{k+1}=g(w^{(k+1)})$，若$||g_{k+1}||\\leq \\epsilon$，则停止运算，得$w^*=w^{(k+1)}$；否则，按下式求出$B_{k+1}$:\n",
    "    $$\n",
    "    B_{k+1}=B_k+\\frac{y_ky_k^T}{y_k^Ty_k}-\\frac{B_k\\delta_k\\delta_k^TB_k}{\\delta_k^TB_k\\delta_k}\n",
    "    $$\n",
    "    其中，$y_k=g_{k+1}-g_k,\\delta_k=w^{(k+1)}-w^{(k)}$\n",
    "    - 置$k:=k+1$, 转到（3）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximal_entropy_model(D, ):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
