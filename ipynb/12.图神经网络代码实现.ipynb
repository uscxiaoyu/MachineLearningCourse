{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e7a4b5e",
   "metadata": {},
   "source": [
    "使用PyG的内置数据进行3个任务的代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa623db",
   "metadata": {},
   "source": [
    "## 1.节点分类任务代码实现\n",
    "Cora数据集是PyG内置的节点分类数据集，代表着学术论文的相关性分类问题（即把每一篇学术论文都看成是节点），Cora数据集有2708个节点，1433维特征，边数为5429。标签是文献的主题，共计 7 个类别。所以这是一个7分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入数据\n",
    "dataset = Planetoid(root='./data/Cora', name='Cora')\n",
    "data = dataset[0]\n",
    "#定义网络架构\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)  #输入=节点特征维度，16是中间隐藏神经元个数\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "#模型训练\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)    #模型的输入有节点特征还有边特征,使用的是全部数据\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])   #损失仅仅计算的是训练集的损失\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#测试：\n",
    "model.eval()\n",
    "test_predict = model(data.x, data.edge_index)[data.test_mask]\n",
    "max_index = torch.argmax(test_predict, dim=1)\n",
    "test_true = data.y[data.test_mask]\n",
    "correct = 0\n",
    "for i in range(len(max_index)):\n",
    "    if max_index[i] == test_true[i]:\n",
    "        correct += 1\n",
    "        \n",
    "print('测试集准确率为：{}%'.format(correct*100/len(test_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a60bff",
   "metadata": {},
   "source": [
    "## 2.边分类任务代码实现\n",
    "同样是利用Cora数据集，只是这个时候我们关注的不再是节点特征，而是边特征，因此，在这里我们需要手动创建边标签的正例与负例。这是一个二分类问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51906f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "# 边分类模型\n",
    "class EdgeClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(EdgeClassifier, self).__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "        self.classifier = torch.nn.Linear(2 * out_channels, 2)  \n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv(x, edge_index))\n",
    "        pos_edge_index = edge_index    \n",
    "        total_edge_index = torch.cat([pos_edge_index, \n",
    "                                    negative_sampling(edge_index, num_neg_samples=pos_edge_index.size(1))], dim=1)\n",
    "        edge_features = torch.cat([x[total_edge_index[0]], x[total_edge_index[1]]], dim=1)  \n",
    "        return self.classifier(edge_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "dataset = Planetoid(root='./data/Cora/raw', name='Cora')\n",
    "data = dataset[0]\n",
    "\n",
    "# 创建train_mask和test_mask\n",
    "edges = data.edge_index.t().cpu().numpy()   \n",
    "num_edges = edges.shape[0]\n",
    "train_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_edges, dtype=torch.bool)\n",
    "train_size = int(0.8 * num_edges)\n",
    "train_indices = torch.randperm(num_edges)[:train_size]\n",
    "train_mask[train_indices] = True\n",
    "test_mask[~train_mask] = True\n",
    "\n",
    "# 定义模型和优化器/训练/测试\n",
    "model = EdgeClassifier(dataset.num_features, 64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(data.x, data.edge_index)\n",
    "    pos_edge_index = data.edge_index\n",
    "    pos_labels = torch.ones(pos_edge_index.size(1), dtype=torch.long)  \n",
    "    neg_labels = torch.zeros(pos_edge_index.size(1), dtype=torch.long)  \n",
    "    labels = torch.cat([pos_labels, neg_labels], dim=0).to(logits.device)\n",
    "    new_train_mask = torch.cat([train_mask, train_mask], dim=0)\n",
    "    loss = F.cross_entropy(logits[new_train_mask], labels[new_train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data.x, data.edge_index)\n",
    "        pos_edge_index = data.edge_index\n",
    "        pos_labels = torch.ones(pos_edge_index.size(1), dtype=torch.long)\n",
    "        neg_labels = torch.zeros(pos_edge_index.size(1), dtype=torch.long)\n",
    "        labels = torch.cat([pos_labels, neg_labels], dim=0).to(logits.device)\n",
    "        new_test_mask = torch.cat([test_mask, test_mask], dim=0)\n",
    "        \n",
    "        predictions = logits[new_test_mask].max(1)[1]\n",
    "        correct = predictions.eq(labels[new_test_mask]).sum().item()\n",
    "        return correct / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 1001):\n",
    "    loss = train()\n",
    "    acc = test()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Acc: {acc:.4f}\")                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c62125",
   "metadata": {},
   "source": [
    "## 3.图分类任务代码实现\n",
    "采用ENZYMES数据集。ENZYMES是一个常用的图分类基准数据集。它是由600个图组成的，这些图实际上表示了不同的蛋白酶的结构，这些蛋白酶分为6个类别（每个类别有100个蛋白酶）。因此，每个图代表一个蛋白酶，我们的任务是预测蛋白酶属于哪一个类别。这是6分类任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce87f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# 加载数据集\n",
    "dataset = TUDataset(root='./data/ENZYMES', name='ENZYMES')\n",
    "dataset = dataset.shuffle()\n",
    "\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义图卷积网络模型\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = torch.nn.Linear(hidden_channels, dataset.num_classes)\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)    # 使用全局平均池化获得图的嵌入\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 1001):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
